--- Q1 2021 ---
Simona Jankowski -- Investor Relations
Thank you. Good afternoon everyone and welcome to NVIDIA's conference call for the first quarter of fiscal 2021. With me on the call today from NVIDIA are Jensen Huang, President and Chief Executive Officer and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the second quarter of fiscal 2021. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent.
During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties and our actual results may vary materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, May 21st, 2020 based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. We can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Jensen.
Jensen Huang -- Founder, President and Chief Executive Officer
Thanks, Simona. Before Colette describes our quarterly results, I'd like to thank those who are on the front lines of this crisis: first responders, healthcare workers, service providers who inspires every day with their bravery and selflessness. I also want to acknowledge the incredible efforts of our colleagues here at NVIDIA. Despite many challenges, they have barely broken stride during one of the busiest periods in our history. Our efforts related to the virus are focused in three areas. First, we're taking care of our families and communities. We've pulled in raises by six months to put more money in our employees hands and NVIDIA and our people have donated thus far more than $10 million to those in need.
Second, we're using NVIDIA's unique capabilities to fight the virus. A great deal of science being done on COVID-19 uses NVIDIA technology for acceleration. Some of the many examples including sequencing the virus, analyzing drug candidates, imaging the virus at molecular resolution with cryo-electron microscopy, and identifying elevated body temperature with AI cameras. And third, because COVID-19 won't be the last killer virus, we need to be ready for the next outbreak. NVIDIA technology is essential for the scientific community to develop an end-to-end computational defense system, a system that can detect early, accelerate the development of a vaccine, contain the spread of disease, and continuously test and monitor.
We are racing to deploy the NVIDIA Clara computational healthcare platforms. Clara Parabricks can accelerate genomics analysis from days to minutes. Clara Imaging will continue to partner with leading research institutes to develop state-of-the-art AI models to detect infections, and Clara Guardian will connect AI to cameras and microphones in hospitals to help overloaded staff watch over patients.
We completed the acquisition of Mellanox on April 27th. Mellanox is now NVIDIA's networking brand and business unit and will be reported as part of our data center market platform, and Israel is now one of NVIDIA's major technology centers. The new NVIDIA has a much larger footprint in data center computing, end-to-end and full stack expertise in data center architectures and tremendous scale to accelerate innovation. NVIDIA and Mellanox are a perfect combination and position us for the major forces shaping the IT industry today, data center scale computing and AI.
From micro service cloud applications to machine learning and AI, accelerated computing and high performance networking are critical to modern data centers. Previously, a CPU compute node was the unit of computing. Going forward, the new unit of computing is an entire data center. The basic computing elements are now storage servers, CPU servers, and GPU servers and are composed and orchestrated by hyperscale applications that are serving millions of users simultaneously. Connecting these computing elements together is the high performance Mellanox networking. This is the era of data center scale computing and together, NVIDIA and Mellanox can architect end-to-end. Mellanox is an extraordinary company and I'm thrilled that we're now one force to invent the future together. Now let me turn the call over to Colette.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, Jensen. Against the backdrop of the extraordinary events unfolding around the globe, we had a very strong quarter. Q1 revenue was $3.08 billion, up 39% year-on-year, down 1% sequentially and slightly ahead of our outlook reflecting upside in our data center and gaming platforms. Starting with gaming, revenue of $1.34 billion was up 27% year-on-year and down 10% sequentially. We are pleased with these results which exceeded expectations in the quarter marked by the unprecedented challenge of the COVID-19.
Let me give you some color. Early in Q1, as the epidemic unfolded, demand in China was impacted with iCafes closing for an extended period. As the virus spread globally, much of the world started working and learning from home and gameplay surged. Globally, we have seen 50% rise in gaming hours played on our GeForce platform driven both by more people playing and more gameplay per user. With many retail outlets closed, demand for our products has shifted quite efficiently to e-tail channels globally. Gaming laptops revenue accelerated to its fastest year-on-year growth in six quarters. We are working with our OEMs, channel partners to meet the growing needs of the professionals and students engaged in working, learning, and playing at home.
In early April, our global OEM partners announced a record new 100 NVIDIA GeForce powered laptops with availability starting in Q1 and the most to ship in Q2. These laptops are the first to use our high-end NVIDIA GeForce RTX 2080 SUPER and 2070 SUPER GPUs, which have been available for desktop since last summer. In addition, OEMs are bringing to market laptops based on the RTX 2060 GPU at just $999, a price point that enables a larger audience to take advantage of the power and features of RTX including its unique ray tracing and AI capabilities. These launches are well timed as mobile and remote computing needs accelerate. The global rise in gaming also lifted sales of NVIDIA, Nintendo Switch and our console business driving strong growth both sequentially and year-over-year.
We collaborated with Microsoft and Mojang to bring RTX ray tracing to Minecraft, the world's most popular game with over 100 million gamers monthly and over 100 billion total views on YouTube. Minecraft with RTX looks astounding with realistic shadows and reflections, light that reflects, refracts, and scatters through surfaces as naturalistic effects like fog. Reviews for it are off the charts. Ars Technica called it a jaw-dropping stunner and PC World said it was glorious to behold. Our RTX technology stands apart not only with our two-year lead in ray tracing, but with its use of AI to speed up and enhance games using the Tensor Core silicon on our RTX-class GPUs. We introduced the next version of our AI algorithm called deep learning super sampling. In real-time, DLSS 2.0 can fill the missing bits from every frame, doubling performance. It represents a major step function from the original and it can be trained on non-gaming specific images making it universal and easy to implement. The value and momentum of our RTx GPUs continue to grow. We have a significant upgrade opportunity over the next year with the rising tide of RTx enabled games, including major blockbusters like Minecraft and Cyberpunk. Let me also touch on our game streaming service, GFN which exited beta this quarter. It gives gamers access to more than 650 games, with another 1,500 in line to get on-boarded. These include Epic Games' Fortnite, which is the most played game on GFN and other popular titles such as Control, Destiny 2 and League of Legends with Cyberpunk joining in the fall. Since launching in February GFN has added 2 million users around the world with both sign-ups and hours of game playing boosted by stay-at-home measures. GFN expands our market reach to the billions of gamers with underpowered devices. It is the most publisher-friendly, developer-friendly game streaming service with the greatest number of games and the only one that supports ray tracing.
Moving to Pro Visualization. Revenue was $307 million, up 15% year-on-year and down 7% sequentially. Year-on-year revenue growth accelerated in Q1, driven by laptop workstations and Turing adoption. We are seeing continued momentum in our ecosystem for RTx ray tracing. We now have RTx support for all major rendering visualization and design software packages, including Autodesk Maya, Dassault's CATIA, Pixar's RenderMan, Chaos Group's V-Ray and many others. Autodesk has announced that the latest release of VRED its automotive 3D visualization software supports NVIDIA RTx GPUs. This enables designers to take advantage of RTx to produce more like-life designs in a fraction of the time versus CPU base systems. Over 45 leading creative and design applications now take advantage of RTx driving a sustained upgrade opportunity for Quadro powered systems, while also extending their reach.
We see strong demand in verticals including healthcare, media and entertainment and higher education among others. Higher healthcare demand was fueled in part by COVID-19 related research at Siemens, Oxford and Caption Health. Caption Health received FDA clearance for an update to its AI guided ultrasound making it easier to perform diagnostics quality cardiac ultrasound. And in media and entertainment demand increased as companies like Disney deployed remote workforce initiatives.
Turning to automotive and robotic autonomous machines. Automotive revenue was $155 million, down 7% year-on-year and down 5% sequentially. The automotive industry is seeing a significant impact from the pandemic and we expect that to affect our revenue in the second quarter as well, likely declining about 40% from Q1. Despite the near-term challenges, our important work continues. We believe that every machine that moves someday will have autonomous capabilities. During the quarter, Xpeng introduced the P7, an all-electric sports sedan with innovative level 3 automated driving features, powered by the NVIDIA DRIVE AGX Xavier AI compute platform. Our open programmable software defined platform enables Xpeng to run is proprietary software while also delivering over-the-air updates for new driving features and capabilities. Production deliveries of the P7 with NVIDIA DRIVE begin next month.
Our Ampere architecture will power our next generation NVIDIA DRIVE platform called Orin, delivering more than six times the performance of Xavier solutions and four times better power efficiency. With Ampere scalability the DRIVE platform will extend from driverless robotaxis all the way down to in-windshield driver assistance systems sipping just a few watts of power. Customers appreciate the top-to-bottom platform all based on a single architecture, letting them build one software-defined platform for every vehicle in their fleet.
Lastly in the area of robotics, we announced that BMW Group has selected the new NVIDIA Isaac robotics platforms to automate their factories, utilizing logistic robots built on advanced AI computing and visualization technologies.
Turning to Data Center. Quarterly revenue was a record $1.14 billion, up 80% year-on-year and up 18% sequentially, crossing the $1 billion mark for the first time. Announced last week the A100 is the first Ampere architecture GPU. Although just announced, A100 is in full production, contributed meaningful to Q1 revenue and demand is strong. Overall data center demand was solid throughout the quarter. It was also broad based across hyperscale and vertical industry customers as well as across workloads, including training, inference and high-performance computing. We continue to have solid visibility into Q2. The A100 offers the largest leap in performance to date over our eight generations of GPUs boosting performance by up to 20 times over its predecessor. It is exceptionally versatile, serving as a universal accelerator for the most important high performance workloads, including AI training and inference as well as data analytics, scientific computing and cloud graphics.
Beyond its leap performance and versatility, the A100 introduces new elastic computing technologies that make it possible to bring right-size computing power to every job, A multi-instance GPU capability allows each A100 to be partitioned into as many as seven smaller GPU instances. Conversely multiple A100s interconnected by our third generation NVLink can operate as one giant GPU for ever larger training tasks. This makes the A100 ideal for both training and for inference. The A100 will be deployed by the world's leading cloud service providers and system builders, including Alibaba Cloud, Amazon Web Services, Baidu Cloud, Dell Technologies, Google Cloud Platform, HPE and Microsoft Azure among others. It is also getting adopted by several supercomputing centers, including the National Energy Research Scientific Computing Center and the Julich Supercomputing Centre in Germany and Argonne National Laboratory. We launched and shipped the DGX A100, our third generation DGX and the most advanced AI system in the world. The DGX A100 is configurable from one to 56 independent GPUs to deliver elastic software defined datacenter infrastructure for the most demanding workloads from AI training and inference to data analytics.
We announced two products for Edge AI, the EGX A100 for larger commercial off-the-shelf servers and EGX Jetson Xavier NX micro-edge servers. Supported by full AI optimized cloud native and secure software the EGX platform is built for AI computing at the edge. With the EGX, hospitals, retail stores, farms and factories can securely carry out real-time processing of the massive amounts of data streaming from trillions of edge sensors. NVIDIA EGX makes it possible to securely deploy and manage and update fleets of servers remotely. EGX is also ideal for the massive computational challenge of 5G networks, which we are working on with our partners like Ericsson and Mavenir.
Additionally, we announced CUDA 11 another important software harnessing the A100's performance and universatility to accelerate three of the most complex and fast-growing workloads, recommendation systems, computational AI and data science. First NVIDIA Merlin is a deep recommendator application framework that enables developers to quickly build state-of-the-art recommendation systems, leveraging our pre-trained models. With billions of users and trillions of items on the Internet deep recommendator are the critical engine powering virtually every Internet service.
Second NVIDIA Jarvis is a GPU accelerated application framework that makes it easy for developers to create, deploy, and run end-to-end real-time conversational AI applications that understand terminology unique to each company and its customers using both vision and speech. Demand for these applications are surging amid the shift to working from home, telemedicine, and remote learning. And third, in the field of data science and data analytics, we announced that we are bringing end-to-end GPU acceleration to Apache Spark, an analytics engine for big data processing that uses more than 500,000 data scientists worldwide. Native GPU acceleration for the entire Spark pipeline from extracting, transforming, and loading the data to training to inference, delivers the performance and the scale needed to finally connect the potential of big data with the power of AI. Adobe has achieved a 7 times performance improvement and a 90% cost savings in an initial test using GPU accelerated data analytics with Spark.
Our accelerated computing platform continues to gain momentum underscored by the tremendous success of GTC Digital, our annual GPU technology conference, which shifted this spring to an online format. More than 55,000 online developers in AI research registered for the online event, which includes hundreds of hours of free content from AI practitioners and industry experts who leverage NVIDIA's platforms. Our ecosystem is now 1.8 million developer strong. Times like these truly test a computing platform's metal in the utility it brings to scientists racing for solutions. Researchers around the world are deploying our GPU computing platform in the fight against COVID-19. Scientists are combining AI simulation to detect changes in pneumonia [Phonetic] cases, sequence the virus, and seek effective bio-molecular compounds for a vaccine or treatment.
The first breakthrough came from researchers at the University of Texas at Austin and National Institute of Health who used the GPU accelerated application to create the first 3D atomic scale map of the virus using NVIDIA GPUs. This was followed by researchers at Oak Ridge National Laboratory who screened 8,000 compounds to identify 77 promising drug targets using the world's fastest supercomputer Summit, which is powered by more than 27,000 NVIDIA GPUs. The V100 GPUs at Oak Ridge are in high demand as they can analyze 17 million compound protein combinations in a day. To help understand the virus spread pattern, the University of California at San Diego, researchers ported their microbiomic analysis software to GPUs in the San Diego supercomputing cluster of 500 times analysis speed up from what some people are more susceptible to the virus.
Okay, moving to the rest of the P&L. Q1 GAAP gross margins were 65.1% and non-GAAP was 65.8%, up sequentially and year-on-year primarily driven by GeForce GPU product mix and higher data center sales. Q1 GAAP operating expenses were $1.03 billion and non-GAAP operating expenses were $821 million, up 10% and 9% year-on-year respectively. Q1 GAAP EPS was $1.47, up 130% from a year earlier and non-GAAP EPS was $1.80, up 105% from a year ago. Q1 cash flow from operations was $909 million.
Before I turn to the outlook, let me make a few comments on our Mellanox acquisition. Beyond the strong strategic and cultural fit that Jensen has discussed, Mellanox has exceptionally strong financial profile. The company reported revenue of $429 million in its March quarter, accelerating to 40% year-on-year growth with GAAP and non-GAAP gross margins in the mid-to-high 60% range. We expect the acquisition to be immediately accretive to non-GAAP gross margins, non-GAAP earnings per share, and free cash flow. We aim to retain the full Mellanox team and accelerate investments in our combined road map as we jointly innovate on our shared vision for the future of accelerated computing.
With that, let me turn to the outlook of the second quarter of fiscal 2021, which includes a full quarter contribution from Mellanox. We have assumed in our outlook the potential ongoing impact from COVID-19. We expect our automotive platform sales to be down 40% on a sequential basis and ProViz to decline sequentially. In gaming, while we will likely see ongoing impact from the partial operations or closures of iCafes and retail stores, we expect that to be largely offset by a shift to e-retail channels. Overall, the precise magnitude of the impact is difficult to predict given uncertainties around the reopening of the economy. Overall, we expect second quarter revenue to be $3.65 billion plus or minus 2%. The contribution of Mellanox revenue is likely to be in the low teens percentage range of our total Q2 revenue. We are providing this breakout to help with comparability between Q1 and Q2, but going forward, will become an integrated part of our data center market platform.
GAAP and non-GAAP gross margins are expected to be 58.6% and 66% respectively, plus or minus 50 basis points. The sequential decline in GAAP gross margins primarily reflects an increase in acquisition-related costs, most of which are non-reoccurring. GAAP and non-GAAP operating expenses are expected to be approximately $1.52 billion and $1.04 billion respectively. A sequential change in GAAP operating expenses reflects an increase in stock-based compensation and acquisition related costs. GAAP and non-GAAP operating expenses for the full year are expected to be approximately $5.7 billion and $4.1 billion respectively. For the full year, stock-based compensation and acquisition related costs also influence. GAAP and non-GAAP OI&E are both expected to be an increase of approximately $50 million and $45 million respectively. GAAP and non-GAAP tax rates are both expected to be 9% plus or minus 1% excluding discrete items. Capital expenditures are expected to be approximately $225 million to $250 million. Further financial details are included in the CFO commentary and other information available on our IR website. New this quarter, we have also posted an investor presentation summarizing our results and key highlights.
In closing, let me highlight upcoming events for the financial community. Next Thursday, May 28th, we will webcast a presentation and Q&A with Jensen on our recent product announcements moderated by Evercore. We will also be at Cowen's TMT Conference on May 27th, Morgan Stanley's Cloud Secular Winners Conference on June 1st, BofA's Technology Conference on June 2nd, Needham's Fourth Automotive Technology Conference on June 3rd and NASDAQ Investor Conference on June 16th. Operator, we will now open for questions. Can you please poll for questions please.
Operator
[Operator Instructions] And your first question comes from Aaron Rakers with Wells Fargo. Please go ahead.
Aaron Rakers -- Wells Fargo -- Analyst
Yeah, thanks and congratulations on the solid quarter. Colette, I'm curious of your commentary around visibility in the data center side. That's been [Phonetic] you know, comments over the last couple of quarters, how would you characterize your visibility today relative to maybe what it was last quarter and how do we think about the visibility in the context of trends maybe into the back half of the calendar year. Thank you.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks well [Phonetic] for the question. You're correct. We have indicated a couple of quarters ago that we were starting to see improved visibility after we came out of the digestion period in the prior overall fiscal year. As we move into Q2, we still have visibility and solid visibility into our Q2 results for overall data centers. So at this time, I'd say, they are relatively about the same of what we had seen going into the Q1 period and we think that is a true indication of their excitement about our platform and most particularly our excitement regarding A100 and its launch and its additional products. Now regarding the second half of the year, as you know, we have seen broad-based growth in both the hyperscale and the vertical industries, both of them in terms -- have hit record levels in our Q1 results and we see in terms of inferencing continuing to grow as well. As well as we're also expanding in terms of edge AI. Our strong demand of the A100 products including the Delta board, but also in terms of our DGXs are just starting a initial ramp. However, we do guide only one quarter at a time. So it's still a little bit too early for us to give a true certainty in terms of the macro situation that's in front of us, but again, we feel very good about the demand for A100.
Operator
Your next question comes from Stacy Rasgon with Bernstein Research. Please go ahead.
Stacy Rasgon -- Bernstein Research -- Analyst
Hi guys, thanks for taking my questions. I first wanted to follow-up on your gaming commentary. You sort of mentioned a couple of offsets, COVID potentially still a headwind, e-tail a tailwind and maybe offsetting each other. Were you trying to suggest that those did offset completely and gaming was kind of flattish into Q2, because I know it has a typical seasonal pattern, switch [Phonetic] is typically up. I guess what were trying to say with those kind of factors and what are the kinds of things we should be thinking about when it comes to seasonality, Colette, into Q2 around that business segment?
Colette Kress -- Executive Vice President and Chief Financial Officer
So let me start and I'll see if Jensen also wants to add on to it. I think you're talking about our sequential between Q1 and Q2. Some of the --
Stacy Rasgon -- Bernstein Research -- Analyst
That's right.
Colette Kress -- Executive Vice President and Chief Financial Officer
Right, some of the pieces that we had seen related to COVID-19 in Q1 may carryover into Q2. COVID-19 in fact had an impact in terms of our retail channels as well as our iCafes. However, as we discussed, it efficiently moved to overall e-tail. We have normally been seasonally down in desktop between Q1 and Q2 and that will likely happen, but we do see the strength in terms of laptops and overall consoles as we move from Q1 to Q2. So in summary, we do expect growth sequentially between Q1 and Q2 for our overall gaming business. Now, I'll turn it over to Jensen to see if he has additional commentary.
Jensen Huang -- Founder, President and Chief Executive Officer
No, that was great. That was fantastic.
Stacy Rasgon -- Bernstein Research -- Analyst
Yeah, I guess just a follow-up on that though, if it's growing I mean -- like in prior years, we've seen it grow like very strong double digits, obviously the mix of the business was different back then, but do you think that the kind of -- I mean are we thinking kind of it's up somewhat -- you don't -- is there any chance that it could be up like on to what we've seen in terms of like typical levels in the past, like, can you give us any sense of magnitude that would be really helpful.
Colette Kress -- Executive Vice President and Chief Financial Officer
Yeah I think when we think about that sequential growth, we'll probably be in the low moving up to probably the mid-single digits in terms of -- that's what our guidance right now and we'll just have to see how the quarter goes.
Stacy Rasgon -- Bernstein Research -- Analyst
That's very helpful.
Jensen Huang -- Founder, President and Chief Executive Officer
Stacy, the thing I would add is this, I would say, I think the guidance is exactly what Colette mentioned, but if you look at the big picture, there's a few dynamics that are working really well in our favor. First, of course, is that RTX and ray tracing is just a home run. Minecraft was phenomenal. We have 33 games in the pipe that has already been announced or shipping. Just about every game developer is signed onto RTX and ray tracing and I think it's a forgone conclusion that this is the next generation. This is the way computer graphics are going to be in the future. So I think RTX is a home run.
The second, the notebooks that we created with RTX and Max-Q is just doing great. We got 100 notebooks in gaming. We have 75 notebooks designed for either mobile workstations or what we call NVIDIA Studio for designers and creators and the timing was just perfect. With everybody needing to stay at home, the ability to have a mobile gaming platform and a mobile workstation was just perfect timing and then, of course, you guys know quite well that Nintendo Switch is doing fantastic. There are three -- the Top 3 games in the world, the top games in the world today are Fortnite, Minecraft, and Animal Crossing. All three games are NVIDIA platforms and so I think we have all the dynamics working in our favor and then we just got to see how it turns out.
Stacy Rasgon -- Bernstein Research -- Analyst
Got it. That's helpful. Thank you, guys.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. Thank you.
Operator
Your next question comes from Joe Moore with Morgan Stanley.
Joe Moore -- Morgan Stanley -- Analyst
Great, thank you. I wanted to ask about the roll out of Ampere, how quickly does that roll into the various segments between hyperscale as well as on the DGX side as well as on the HPC side and is it a smooth transition, is there, you know, I remember when you launched Volta, there was a little bit of a transitional pause, just can you tell us how you see that ramping up with the different customer segments?
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah, thanks a lot Joe. So first of all, taking a step back, accelerated computing is now common sense in data centers. It wasn't the case when we first launched Volta. If you went back to Volta, Volta was the first generation that did deep learning training in a really serious way and it was really focused on training. It was focused on training and high performance computing. We didn't come until later with the inference version called T4, but over the course of the last five years, we've been accelerating workloads that are now diversifying in data centers. If you take a look at most of the hyperscalers, machine learning is now pervasive, deep learning is now pervasive. The notion of accelerating deep learning and machine learning using our GPUs is now common sense. It didn't used to be. People still saw it as something esoteric, but today, data centers all over the world expect a very significant part of their data center being accelerated with GPUs.
The number of workloads that we've accelerated since in the last five years has expanded tremendously whether it's imaging or video or conversational AI or deep recommender systems that probably unquestionably at this point, the most important machine learning model in the world. So the number of applications we now accelerate is quite diverse and so that's really -- that's contributed greatly to the ramp of Ampere. When we started to introduce Ampere to the data centers, it was very commonsensical to them that they would adopt it. They have a large amount of workload that's already accelerated by NVIDIA GPUs and as you know, our GPUs are architecturally compatible from generation to generation. We're forward compatible, we're backwards compatible. Everything that runs on T4 runs on A100, everything that runs on V100 runs on A100 and so I think the transition is going to be really, really smooth.
On the other hand, because V100 and T4 which by the way, V100 and T4 had a great quarter. It was sequentially up and then on top of that, we grew with the A100 shipment. A100 or excuse me, V100 and T4 are now quite broadly adopted in hyperscalers for their AI services, in cloud computing, and in vertical industries, as Colette mentioned earlier, which is almost roughly half of our overall HPC business all the way out to the edge, which had a great quarter and then a much smaller part, of course, you know, supercomputing is important, but it's a very small part of high performance computing, but that's also -- we also shipped A100 to supercomputing centers. So I think the general sense of it -- the summary of it is that the number of workloads breaks [Phonetic] already computing has continued to grow. The adoption of machine learning and AI in all the clouds and hyperscalers has grown. The common sense of using acceleration is now a foregone conclusion and so I think we're ramping into a very receptive market with a really fantastic product.
Joe Moore -- Morgan Stanley -- Analyst
Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah, thanks a lot, Joe.
Operator
Your next question comes from Vivek Arya with Bank of America. Please go ahead.
Vivek Arya -- Bank of America Merrill Lynch -- Analyst
Thanks for taking my question and congratulations on the strong growth and execution. Just a quick clarification, Colette, 66% kind of the new baseline for gross margin.
And then the question Jensen for you is, give us a sense for how much inference as a workload and Ampere as a product are expected to contribute. I'm just curious where you are in terms of growing in the inference and edge AI market and where are we kind of in the journey of Ampere penetration? Thank you.
Colette Kress -- Executive Vice President and Chief Financial Officer
Let me start on the first question regarding the gross margin and our gross margin as we look into Q2. We are guiding Q2 non-GAAP gross margins at 66%. This is -- would be another record gross margin quarter just as we finished a -- overall record level even as we are continuing right now to ramp our overall Ampere architecture withing that. The Q2 also incorporates Mellanox. Mellanox is -- had very similar overall margins to our overall data center margins as well. But we see this new baseline as a great transition and likely to see some changes as we go forward. However, it's still a little early to see where these gross margins will go, but we're very pleased with the overall guidance right now at 66% for Q2.
Jensen Huang -- Founder, President and Chief Executive Officer
Accelerated computing is just at the beginning of its journey. And if you look at -- if you look at -- I would characterize it as several segments. First is hyperscaler AI micro services, which is all the services that we enjoy today that has AI, whenever you shop on the web it recommends a product, when you're watching a movie it recommends a movie or recommends a song, all of those -- or recommends news or recommends a friend or recommends a website, the first 10 websites that they recommend, now all of these recommenders that are powering the Internet are all based on machine learning today. It's the reason why they're collecting so much data. The more data they can collect, the more they could predict your preference. And predicting your preference is the core to a personalized Internet. It used to be largely based on CPU approaches, but going forward it's all based on deep learning approaches. The results are much more superior and a few percentage change in preference prediction accuracy could result in tens of billions of dollars of economics. And so this is very, very big deal and the shift toward deep learning in hyperscale micro services or AI micro services is still ramping.
Second is cloud. And as you know, cloud is a $100 billion market segment of IT today, growing about 40% into $1 trillion opportunity. This -- cloud computing is the single largest IT industry transformation that we have ever seen. The two powers that is really -- the force -- the two forces that is really driving our data center business is AI and cloud computing. We're perfectly positioned to benefit from these two powerful forces. So the second is cloud computing and that journey is -- has a long ways to go.
Then the third is industrial edge. In the future -- today it's not -- it's not the case today. But the combination of IoT, 5G, industrial 5G and artificial intelligence is going to be -- is going to turn every single industry into a tech industry. And whether it's logistics or warehousing or manufacturing or farming, construction, industrial every single industry will become a tech industry. And there will be trillions of sensors and they will be connected to little micro data centers and those data centers will be in the millions, they will be distributed all over the edge. And that journey has just barely started.
We announced three very important partners in three domains and they are the lead partners that we felt that people would know, but we have several hundred partners that are working with us on edge AI. We announced Walmart for smart retail, we announced the US Postal Service, the world's largest mail sorting service and logistics service and then we announced this last quarter, BMW who is working with us to transform their factory into a robotics automated factory in the future. And so these three applications are great examples of the next phase of artificial intelligence and where Ampere is going to ramp into and that is just really at its early, early stages.
And so I think it's fair to say that we're really well positioned in the two fundamental forces of IT today, data center scale computing and artificial intelligence and the segments that it's going to make a real impact are all gigantic markets, hyperscale AI, cloud and edge AI.
Vivek Arya -- Bank of America Merrill Lynch -- Analyst
Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Thanks a lot, Vivek.
Operator
C.J. Muse with Evercore, please go ahead.
C.J. Muse -- Evercore ISI -- Analyst
Yeah. Good afternoon. Thank you for taking the question. I guess I'm going to ask two. Colette, can you help us with what you think the growth rate for Mellanox could look like in calendar '20? And then Jensen, a bigger picture question for you. And really not specific to healthcare, more broad based, but how do you think about the long-lasting impact of COVID on worldwide demand for AI? Thank you.
Colette Kress -- Executive Vice President and Chief Financial Officer
C.J., can you help me? You cut out in the middle of your sentence to me. Can you repeat the first part of it for me? Thank you.
C.J. Muse -- Evercore ISI -- Analyst
Yeah. Sorry about that. I'm curious if you could provide a little handholding on what we should think about for growth for Mellanox in calendar '20.
Colette Kress -- Executive Vice President and Chief Financial Officer
At this time it's a little early for us and as you know, we generally just give one quarter out and we're excited to bring the Mellanox team on board, so we can start beginning the future of building products together for the overall [Technical Issues] seen their overall performance over the last couple of quarters. They had a great last year, they had a great March quarter as well and we're just going to have to stay tuned to see equally with them what the second half of the year looks for them. Okay.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah, C.J. Thanks for the question. This pandemic is really quite tragic and is reshaping industries and markets. And I think it's going to be structural. I think it's going to remain and I think your question is really good because now is a good time to think about where to double down. There is a few areas that I believe are going to be structurally changed. And I think that once I said it will be very sensible.
The first is that the world's enterprise digital transformation and moving to the cloud that's going to accelerate. Every single company can't afford to rely just on on-prem IT. They have to be much more resilient. And having a hybrid cloud computing infrastructure is going to provide them the resilience they need. And so that's one. And when the world moves and accelerates into this $1 trillion IT infrastructure transformation which is now $100 billion into that journey, it's growing 40% a year, I wouldn't be surprised to see that that accelerate. And so cloud computing AI is going to accelerate because of that.
The second is the importance of creating a computational defense system. The defense systems of most nations today are based on radar and in the future our defense systems are going to detect things that are unseeable, it's going to be infectious disease. And I think every nation and government and scientific lab are now gearing up to think about what does it take to create each country that is based on computational methods. And NVIDIA an accelerated computing company. We take something that otherwise would take a year in the case of Oak Ridge and they filtered one billion compounds in a day. And that's what you need to do, you need to find a way to have an acceleration -- an accelerated computational defense system that allows you to find insight, detect early warning ASAP. And then of course that computational system has to go through the entire range from mitigation to containment to living within a monitoring. And so scientific labs are going to be gearing up, national labs are going to be gearing up.
The third part is the AI and robotics. We're going to have to have the ability to be able to do our work remotely. NVIDIA has a lot of robots that are helping us in our labs and without those robots helping us in our labs, we have a hard time getting our work done. And so we need to have -- we need to have remote autonomous capability for -- to handle all of these dangerous circumstances, to disinfect environments, to fumigate environments autonomously, to clean environments, to be able to interact with people where as little as possible in the event of an outbreak, all kinds of robotics applications are being dreamed up right now to help society forward in the case of another outbreak.
And then lastly, I think more and more people are going to work permanently from home. There is a strong movement of those companies that are going to support a larger percentage of people working from home. And when people are working from home it's going to clearly increase the single best home entertainment, which is video games. I think video games is going to represent a much larger segment of the overall entertainment budget of society. And so these are some of the trends I would say. I would say, cloud computing, AI, I would say national labs, a computational defense system, robotics and working from home are structural changes that are going to be here to stay and these dynamics are really good for us.
Operator
Your next question comes from Toshiya Hari with Goldman Sachs. Please go ahead.
Toshiya Hari -- Goldman Sachs -- Analyst
Hi guys. Good afternoon and thank you very much for taking the question. I had one for Colette and then one for Jensen as well, if I may. Colette I wanted to come back to the gross margin question. You're guiding July essentially flat sequentially, despite what I'm guessing as a better mix with non-ops coming in and automotive guided down 40% sequentially, I guess the question is what are some of the offsets that are pulling down gross margin in the current quarter? And sort of related to that, how should we be thinking about the cadence in opex going forward, given the six month pull-in that you guys talked about on the compensation side? And then one quick one for Jensen. I was hoping you could comment on the current trade landscape between the US and China. I feel like you guys shouldn't be impacted in a material way directly nor indirectly. But at the same time, given the critical role you play in scientific computing, I can sort of see a scenario where some people may claim that you guys contribute to efforts outside of the US. So you can kind of speak on that -- speak to that and that will be helpful. Thank you.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks Toshiya for your question. So regarding our gross margins in the second quarter, our second quarter guide at 66% is up sequentially from even a record level in terms of what we had in terms of Q1. This next record that we hope to achieve with our overall guidance is even with including our overall Ampere architecture. So typically when we transition to new architectures margins can somewhat be a little bit lower on the on-track potential kind of move up and trend up over time. Additionally, as you articulated, our automotive is lower, but also we're going to see growth in some of our platforms in gaming such as consoles which may offset those two.
But overall, there's nothing structural to really highlight other than our mix in business and the ramp of Ampere and its transition.
Jensen Huang -- Founder, President and Chief Executive Officer
Let's see. The trade tension, we've been living in this environment for some time, Toshiya. And as you know, the trade tension has been in the background for -- coming up on a year, probably got longer. And China's high-performance computing systems are largely based on Chinese electronics anyhow. And so -- so that's -- I think our condition won't materially change going forward.
Colette Kress -- Executive Vice President and Chief Financial Officer
So Toshiya, let me respond to your second question that you had for me, which was regarding to our opex and our decision to pull forward our overall struggle [Phonetic] into Q2. This is something that we've normally done later in the year. We felt it was prudent during the current COVID-19. Although our employees are quite safe, we just wanted to make sure that their family members also were safe and have the opportunity to have cash upfront. It is about a couple of months, about four months earlier than normal and it is incorporated in our guidance for Q2.
Operator
Your next question comes from Mark Lipacis with Jefferies. Please go ahead.
Mark Lipacis -- Jefferies -- Analyst
Hi. Thanks for taking my question. Question coming back to the A100. I am trying to understand how this kind of fits into the evolution of your solutions set over time and the evolution of the demand for the applications. Is -- I think -- I guess if I think about it going back, you had a solution which was largely training based and then you kind of introduced solutions that were targeted more inferencing and now you have a solution. It sounds to my understanding that it solves both inferencing and training efficiently. And so I guess I'm wondering is three years, five years, 10 years down the line is this part of the kind of general-purpose computing or acceleration framework that you had talked about in the past, Jensen, where Ampere is kind of like an Ampere class product. Or is this -- would you still -- should we still expect to see inferencing specific solutions in the market and the training specific solutions and then Ampere solution for a different class application? If you could provide a framework for thinking about Ampere in those context, I think that would be helpful. Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. Thanks a lot, Mark. Good question. I think the -- if you take a step back, currently in our data centers, the current setup in data centers, starting from probably all the way back six, seven years ago, but really accelerating in the last five years and then really accelerating in the last couple of years. We learned our way into it. There are three classes of workloads and they kind of came into acceleration over time.
The first class of workload that we discovered was -- the major workload was deep learning training -- deep learning training. And the ideal setup for that today, prior to Ampere or yesterday prior to Ampere is the V100 SXM with NVLink, eight GPUs on one board and that architecture is called scale up. It's like a supercomputer architecture. It's like a weather simulation architecture. It's -- if you are trying to build the largest possible computing node you can for one operating system, so scale up.
And the second -- the second thing that we learned along the way was then cloud computing started to grow because researchers around the world needed to get access to accelerated platform for developing their machine learning algorithms. And because they have a different degree of budget and they want to get into it a little bit more lightly and have the ability to scale up to larger nodes, the perfect model for that was actually a B100 PCI Express not SXM, but PCI Express that allows you to offer one GPU all the way up to many GPUs. And so that versatility B100 PCI Express, not as scalable in performance as the B100 SXMs but it was much more flexible for rentals. Cloud renting was really quite ideal. And then we started to get into inference and we're now on our seventh generation of TensorRT 7. Along the way we've been able to accelerate more and more and today we large accelerate every deep learning inference, computational graph that's out there and the ideal GPU for that was something that has the reduced precision, which is called [Indecipherable] reduced precision, not with electronics that is focused more for inference and because inference is a scale out application where you have millions of queries and each one of the queries are quite small versus scale up where you have one training job and that one training job is running for days. It could be running for days and sometimes even weeks and so scale up application is for one user that uses it for a long period of time on a very large machine. Scale out is for millions of users, each one of them have a very small query and that query could last hundreds of milliseconds where ideally you'd like to get done in hundreds of milliseconds.
And so notice I've got three different architecture in the data center today. Most data centers today has a storage server, has CPU servers, and it has scale up acceleration servers with Voltas, has scale out servers with T4s and then it has scale cloud computing flexible servers based on V100s. And so, the ability to predict workload is so hard and therefore the utilization of these systems will be spiky and so we created an architecture that allows for three things. The three characteristics of Ampere are number one, it is the greatest generational leap in history. I mean, I don't remember a generation where we increased throughput for training and inference by 20 times, it's just a gigantic leap. For training and for inference, it is a gigantic leap forward. The second, it's the first architecture that is unified. We could use the computation engine of Ampere accelerates the moment the data comes into the data center from data processing, it's called ETL, the engine, which many of you publicly know is the single most important computational engine in the world today for big data, it used to be Hadoop, but now it's Spark. Spark is used all over the world, 16,000 [Phonetic] customers. We finally have the ability to accelerate that. And then it's -- Ampere is also good for training, deep learning, machine learning, XG [Phonetic] boost as well as deep learning all the way out to inference and so we now have a unified acceleration platform for the entire workload.
And then the third thing is it's the first GPU ever, the first acceleration platform ever that's elastic. You can reconfigure it, you could configure it for either scale up or you can configure it for scale out. When you configure it for scale up, you gang a whole bunch of GPUs together using NVLink and it creates this one gigantic GPU. When you want to scale it out, that same computation node becomes 56 small GPUs and each one of those 56 small GPUs, each one of those 56 partitions, each one is more powerful than Volta. I mean it's really quite extraordinary. And so, Ampere is a breakthrough on all of these fronts for performance, for the fact that it unifies the workload and you can now have one acceleration cluster, and the number three, it's elastic. You can use it in the cloud, you can use it for inference, you can use it for training and so the versatility of Ampere is the thing that I'm most excited about and now you could have one acceleration cluster that serves all of your needs.
Mark Lipacis -- Jefferies -- Analyst
Thank you. It's very helpful.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. Thanks a lot, Mark.
Operator
Your next question comes from Timothy Arcuri with UBS. Please go ahead.
Timothy Arcuri -- UBS -- Analyst
Thanks a lot. Actually I had two, I guess Jensen, first for you. Just on the data center business, things have been very strong recently, obviously there's always concerns that customers are pulling in capex, but it sounds like you have pretty good visibility into July, but I guess last time most folks also thought that you're kind of attrition [Phonetic] was so low that you would be immune to any digestion, but that wasn't the case. I guess I'm wondering, things are different now with A100 and what not, but my question is, how do you handicap your ability to this time maybe get through any digestion on the capex side and then I guess second question, Colette, stock comp had been running like $220 million [Phonetic] a quarter and the guidance implies that it goes to like $460 million [Phonetic] a quarter. So it goes up a lot. Is that all executive retention and is that sort of the right level as you look into 2021? Thanks.
Jensen Huang -- Founder, President and Chief Executive Officer
Colette, did you want to handle that first and then I'll do the --
Colette Kress -- Executive Vice President and Chief Financial Officer
Sure. So let me help you on the overall GAAP adjustments. So the delta between our GAAP opex and our non-GAAP opex. If you look at it for the full year and what we guided, we probably have about $1.55 billion associated with GAAP level expenses. Keep in mind, there is more in there than just our stock-based compensation. We have also incorporated the accounting that we will do for the overall Mellanox and a really good portion of those costs are associated with the amortization of intangibles and also in terms of acquisition-related costs and deal fees and one-time items. So our stock-based compensation includes what we need for NVIDIA and also the onboarding of Mellanox. There is some retention with the overall onboarding of Mellanox, but for the most part, it is just working them in to the year for three quarters which is influencing the stock-based compensation.
Jensen Huang -- Founder, President and Chief Executive Officer
Tim, there are several differences between our condition then and our condition today. So the first difference is the diversity of workload we now accelerate. Back then, we were early in our inference, we're still early in our inference and most of the data center acceleration was used for deep learning and so today, the versatility spans from data processing to deep learning and the number of different types of AI models that's been trained for deep learning is growing tremendously from detecting -- from training video -- from training of models for detecting unsafe video to natural language understanding to conversational AI to now a gigantic movement toward deep recommender systems and so the number of different models that are being trained is growing, the size of the models are gigantic, recommendation systems are gigantic. They are training on models that are hundreds of -- the data size is hundreds of terabytes, hundreds of terabytes and it would take tens -- hundreds of servers to hold all of the data that is needed to train these recommender systems. And so the diversity of -- from data analytics to training all the different models to the inference of all the different models, we didn't inference recurring neural net [Phonetic] at the time, which was -- which is probably the most important model today language models, speech models are all recurring neural net [Phonetic] models and so those models were early for us at the time. So number one, is the diversity of workloads.
The second is the acceleration to cloud computing. I think that accelerated cloud computing is a movement that is going to be a multi-year, if not, a decade-long transition. From where we are today, it's only $100 billion industry -- segment of the IT industry, it's going to be $1 trillion some day and that movement is just starting. We're also much more diversified out of the clouds. At the time, cloud was largely where our acceleration went for a deep learning and today, hyperscale only represents about half and so we've diversified significantly out of cloud -- not out of cloud, but including vertical industries and a lot of that has to do with edge AI and inference and as I mentioned earlier, we're working with Walmart and BMW and USPS and that's just the tip of the iceberg and so I think the conditions are a little different and what I would say lastly is Ampere. I mean we ramped a few weeks, even though it was quite significant, it was a great ramp. The demand is fantastic. It is the best ramp we've ever had. The demand is the strongest we've ever had in data centers and we're starting the ramp of a multi-year ramp. And so -- so those are some of the differences. I think the conditions are very different.
Timothy Arcuri -- UBS -- Analyst
Thank you, Jensen.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah, thanks a lot, Tim.
Operator
Your next question comes from Harlan Sur with J. P. Morgan. Please go ahead.
Harlan Sur -- J. P. Morgan -- Analyst
Good afternoon. Thanks for taking my question. Jensen, can you [Phonetic] show the importance of networking, networking fabric and the Mellanox acquisition, right, for example, when you guys moved from virtual DGX-1 to virtual DGX-2, [Indecipherable] the GPU chipset but by adding a custom networking fabric chip and more Mellanox network interface cards, among other things you guys drove a pretty significant improvement in performance for GPU. But now when we think about scaling out compute acceleration to data center scaled implementation, how does Mellanox and Ethernet switching platforms differ from those provided by other large networking OEMs, some of whom have been your long-term partners? And then how does the Cumulus acquisition fit into the switching and networking strategy as well?
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. Great. Thanks a lot, Harlan. Appreciate the question. So DGX, you know this is our third generation DGX and it's really successful, people love it. It's the most advanced AI instrument in the world. If you're a serious AI researcher this is your instrument. And in the DGX there are eight A100 and there are nine Mellanox mix, the highest speed mix they have. And so we have a great appreciation for high-performance networking. High-performance networking and high-performance computing go hand in hand. And the reason for that is because the problems we're trying to solve no longer fit in one computer, no matter how big it is. And so it has to be distributed. And when you distribute a computational workload of such intense scale the communications overhead becomes one of its greatest bottlenecks, which is the reason why Mellanox is so valuable. This is the reason why this company is so precious and really a jewel and one of a kind. And so -- and it's not just about the link speed, it's -- not mostly, I mean, we just have a deep appreciation for software. It's a combination of architecture and software and electronics design, chip design. And that combination Mellanox is just world-class and that's the reason why they're in 60% of the world's supercomputers. That's why there in 100% of the AI supercomputers. And their understanding of a large scale distributed computing is second to none.
Now in the world of -- and I just talked about scale up and you're absolutely right. Now the question is why scale out. And the reason for that is this. This is the reason why they're doing so well. The movement toward disaggregated micro service applications where containers --micro service containers are distributed all over the data center and orchestrated so that the workload could be distributed across a very large hyperscale data center. That architecture and you probably know, the three most important applications in my estimation in the world today, number one would be Tensorflow and PyTorch, number two would be Spark and number three would be Kubernetes, you could rank it however you desire. And these three applications in the case of Kubernetes, it's a brand new type of application where the application is broken up into small pieces and orchestrated across an entire data center.
And because it's broken up into small pieces and orchestrated across the entire data center the networking between the compute nodes becomes the bottleneck again. And that's the reason why they're doing so well, by increasing the network performance by offloading the communications of the CPUs you increase the support of a data center tremendously. And so it's the reason why they had a record quarter last quarter, it's the reason why they've been going 27% per year and their stock was that, their integration into the hyperscale cloud companies there are no -- there are incredibly low latency of their link makes them really unique, even -- whether it's Ethernet or InfiniBand, in both cases. And so there -- there it's a really fantastic stack.
And then lastly Cumulus. We would like to -- we would like to innovate in this world where the world is moving away from just a CPU as a compute node. The new computing unit, a software developer is writing a piece of software that runs on the entire data center. In the future going forward, the fundamental computing unit is an entire datacenter, it's so incredible, it's just utterly incredible. You write an application, one human provide an application and it would literally activate an entire data center.
And in that world, we would like to be able to innovate from end to end, from networking storage, security, everything has to be secured in the future so that we can reduce the attack surface down to practically nothing and so networking storage, security all completely offloaded, all incredibly low latency, all incredibly high performance, and all the way to compute all the way through the switch. And then the second thing is we'd like to be able to innovate across the entire stack. You know that NVIDIA is just supremely obsessed on software stacks and the reason for that is because software creates market, you can't create new markets like we're talking about, whether it's computational healthcare or autonomous driving or robotic or conversational AI or recommender systems edge AI all of that requires software stacks. It takes software to create markets. And so our obsession about software and creating creating open platforms for the ecosystem and all of our developer partners, Cumulus plays perfectly into that. They are -- they pioneered the open networking stack and they pioneered in a lot of way, software defined data centers and so we are super super excited about the team and now we have the ability to innovate in a data center scale world from end to end and then from top to bottom the entire stack. Okay.
Harlan Sur -- J. P. Morgan -- Analyst
Thank you, Jensen.
Jensen Huang -- Founder, President and Chief Executive Officer
Hey, thanks a lot.
Operator
Your next question comes from William Stein with SunTrust. Please go ahead.
Will Stein -- SunTrust Robinson Humphrey -- Analyst
All right. Thank you for taking my question. Jensen, I'd like to focus on something you said I think it was in one of your earlier responses. You said something about a very significant part of data centers are now accelerated with GPUs. I'm sort of curious how to interpret that. If we think about sort of the evolution of compute architecture going from almost entirely let's say, racks and racks of GPUs to some future day where we have many more accelerators and maybe a much smaller number of of CPUs relative to those. Maybe you can talk to us about where we are in terms of that architectural shift and where you think it goes sort of longer term, where we are in the position of that?
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. I appreciate the question and this -- for computer architecture geeks and people who follow history you know well that in the entire history of time, there are only two computing architectures that has made it so far, which is one of them is x86 the other one is ARM in any reasonable way. And if you get a ARM computer, you get a x86 computer you could program it. And in fact, there is no such thing as an accelerated computing platform until we came along. And today we're the only computing [Indecipherable] computing platform that you could really marginally address. We are in every cloud, we are in every computer company, we're in every country, we are at every single site and we accelerate applications from computer graphics to video games to scientific computing to workstations to machine learning to robotics. This journey took 20-some-odd years. Inside our company it took 20-some odd years and we've been focused on accelerated computing since the beginning of our Company and we made a general purpose really starting with endeavor cost CG, C for graphics and then it became CUDA and we've been working on accelerated computing for quite a long time and I think at this point, it's a forgone conclusion that accelerated computing has reached the tipping point as well beyond it. The number of developers this year that we supported was almost 2 million developers around the world and it's growing what appears to be exponentially and so I think accelerated computing is now a well-established -- NVIDIA accelerated computing is well established, is common sense and people who are designing data centers expect to put accelerated computing in it.
The question is how much? How much accelerated computing do you use and what part of the date -- in your pipeline do you do it? And the big -- the gigantic breakthrough of course, we know well now, and NVIDIA is recognized as one of the three pillars that ignited the modern AI, the big bang of modern AI and the other key pillar of course is deep learning algorithm and the abundance of data. And so these three ingredients came together and people use NVIDIA accelerated computing largely for training, but over time, we expanded training to have a lot more models and as I mentioned earlier, the single most important model of machine learning today is the recommender system.
It's the most important model because it's the only way that you and I could use the Internet in any reasonable way, it is the only way that you and I could use a shopping website or a video web or a video app or a music app or a book or news or anything and so it is the engine of the Internet from the consumers' perspective. From the company's perspective, it is the engine of commerce. Without the recommender system, there is no way they could possibly make money and so their accuracy in predicting user preferences is core to everything they do. You just go up and down the list of every company and that engine is gigantic, it is just a gigantic engine and from the data processing part of it, which is the reason why we went and spent three years on Spark and RAPIDS, which made Spark possible and all the work that we did on NVLink and all that stuff was really focused on big data analytics.
The second is all of the training of the deep learning models and then inference. So the number of applications, the footprint of accelerated computing has grown tremendously and its importance has grown tremendously, because the applications are the most important applications of these companies and so I think when I mentioned, when I said that that acceleration is still growing, it is, but the major workloads, the most important workloads of the world's most important companies solidly require acceleration and so I'm looking forward to a really exciting ramp for Ampere for all of the reasons that I've just mentioned.
Operator
Your next question comes from John Pitzer with Credit Suisse. Please go ahead.
John Pitzer -- Credit Suisse -- Analyst
Yeah, hi guys. Thanks for letting me ask the question. Just two quick ones. Colette, I hate to ask something as mundane as opex, but just given the full year guide, there's sort of a lot to unpack and you talked about some of it like the raises. I mean, I think you also probably have some COVID plus or minuses in that. I think there is an extra week this year as well. And then, of course, there is Mellanox and how you're thinking about investing in that asset. I guess I'm just kind of curious, when we look at the full year guide, is there something structural going on, on opex as you try to take advantage of all these opportunities or can we use it as sort of a guidepost to how you're thinking about revenue for the back half of the year as well. How do I understand that and then Jensen, just a quick one for you, kind of makes sense to me that COVID is accelerating activity in sort of HPC and hyperscale and maybe even in certain verticals like healthcare, but in the other verticals as the sort of the shelter-in-place kind of hurt engagement and could we actually come out of Covid with some pent-up demand in those vertical markets?
Colette Kress -- Executive Vice President and Chief Financial Officer
Okay. Thanks, John for the question. Let's start from the first perspective on the overall opex for the year. We've guided the non-GAAP at approximately $4.1 billion for the year. Yes, that incorporates three full quarters of Mellanox, Mellanox and its employees, we have about close to 3,000 Mellanox employees coming on board. You are correct, we have a 53rd week in this quarter, excuse me, not this quarter, this year and that has been outlined in our SEC filings that you should expect that as well. We pulled forward a little bit our focal by several months in order to take care of our employees. And then lastly, though we are investing in our business, we see some great opportunities. You've seen some great results from our investment and there is more to do. We are hiring and investing in those businesses. So there is nothing different structurally but just this onset of Mellanox and are investing together I think we'll produce long-term great results.
Jensen Huang -- Founder, President and Chief Executive Officer
And as usual, John, you know that we're investing into the IT industry's largest opportunities: cloud computing and AI. And then after these two opportunities is edge AI. And so we're looking down the fairway with some pretty extraordinary opportunities, but as usual, we're thoughtful about the rate of investment and we're well managed and NVIDIA's leadership team are excellent managers and and you could count on us to continue to do that. Hey, Simona, what was John's question? Could you just give me one hint. I have it at the tip of my hand.
John Pitzer -- Credit Suisse -- Analyst
Just the idea of engagement levels in verticals just with shelter-in-place, has that hampered [Speech Overlap].
Jensen Huang -- Founder, President and Chief Executive Officer
Oh, yeah, right, A few -- some of the industries have been affected. We already mentioned automotive industry. The automotive industry has been grounded to a halt. Manufacturing has largely stopped and you saw that in our guidance. We expect automotive to be down 40% quarter-to-quarter, it's not going to remain that way. It's going to come back and nobody knows what level it is going to come back to and how long, but it's going to come back and there is no question in my mind that the automotive industry, they are hunkered down right now, but they will absolutely invest in the future of autonomous vehicles, they have too or they'll be extinct. It's not possible not to have autonomous capability in the future of everything that moves, not so that it could just completely drive without you, that's a nice benefit too, but mostly because of safety and comfort and just the joy of what seems like the car is reading your mind and, of course, you are still responsible for driving it, but it just seems to be coasting down the road reading your mind and helping you.
So I think the future of autonomous vehicles is a certainty. People recognize the incredible economics that the pioneer Tesla is enjoying and the industry is going to go after it. The future car companies are going to be software-defined companies and technology companies and they would love to have an economic that allows them to enjoy the installed base of their fleets and so they are going to go after it. I am certain that this is going to come back and I have every confidence its going to come back. And let's see, the energy sectors have been impacted, the retail sector has been impacted. Those aren't large industries for us, but nonetheless, they are impacted. The impact in some of the industries is accelerating their focus in robotics. Like for example, on the one hand, BMW's has obviously impacted in manufacturing, which is the reason why they're moving so rapidly toward robotics. They have to figure out a way to get robotics into their factories. The same thing with retail. You're going to see a lot more robotics support in retail, you're going to see a lot more robotics support in warehouses, in logistics, and so during this time when the market when the industry is disrupted and impacted, it allows the market leaders to really lean into investing into the future and so when they come back, they'll be coming back stronger than ever.
Operator
And your next question comes from Matt Ramsay with Cowen. Please go ahead.
Matt Ramsay -- Cowen -- Analyst
Thank you very much. Good afternoon. Two different topics. Jensen, first of all, congrats on Ampere, it's heck of a product.
Jensen Huang -- Founder, President and Chief Executive Officer
Thank you, Matt. I'm so proud of it.
Matt Ramsay -- Cowen -- Analyst
The first question is it might have been a little bit hard to talk when the deal was pending about this topic, but now that its closed, maybe you could talk a little bit about opportunities to innovate on and customize the Mellanox stack and the balance of having an industry standard. And the second one is E3 canceled, Computex moved around, at the same, there's obviously stay-at-home gaming demand. Just how you think about gaming product, launch logistics and any comments on there would be really helpful. Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah, thanks a lot, Matt. Appreciate your questions. I'll go backwards, because it's kind of cool. On the one hand, I do miss that we can't engage the developers face-to-face, it's just so much fun, GTC seeing all their work and the hundreds of papers that are presented, I learn so much each time and frankly I really enjoy the analyst meetings that we have and so there is all kinds of stuff that I miss about the physical GTC, but here's the amazing thing. We're now almost [Phonetic] 58,000 attendees. The GTC kitchen keynote, I did it from my kitchen just right behind me and the kitchen keynote has been viewed almost 4 million times and the video is incredible and so I think our reach could be quite great and so I'm not too -- we've got an amazing marketing team and we just -- we got great people, they're going to find a way to reach our gamers and whenever we launch something next, the gamers are going to be in our -- and our customers are going to be -- our end market is going to be real excited to see it. And so, I'm very confident that we're going to do just fine. Matt, what was the question before. I should never do it backwards.
Matt Ramsay -- Cowen -- Analyst
Just the industry standard versus customization of Mellanox opportunity.
Jensen Huang -- Founder, President and Chief Executive Officer
I see, OK, yeah. There is -- we worked so closely with Mellanox over the years and on the day that we announced GTC, you could see the number of products that we have working together, the product synergies are really incredible and the product synergies include a lot of software development that went in and a lot of architectural development that went in. DGX comes with [Indecipherable] as I mentioned. If you look at our data center, before we shipped DGXs to the customers, we shipped it to our own engineers and the reason for that is because every single product in our company has AI in it, from Jarvis to Metropolis to Merlin, to DRIVE, to Clara to Isaac, right, all of our products has AI in it and we're accelerating frameworks for all of the AI industry and Ampere comes with a brand new numerical format called TensorFloat-32 and TF32 is just a fantastic new numerical format and the performance is incredible and we had to get it integrated in with the industry standard frameworks and now TensorFloat comes standard with -- with TensorFloat -- with TF32 and PyTorch comes standard with TF32 and so we need our own large-scale data center and so the first customer we shipped to was ourselves and then we started shipping as quickly as we could to all of the customers.
You saw that in our data center in our supercomputer, we have 170 state-of-the-art brand new Mellanox switches and almost 1,500, 200-gigabit per second Mellanox mix and 15 kilometers of cables, fiber-optic cables and that is one of the most powerful supercomputers in the world today and it's based on Ampere and so we have a great deal of work that we did there together. We announced our first edge computer. Between us and Mellanox, in this new card we call the EGX A100 and it integrates Ampere and it integrates Mellanox's CX-6 Dx which is designed for 5G telcos and edge computing, it's incredible security and it has single root of trust and it's virtualized and so basically, the EGX A100 when you put it into a standard x86 server, turns that server into a cloud computer in a box, the entire capability of a state-of-the-art cloud, which is cloud native, its secure, it has incredible AI processing, it's now completely hyperconverged inside one box. The technology that made EGX A100 is really quite remarkable and so you could see all the different different product synergies that we have in working together. We couldn't have done Spark acceleration without the collaboration with Mellanox. They worked on this piece of networking software called UCX. We worked on NCCL, together it made possible the infrastructure for large scale distributed computing. I mean -- just the list goes on and on and on and so we -- the two teams have great chemistry, it's a great culture fit. I love working with them and right out of the chute, you saw all of the great product synergies that are made possible because of the combination.
Operator
That is all the time we have for questions. I'l turn the call back to Jensen Huang for closing remarks.
Jensen Huang -- Founder, President and Chief Executive Officer
Thank you. We had a great and busy quarter. With our announcements, we highlighted several initiatives: First, computing is moving to data center scale. Where computing and networking go hand-in-hand, the acquisition of Mellanox gives us deep expertise and scale to innovate from end-to-end. Second, AI is the most powerful technology force of our time. Our Ampere generation offers several breakthroughs. It is the largest ever generational leap, 20 times in training and inference throughput, the first unified acceleration platform for data analytics, machine learning, deep learning, training and inference, and the first elastic accelerator that can be configured for scale up applications like training to scale out applications like inference. Ampere is fast, it's universal, and it's elastic. It's going to rearchitect the modern data center. Third, we're opening large new markets with AI software application frameworks such as Clara for healthcare, DRIVE for autonomous vehicles, Isaac for robotics, Jarvis for conversational AI, Metropolis for edge IoT, Aerial for 5G and Merlin with the very important recommender systems. And then finally, we have built up multiple engines of accelerated computing growth, RTX computer graphics, artificial intelligence and data center scale computing from cloud to edge. I look forward to updating you on our progress next quarter. Thanks everybody.
Operator
[Operator Closing Remarks]
Duration: 98 minutes
Simona Jankowski -- Investor Relations
Jensen Huang -- Founder, President and Chief Executive Officer

--- Q2 2021 ---
Simona Jankowski, you may begin your conference.
Simona Jankowski -- Vice President, Investor Relations
Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the second quarter of fiscal 2021. With me on the call today from NVIDIA are Jensen Huang, president and chief executive officer; and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on NVIDIA's investor relations website.
The webcast will be available for replay until the conference call to discuss our financial results for the third quarter of fiscal 2021. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations.
These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, August 19, 2020, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. You can find the reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette. 
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, Simona. Q2 was another extraordinary quarter. The world continued to battle the COVID-19 pandemic, and most of our employees continue to work from home. But through the team's agility and dedication, we successfully combined Mellanox into NVIDIA while also delivering a very strong quarter.
Revenue was $3.87 billion, up 50% year on year, up 26% sequentially, and well ahead of our outlook. Starting with gaming. Revenue was $1.65 billion, was up 26% year on year and up 24% sequentially, significantly ahead of our expectations. The upside is broad-based across geographic regions, products, and channels.
Gaming's growth amid the pandemic highlights the emergence of a leading form of entertainment worldwide. For example, the number of daily gamers on Steam, a leading PC game online distributor, is up 25% from pre-pandemic levels. And NPD reported that U.S. consumer spending on video games grew 30% in the second calendar quarter to a record $11 billion.
NVIDIA's PCs and laptops are ideal for the millions of people who are now working, learning, and gaming at home. At the outset of the pandemic, many retail outlets were closed, and demand shifted to online channels. As the quarter progressed and the stores reopened, retail demand picked up, iCafes largely reopened, and online sales continued to thrive. Gaming laptop demand is very strong as students and professionals turn to GeForce-based systems to improve how they work, , and game from home.
We ramped over 100 new models with our OEM partners, focused on both premium and mainstream price points. In the premium laptop segment, we delivered unparalleled performance with the GeForce RTX 2080 and the 2070 SUPER GPUs InfiniBand form factors. We also brought ray tracing to gaming laptops for the first time at price points as low as $999 with the GeForce RTX 2060. In the mainstream segment, we brought the GeForce GTX to laptop price points as low as $699.
Momentum continues for our Turing architecture, which enables stunning new visual effects in games and is driving powerful upgrade cycle among gamers. Its RTX technology adds ray tracing and AI to programmable shading and has quickly redefined the new standard for computer graphics. DLSS used the AI capabilities of Turing to boost frame rates by almost 2x while generating crisp image quality. RTX support in blockbuster games continues to grow, including megahit Death Stranding, the highly anticipated Cyberpunk 2077, and the upcoming release of Watch Dogs.
These games join Minecraft and other major titles that support NVIDIA RTX ray tracing and DLSS. We're in the midst of a 21-day countdown campaign promoting a GeForce special event on September 1, with each day highlighting a year in the history of GeForce. We don't want to spoil the surprise, but we encourage you to tune in. We are very pleased with the traction of our GeForce NOW cloud gaming service, now in its second quarter of commercial availability.
GFN offers the richest content to any game streaming service through partnerships with leading digital game stores, including Valve Steam, Epic Games, and Ubisoft Uplay. GeForce NOW enables users with underpowered PC, Macs, or Android devices to access powerful GPUs to play their library of PC games in the cloud, expanding the universe of gamers that we can reach with GeForce. Just yesterday, we announced that GFN is now supported on Chromebooks, further expanding our reach into tens of millions of users. In addition to NVIDIA's own service, GFN is available or coming soon to a number of telecom partners around the world, including SoftBank and KDDI in Japan, Rostelecom, and Beeline in Russia, LG U+ in South Korea, and Taiwan Mobile.
Moving to pro viz. In Q2 was $203 million in revenue, down 30% year on year and down 34% sequentially, with declines in both mobile and desktop workstations. Sales were hurt by lower enterprise demand amid the closure of many offices around the world. Industries negatively impacted during the quarter include automotive, architectural, engineering and construction, manufacturing, media and entertainment, and oil and gas.
Initiatives by enterprises to enable remote workers drove demand for virtual and cloud-based graphic solutions. Accordingly, our Q2 vGPU bookings accelerated, increasing 60% year on year. Despite near-term challenges, we are winning new business in areas such as healthcare, including Siemens, Philips and General Electric, and the public sector. We continue to expand our market opportunity with over 50 leading design and creative applications that are NVIDIA RTX-enabled, including the latest release from Foundry, Chaos Group, and Maxon.
These applications provide faster ray tracing and accelerated performance, improving creators design workflows. The pandemic will have a lasting impact on how we work. Our revenue mix going forward will likely reflect this evolution in enterprise workforce trends with a greater focus on technologies, such as NVIDIA laptops and virtual workstations that enable remote work and virtual collaboration. Moving to automotive.
Automotive revenue was $111 million, down 47% year on year and down 28% sequentially. This was slightly better than our outlook of a 40% sequential decline as the impact of the pandemic was less pronounced than expected, with auto production volumes starting to recover after bottoming in April. Some of the decline is also due to the roll-off of legacy infotainment revenue, which remained a headwind in future quarters. In June, we announced a landmark partnership with Mercedes-Benz which, starting in 2024, will launch software-defined intelligent vehicles across an entire fleet in using end-to-end NVIDIA technology.
Mercedes will utilize NVIDIA's full technology stack, including the DRIVE AGX computer, DRIVE AV autonomous driving software, and NVIDIA's AI infrastructure, spanning from the core to the cloud. Centralizing and unifying computing in the car will make it easier to integrate and upgrade advanced software features as they are developed. With over-the-air updates, vehicles can receive the latest autonomous driving and intelligent cockpit features, increasing value and extending majority of ownership with each software upgrade. This is a transformator announcement for the automotive industry, making the turning point of traditional vehicles becoming high-performance updatable data centers on wheels.
It's also a transformative announcement for NVIDIA's evolving business model as the software content of our platforms grows, positioning us to build a recurring revenue stream. Moving to data center. Data center is diverse, consist of cloud service providers, public cloud providers, supercomputing centers, enterprises, telecom, and industrial edge. Q2 revenue was a record $1.75 billion, up 167% year on year and up 54% sequentially.
In Q2, we incorporated a full quarter of contribution from the Mellanox acquisition, which closed on April 27, the first day of our quarter. Non-ops contributed approximately 14% of company revenue and just over 30% of data center revenue. Both compute and networking within data center set a record with accelerating year on year growth. The biggest news in data center this quarter was the launch of our Ampere architecture.
We are very proud of the team's execution in launching and ramping this technological marvel, especially amid the pandemic. The A100 is the largest chip ever made with 54 billion transistors. It runs our full software stack for accelerating the most compute-intensive workloads. Our software leases include CUDA 11, the new versions of over 50 CUDA-X libraries, and a new application frameworks for major AI workloads, such as Jarvis for conversational AI and Merlin for deep recommender systems.
The A100 delivers NVIDIA's greatest generational leap ever, boosting AI performance by 20x over its predecessor. It is also our first universal accelerator, unifying AI training and inference and powering workloads, such as data analytics, scientific computing, genomics, edge video analytics, 5G services, and graphics. The first Ampere GPU, A100, has been widely adopted by all major server vendors and cloud service providers. Google Cloud Platform was the first cloud customer to bring it to market, making it the fastest GPU to come to the cloud in our history.
And just this morning, Microsoft Azure announced the availability of massively scalable AI clusters, which are based on the A100 and interconnected with 200-gigabyte-per-second Mellanox InfiniBand networking. A100 is also getting incorporated into offerings from AWS, Alibaba Cloud, Baidu Cloud and Tencent Cloud. And we announced that the A100 is going to market with more than 50 servers from leading vendors around the world, including Cisco, Dell, Hewlett Packard Enterprise, and Lenovo. Adoption of the A100 into leading server makers offerings is faster than any prior launch, with 30 systems expected this summer and over 20 more by the end of the year.
The A100 is already winning industry recognition in the latest A100 training benchmark, MLPerf 0.7, NVIDIA set 16 records, sweeping all categories for commercially available solutions in both per chip and outscale performance based on the A100. MLPerf offers the industry's first and only objective AI benchmark. Since the benchmark was introduced two years ago, NVIDIA has consistently delivered leading results and record performance for both training and inference. NVIDIA also topped the chart in the latest TOP500 list of the fastest supercomputers.
The ranking, released in June, showed that eight of the world's top 10 supercomputers use NVIDIA GPUs, NVIDIA networking, or both. They include the most powerful systems in the U.S. and Europe. NVIDIA, now combined with Mellanox, powers tow-thirds of the top 500 systems on the list compared with just less than a half for the two companies in total two years ago.
In energy efficiencies, systems using NVIDIA GPUs are pulling away from the pack. On average, they're nearly 2.8x more powerful and efficient than systems without NVIDIA GPUs, measured by gigaflops per watt. The incredible performance and efficiency of the A100 GPU is best amplified by NVIDIA's own new Selene supercomputer, which debuted as No.7 on the top 500 list and is the only top 100 systems to cross the 20 gigaflops per watt barrier. Our engineers were able to assemble Selene in less than four weeks using NVIDIA's open modular DGX SuperPOD reference architecture instead of the typical build time of months or even years.
This is the system that we will use to win the MLPerf benchmarks, and it is a reference design that's available for our customers to quickly build a world-class supercomputer. We also brought GPU acceleration to data analytics, one of the largest and fastest-growing enterprise workload. We enabled an acceleration of the entire data analytics workload pipeline for the first time with NVIDIA's GPUs and software stack in the latest version of Apache Spark released in June. Spark is the world's leading data analytics platform used by more than 500,000 data scientists and 16,000 enterprises worldwide.
And we have two major milestones to share. We have now shipped a cumulative total of 1 billion CUDA GPUs, and the total number of developers in the NVIDIA ecosystem just reached 2 million. It took over a decade to reach the first million and less than 2 years to reach the second million. Mellanox has fantastic results across the board in its first quarter as part of NVIDIA.
Mellanox revenue growth accelerated with strength across Ethernet and InfiniBand products. Our Ethernet shipments reached a new record. Major hyperscale build drove the upside in the quarter as growth in cloud computing and AI is fueling increased demand for high-performance networking. Mellanox networking was a critical part of several of our major new product introductions this quarter.
These include the DGX AI system, the DGX SuperPOD clusters for our Selene supercomputer, and the EGX Edge AI platform. We also launched the Mellanox ConnectX-6 Ethernet NIC, the 11th generation product of the ConnectX family and is designed to meet the needs of modern cloud and hyperscale data centers, where 25, 50, and 100 gigabyte per second is becoming the standard. We expanded our switch networking capabilities with the addition of Cumulus Networks, a privately held network software company that we purposed in June. Cumulus augments our Mellanox acquisition in building our open modern data center.
The combination of NVIDIA accelerated computing, Mellanox networking, and Cumulus software enables data centers that are accelerated, disaggregated, and software-defined to meet the exponential growth in AI, cloud, and high-performance computing. Moving to the rest of the P&L. Q2 GAAP gross margin was 58.8%, and non-GAAP gross margin was 66%. GAAP gross margin declined year on year and sequentially due to costs associated with the Mellanox acquisition.
Non-GAAP gross margins increased by almost 6 points year on year, reflecting a shift in product mix with higher data center sales and lower automotive sales. Q2 GAAP operating expenses were $1.62 billion, and non-GAAP operating expenses were $1.04 billion, up 67% and 38% from a year ago, respectively. Q2 GAAP EPS was $0.99, up 10% from a year earlier. Non-GAAP EPS was $2.18, up 76% from the year ago.
Q2 cash flow from operations was $1.57 billion. With that, let me turn to the outlook for the third quarter of fiscal 2021. We expect revenue to be $4.4 billion, plus or minus 2%. With that, we expect gaming to be up just over 25% sequentially, with data center to be up in the low to mid-single digits sequentially.
We expect both pro viz and auto to be at similar levels out in Q2. GAAP and non-GAAP gross margins are expected to be 62.5% and 65.5%, respectively, plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $1.54 billion and $1.09 billion, respectively. Full year GAAP and non-GAAP opex is tracking in line with our outlook of $5.7 billion and $4.1 billion, respectively.
GAAP and non-GAAP OI&E are both expected to be an expense of approximately $55 million. GAAP and non-GAAP tax rates are both expected to be 8%, plus or minus 1%, excluding discrete items. Capital expenditures are expected to be approximately $225 million to $250 million. Further financial details are included in the CFO commentary and other information available on our IR website.
In closing, let me highlight upcoming events for the financial community. We will be at the BMO Virtual Technology Summit on August 25, Citi's 2020 Global Technology Conference on September 9, Deutsche Bank's Technology Conference on September 14, and the Evercore's virtual memo forum, The Future of Mobility, on September 21. We will also host a financial analyst Q&A with Jensen on October 5th as part of our next virtual GTC. Our earnings call to discuss our third quarter's results is scheduled for Wednesday, November 18.
We will now open the call for questions. Operator, would you please poll for questions? Thank you.
Operator
Certainly. [Operator instructions] Your first question comes from the line of Vivek Arya with Bank of America. Your line is open.
Vivek Arya -- Bank of America Merrill Lynch -- Analyst
Thanks for taking my question, and congratulations on the strong growth and execution. Jensen, I'm wondering how much of the strength that you're seeing in gaming and data center is, you know, maybe more temporary because COVID or, you know, some customer pull-ins in the data center or so forth? And how much of it is more structural and more secular that can continue even once we get into, hopefully, you know, sooner rather than later, into a more normalized period for the industry?
Jensen Huang -- President and Chief Executive Officer
Yeah. Vivek, thank you. So first of all, we didn't see pull-ins, and we're in the beginning of our brand-new product cycle with Ampere, and so the vast majority of the data center growth came from that. The gaming industry, they -- with all that's happening around the world, and it's really unfortunate, but it's made gaming the largest entertainment medium in the world.
More than ever, people are spending time digitally, spending on time -- spending their time in video games. The thing that people haven't realized about video games is that it's not just the game itself anymore. The variety of different ways that you can play, whether you can hang out with your friends in Fortnite, go to a concert in Fortnite, building virtual worlds in Minecraft, you're spending time with your friends, you're using it to create and to realize your imaginations. People are using it for broadcast, for sharing ideas and techniques with other people.
And so -- and then of course, it's just an incredibly fun way to spend time, even by consumption of the video -- of a video game. And so, there's just so much that you could do with video games now. And I think that this way of enjoying entertainment digitally has been accelerated as a result of the pandemic, but I don't think it's going to return. Video game adoption has been going up over time and pretty steadily.
And PC is now the single largest entertainment platform -- is the largest gaming platform. And GeForce is now the largest gaming platform in the world. And as I mentioned, it's not just about gaming. There's just so many different ways that you could enjoy games.
With data center, the things that -- the structural change that's happening in data center are coupled with different dynamics that are happening at the same time. The first dynamic, of course, is the movement to the cloud. The way that a cloud data center is built and the way that an enterprise data center or a cluster is built is fundamentally different. And it's really, really beneficial to have the ability to accelerate applications that cloud service providers would like to offer, which is basically everything.
And we know that one of the most important applications of today is artificial intelligence. It's a type of software that really wants acceleration. And NVIDIA's GPU acceleration is the perfect medium, perfect platform for it. And then the last reason about the data center is the -- this architectural change from hosting applications to hosting services that's driving this new type of architecture called disaggregation versus hyper converged.
And the original name of hyperscalers is a large data center of a whole bunch of hyperconverged computers. But the computers of today are really disaggregated. A single application service could be running on multiple servers at the same time, which generates a ton of east-west traffic, and a lot of it is artificial intelligence neuro network models. And so, because of this type of architecture, two components, two types of technologies are really important to the future of cloud.
One of them, as I mentioned, was -- is acceleration, and our GPU is ideal for it. And then the other one is high-speed networking. And the reason for that is because the server is now disaggregated, the application is fractionalized and broken up into this -- in a bunch of small pieces that are running across the data center. And whenever an application needs to send parts of the answer to another server for the microservice to run.
That transition is called east-west traffic. And the most important thing you could possibly do for yourself is to buy really high-speed, low-latency networking. And that's what Mellanox is fantastic at. And so, we find ourselves really in this perfect condition where the future is going to be more virtual, more digital, and that's why -- that's the reason why GeForce is so successful.
And then we find ourselves in a world where the future is going to be more autonomous and more AI-driven. And that's the benefit of our GPUs. And then, lastly, cloud microservice transactions really benefit high-speed networking, and that's where Mellanox comes in. And so, I think that this is -- the dynamics that I'm describing are permanent, and it's just been accelerated to the present, you know, because of everything that's happening to us.
But this is the future, and it's not -- there's no going back. It's -- and we just found everything accelerated.
Operator
Your next question comes from the line of Timothy Arcuri with UBS. Your line is open.
Timothy Arcuri -- UBS -- Analyst
Thanks a lot. Jensen, I guess I had a question on both architecture and also manufacturing. And I think on the manufacturing side, you've been, you know, radical on that for some time. And when you've been asked in the past about moving to more of a tiled or chiplet approach, you sort of made light of that.
But the CPU guys are clearly picking that approach. So, I guess, the question is why do you think you won't have to make a similar move? And then on the side of architecture, the theme of Hot Chips this week was really how compute demand is far outstripping computing power? And then we see this, you know, talk about you and ARM. So, I guess can you talk about whether GPU is the future and, you know, maybe the broader opportunity to integrate CPU and GPU? Thanks.
Jensen Huang -- President and Chief Executive Officer
Yeah. We push architecture really hard. And the way we push architecture is we start from the system. But we believe that the future computer company is a data center-scale company.
The computing unit is no longer a microprocessor or even a server or even a cluster. The computing unit is an entire data center now. And as I was explaining it to Vivek just now that a microservice that we're enjoying hundreds of billions of transactions a day, those are broken up into a whole bunch of microservices that are running across the entire data center. And so, the data center is running -- the entire data center is running an application.
I mean, that's pretty remarkable thing. And that happened in the last several years. We were ahead of this trend, and we recognized that, you know, as a computing company, we have to be a data center-scale company, and we architect from that [Inaudible]. If you look at our architecture, we were the first in the world to create the concept of an NVLink, with eight processors being fully synchronized across the computing node, and we created the DGX.
We recognize the importance of high-speed networking and low-latency networking, and that's why we bought Mellanox. And the amount of software that we invented along the way to make it possible for low-latency communications, whether it's GPUDirect or, recently, the invention of GPUDirect Storage, all of that technology was inspired by the idea that you have to think about the data center all in one holistic way. And then in the last -- in this current generation with Ampere, we invented the world's first multi-instance GPU. We invented the world's first multi-instance GPU, which means that our Ampere GPU could simultaneously be one GPU or, with NVlink, eight GPUs combined, working together, So you could – you know, GPUs are working harmoniously together.
Or each one of the GPUs could fractionalize itself, if you don't need that much GPU working on your workload, fractionalize into a multi-GPU instance, we call the MIG, a little tiny instance. And each one of those tiny instances are more powerful and more performant than our entire Volta GPU lap time. And so, whether you like to fractionalize the GPU, which happens oftentimes, create a larger GPU using NVLink, or create an even larger GPU, the size of DGX POD, connected together with high-speed, low-latency networking with Mellanox, we could architect it any way you'd like. You made a comment about -- you asked a question about ARM.
We've been a long-term partner of ARM, and we use ARM in a whole bunch of applications. And whether it's autonomous driving or a robotics application, the Nintendo Switch, console business that we're in. And then, recently, we brought CUDA to ARM and to bring accelerated computing to ARM. And so, we worked with the ARM team very closely.
They're really great guys. And one of the specials about the ARM architecture that you know very well is that it's incredibly energy-efficient. And because it's energy-efficient, it has the headroom to scale into very high-performance levels over time. And so, anyways, we love working with the ARM guys.
Operator
Your next question comes from the line of Aaron Rakers with Wells Fargo. Your line is open.
Aaron Rakers -- Wells Fargo Securities -- Analyst
Yeah. Thanks for taking the question. Congratulations on the quarter. Just building on some prior questions.
The first one, I was just curious if you could help us appreciate kind of the installed base of the gaming GPU business, you know, relative to where we're at the Turing upgrade cycle, you know, what do we see still on prior generations, be it Pascal or before? And then secondly, I was wondering, you know, Colette, could you just give me a kind of updated commentary or views on visibility in the data center business? How that – you know, how has that changed over the last three months? What does that look like as you look through the back half of the calendar year? Thank you.
Jensen Huang -- President and Chief Executive Officer
Yeah. Thanks a lot, Aaron. We are -- we're still in the ramping of the RTX generation. Turing, Turing the current generation that we're in, is the world's first ray tracing GPU.
And it fuses -- the RTX technology fuses three fundamental technologies: the programmable shader that we introduced a long time ago that revolutionized computer graphics, and we added two new technologies. One technology is a ray tracing acceleration core that makes the tracing of rays and looking for intersections between the ray and the scene -- objects in scene super, super fast. And that's -- it's a complicated problem. It's a super complicated problem.
We want it to be running concurrently to shading so that the ray traversal and the shading of the pixels could be done independently and concurrently. The second thing is we invented this technology to bring AI, artificial intelligence, using this new type of algorithm called deep learning to computer graphics. And one example of its capability is the algorithm we introduced called DLSS, Deep Learning Super Sampling, which allows us to essentially synthesize by learning from previous examples, essentially learning from previous examples of images and remembering it, remembering what beautiful images look like so that when you take a low-resolution image, and you run it through the deep neural network, it synthesizes a high-resolution image that's really, really beautiful. And people have commented that it's even more beautiful than native rendered images at the native resolution.
And the benefit is not only is it beautiful, it's also super fast. We essentially nearly doubled the performance of RTX as a result of doing that. So, you can have the benefit of ray tracing as well as very high resolution and very high speed. And so that's called RTX.
And Turing is probably not even close, not even one-third of the total installed base of all of our GeForce GPUS, which is, as you know, the single-largest installed base of gaming platforms in the world. And so, we support this large installed base, and we're in the process of bringing them to the future with RTX. And now, with the new console generation coming, every single game developer on the planet is going to be doing ray tracing, and they're going to be creating much, much richer content. And because of multi-platform, cross-platform play, and because of the size of the gaming platform, PC gaming platform, it's really important that these game developers bring the latest generation content to PCs, which is great for us.
Aaron Rakers -- Wells Fargo Securities -- Analyst
And then on the data center visibility?
Colette Kress -- Executive Vice President and Chief Financial Officer
Yeah. Let me see if I can answer this one for you. Yes, we have been talking about our visibility of data center. And as you've seen in our Q2 results, you can see that our overall adoption of the NVIDIA computing portfolio has accelerated quite nicely.
But keep in mind, we're still really early in the product cycle. A100 is ramping. It's ramping very strong into our existing installed bases but also into new markets. Right now, A100 probably represents less than a quarter of our data center revenues.
So we still have a lot to grow. We have good visibility looking into Q3 with our hyperscales. We have a little bit more of a mixed outlook in terms of our vertical industries, given a lot of the uncertainty in the market and in terms of the overall economy. On-premises are challenged because of the overall COVID.
But remember, industries are quickly and continuing to adopt and move to the overall cloud. But overall, we do expect a very strong Q3.
Operator
Your next question comes from the line of C.J. Muse with Evercore ISI. Your line is open.
C.J. Muse -- Evercore ISI -- Analyst
Yeah, hi. Thank you for taking the questions. I guess two questions. If I look at your outstanding inventory purchase obligations, grew 17% sequentially.
Is that – you know, as you prepare for the September 1 launch? And can you kind of comment on gaming visibility into the back half of the year? And then the second question, Jensen, you know, I know you're very focused on platforms and driving recurring revenues. I would love to hear if there's any, you know, particular platforms over the last three months where you've made real headway or get you excited, whether Jarvis, Merlin, Spark or whatever. Thank you.
Jensen Huang -- President and Chief Executive Officer
Yeah. Thanks so much, C.J. We're expecting a really strong second half for gaming. I think this may very well be one of the best gaming seasons ever.
And the reason for that is because PC gaming has become such a large format. The combination of amazing games like Fortnite and Minecraft and because of the way people game now, their gaming and their e-sporting, even F1 is an e-sport now, they're hanging out with friends. They're using it to create other content. They're using, you know, game captures, create art.
They're sharing it with the community. It's a broadcast medium. The number of different ways you could game has just really, really exploded. And it works on PCs because all the things that I described, you know, require cameras or keyboards or streaming systems and -- but it requires an open system that is multitasking.
And so, the PC has just become such a large platform for gaming. And the second thing is that RTX, it's a home run. You know, we really raised the bar with computer graphics, and the games are so beautiful, and it's really, really the next level. It's not been this amazing since we introduced programmable shaders about 15 years ago.
And so, for the last 15 years, we've been making programmable shaders better and better and better, and it has been getting better. But there's never been a giant leap like this. And RTX brought both artificial intelligence as well as ray tracing to PC gaming. And then the third factor is the console launch.
There's -- people are really -- the game developers are really gearing up for a big leap. And, you know, because of the gaming -- because how vibrant the gaming market is right now and how many people around the world is depending on gaming at home, I think it's going to be the most amazing season ever. We're already seeing amazing numbers from our console partner, Nintendo. Switch has -- about to sell more than Super Nintendo, more than all the Famicom.
I mean -- which was one of the best gaming consoles of all time. I mean, they're on their way to make Switch the most successful gaming platform of all time. And so, I'm super excited for them. And so, I think it's going to be quite a huge second half of the year.
Operator
Your next question comes from the line of Toshiya Hari of Goldman Sachs. Your line is open.
Jensen Huang -- President and Chief Executive Officer
Colette, I felt like I didn't -- I missed C.J.'s second question. Can we jump on and answer it?
Colette Kress -- Executive Vice President and Chief Financial Officer
I think your -- I think the question was regarding our inventory purchases on that piece. Is that the part that you're referring to?
Jensen Huang -- President and Chief Executive Officer
Yes. That's the one. Yes.
Colette Kress -- Executive Vice President and Chief Financial Officer
Yeah. Keep in mind, C.J., that when you think about the complexity of the products that we are building, we have extremely long lead times, both in terms of what we produce for the data center, our full systems that we need to do, as well as what you are seeing now between the sequential growth between Q2 and Q3 for overall gaming. So, all of that is in preparation for the second half. Nothing unusual about it other than, yes, we've got to hit those revenue numbers that are in our Q3 guidance.
C.J. Muse -- Evercore ISI -- Analyst
OK.
Operator
Your next question comes from the line of Toshiya Hari with Goldman and Sachs. Your line is open.
Toshiya Hari -- Goldman Sachs -- Analyst
Hi. Good afternoon, and thank you so much for taking the question. I had one for Jensen and another one for Colette. Just following up on the data center business.
As you probably know, quite a few of your peers have been talking about potential digestion of capacity on the part of your hyperscale customers over the next, call it, six to 12 months. Curious, is that something that you think about, worry about in your data center business? Or do you have enough idiosyncratic growth drivers like the A100 ramp? And I guess, the breadth that you've built within your data center business across compute and networking, are those enough for you to buck the trend within data center over the next six to 12 months? And then the second one for Colette, just on gross margins. You're guiding October-quarter gross margins down 50 basis points sequentially. Based on the color that you provided for the individual segments, it looks like mix remains pretty positive.
So just curious what's driving the marginal decline in gross margins in the October quarter. Thank you.
Jensen Huang -- President and Chief Executive Officer
Yeah. Thank you. So -- and thanks for the question. The -- our data center trend is really tied to a few factors.
One is the proliferation of using deep learning and artificial intelligence and all the services are -- that are in -- by the cloud service providers. And I think it's fair to say that over the last several years, the number of breakthroughs in artificial intelligence has been really terrific. And we're seeing anywhere from 10x times -- 10x more computational requirement each year to more than that. And so, in the last three years, we've seen somewhere between 1,000 to 3,000x increase in the size of models, the computational requirement necessary to create these AI models and to deploy these AI models.
And so, the No.1 trend that we are -- we're probably indexed to is the breakthroughs of AI and the usefulness of AI and how people are using it. And one of the -- and I remember C.J.'s question now, and I'll answer this along with that. One of the things that we look for and you should look for is how -- what kind of breakthroughs are based on deep learning and based on AI that these services all demand. And there are three big ones, just gigantic one.
Of course, one of them is natural language understanding. The ability to take a very complicated text and use deep learning to create essentially a dimension reduction, it's called deep embedding, dimension reduction on that body of text so that you could use that vector as a way to teach a recommender system, which is the second major breakthrough, the recommender system, how to predict and make a recommendation to somebody. Recommendation on ads and videos. And there are trillions of videos on the web.
You need ways to recommend them, both the news and just the amount of information that is going to -- that is in true dynamic form require these recommenders to be instantaneous. And so, the first one is natural language understanding. The second one is the recommender system, gigantic breakthroughs in the last several years. And the third is conversational AI.
I mean, we're going to have conversational engines that are just super clever. And they can predict what you're about to ask. They're going to predict the right answer for you, make recommendations to you based on the three pillars that I just described. And I haven't even started talking about robotics, the breakthroughs that are happening there with all the factories that need to automate.
And breakthroughs that we're seeing in self-driving cars, the models there are really improving fast. And so, the answer to you, Toshiya, and C.J. are kind of similar, that on the first one, we're indexed to AI. The second, we're indexed to breakthroughs of AI.
So that it can continue to consume more and more capability and more technology. And then the third thing that we're indexed to is the movement of workloads to the cloud. It is now possible to do rendering in the cloud, remote graphics workstations in the cloud. And NVIDIA virtual workstations is in every single cloud.
You could do big data analytics in the cloud. And these applications, I've just given you a few applications where you can do scientific computing in the cloud. These applications all have fundamentally different computing architectures. NVIDIA is the only accelerated architecture that allows you to do microservices for conversational AI and other types of AI applications to scale up applications like high-performance computing, training, big data analytics to virtualize applications like workstations.
Our platform is universal. And these three facts that I just described are supremely complex, virtualized, microservices-based, and scale-up-based. And so, these – bare-metal scale-up. And these are complicated, and it's one of the reasons why we bought Mellanox because they're at the core and at the intersection of all of that.
The storage, the networking, the security, the virtualization, they're at the intersection of all of that. And I just described three dynamics that are very, very powerful and are at the early stages yet. And so those are the things that we're really indexed to. And then lastly, when somebody adopts -- when we introduce a new platform like Ampere, we're in the beginning of a multiyear product cycle, Ampere is such a gigantic breakthrough.
It's the first universal GPU we ever created. It is both able to scale up as well as scale out, scale up as in multi GPUs, scale out is fractionalization, multi-instance GPUs. And it's -- it reduced -- it saves money, tremendous amount of money for people who use it. It speeds up their application.
It reduces their TCO. Their TCO value just goes through the roof. And so, we're in the beginning of this multiyear cycle and the enthusiasm has been fantastic. This is the fastest ramp we've ever had.
And so, we're going to keep on racing through the second half.
Colette Kress -- Executive Vice President and Chief Financial Officer
OK. And, Toshiya, you asked a question regarding our guidance going forward regarding gross margin. And within our Q3 guidance, we have just a small decline in our gross margin from Q2. Most of that is really associated with mix, but also a little bit in terms of the ramping of our new Ampere architecture products that we have.
So, keep in mind, our data center will likely be a lower percentage of total revenue, given the strong overall gaming growth that we expect between Q2 and Q3. Within that gaming growth, keep in mind, consoles are also included, which will continue to be below our company totals average gross margin, and that is expected to be up strongly quarter over quarter for our overall console shipments. We're going to be ramping those new architectures over time when we have the ability to expand our gross margin as Ampere GPUs mature, too.
Operator
Your next question comes from the line of Stacy Rasgon with Bernstein Research. Your line is open.
Stacy Rasgon -- Bernstein Research -- Analyst
Hi, guys. Thanks for taking my questions. I wanted to dig into data center a little bit. This is a question for Colette.
So, in the quarter, ex Mellanox, data center was up, core data center, maybe 6%, 7%. The guide looks to be roughly similar to that into Q3. Can you talk to us a little bit about what's driving the trajectory? Are you more demand- or more supply limited at this point? What does your supply situation look like? And what are the lead times especially on the A100 products for data center look like at this point? Like if you have more capacity available, do you think you'd have like a stronger trajectory than you have right now?
Colette Kress -- Executive Vice President and Chief Financial Officer
Yeah. Stacy, so thanks for the question. Let me first start on our Q3 outlook and what we're seeing. And when we think about our demand and our supply, we're very comfortable with the supply that we have.
Keep in mind, our products are quite complex, and a lot of our time is spent in terms of procuring every aspect of that supply over multiple quarters previously. So that's how we work. But we are very confident with the overall supply that we have across the board in data center. Keep in mind that it's not just A100.
We are continuing to sell V100, T4. And we're also bringing new versions of the A100 coming to overall market. So, I hope that helps you understand our statements on where are we at in terms of the Q3 guidance. We'll see if Jensen wants to add a little bit more to that.
Jensen Huang -- President and Chief Executive Officer
Well, when we're ramping, we sure love to have more and sooner. And -- but this is our plan, and we're executing to the plan. It is a very complicated product, as Colette mentioned. It is the most [Inaudible].
Stacy Rasgon -- Bernstein Research -- Analyst
Got it. Got it. And just a quick follow-up. Within the data center guidance, how do you think about like the core data center sequential growth versus Mellanox?
Colette Kress -- Executive Vice President and Chief Financial Officer
Yeah. So, in terms of moving from Q2 to Q3, we believe that most of the actual growth that we will receive in that single -- low single-digit to mid-single-digit growth will likely stem from NVIDIA compute will be the largest driver of that.
Operator
Your next question comes from the line of Joseph Moore with Morgan Stanley. Your line is open.
Joseph Moore -- Morgan Stanley -- Analyst
Great. Thank you. I wonder if I could ask a longer-term question about the -- how you guys see the importance of process technology. There's been a lot of discussion around that in the CPU domain.
But you guys haven't really felt the need to be first on seven-nanometer, and you've done very well. Just how important do you think it is to be early in the new process node? And how does that factor into the cycle of innovation at NVIDIA?
Jensen Huang -- President and Chief Executive Officer
Yeah. First of all, thanks, Joe. The process technology is a lot more complex than a number. I think people have simplified it down to almost a ridiculous level, right? And so, process technology, we have a really awesome process engineering team.
World-class. Everybody will recognize that it's absolutely world-class. And we work with the foundries, we work with TSMC really closely, to make sure that we engineer transistors that are ideal for us and we engineer metallization systems that's ideal for us. It's a complicated thing, and we do it at high part.
Then the second part of it is where architecture, where the process technology and the rest of the design process, the architecture of the chip, and the final analysis, what NVIDIA paid for, is architecture, not procurement of transistors. We're paid for architecture. And there's a vast difference between our architecture and the second-best architecture and the rest of the architectures. The difference is incredible.
We are easily twice the energy efficiency all the time, irrespective of the number of the -- in the transistor side. And so, it must be more complicated than that. And so, we put a lot of energy into that. And then the last thing I would say is that going forward, it's really about data center-scale computing.
Going forward, you optimize at the data center scale. And the reason why I know this for a fact is because if you're a software engineer, you would be sitting at home right now and you will write a piece of software that runs on the entire data center in the cloud. You have no idea what's underneath it, nor do you care. And so, what you really want is to make sure that, that data center is as high throughput as possible.
There are a lot of code in there. And so, what NVIDIA has decided to do over the years is to take our game to a new level. Of course, we start with building the world's best processors, and we use the world's best foundries, and we partnered them very closely to engineer the best process for us. We partner with the best packaging companies to create the world's best packaging.
We're the world's first user of cobots. And whether it's -- I think we're -- I'm pretty sure we're still the highest volume by far of 2.5D and 3D packaging. And so, we start from a great chip. We start from a great chip, but we don't end there.
That's just the beginning for us. Now we take this thing all the way through systems, the system software, algorithms, networking, all the way up to the entire data center. And the difference is absolutely shocking. You know, we built our data center, Selene, and it took us four weeks.
We put up Selene in four weeks' time. It is the seventh-fastest supercomputer in the world, one of the fastest AI supercomputers in the world. It's the most energy-efficient supercomputer in the world, and it broke every single record in MLPerf. And that kind of shows you something about the scale that we work and the complexity of the work that we do.
And this is our -- the future. It's for -- the future is about data centers.
Operator
We have no further questions at this time. Jensen Huang, I turn the call back over to you.
Jensen Huang -- President and Chief Executive Officer
Thank you. The accelerated computing model we pioneered has clearly passed the tipping point. Adopting of NVIDIA computing is accelerating. On this foundation and leveraging one architecture, we have transformed our company in three dimensions.
First, NVIDIA is a full-stack computing platform company, offering the world's most dynamic industries, the chips systems, software and libraries like NVIDIA AI to tackle their most pressing challenges. NVIDIA -- second, NVIDIA is a data center-scale company with capabilities to architect, build and operate the most advanced data centers. The data center is the new computing unit. With this capability, we can create modern data center architectures that are computer maker partners, and then scale out to the world's industry.
Third, NVIDIA is a software-defined company today, with rich software content like GeForce NOW, NVIDIA virtual workstation in the cloud, NVIDIA AI and NVIDIA Drive that will add recurring software revenue to our business model. In the coming years, AI will revolutionize software. Robotics will automate machines, and the virtual and physical worlds will become increasingly integrated through VR and AR. Industry advancements will accelerate, and NVIDIA-accelerated computing will play an important role.

--- Q3 2021 ---
Simona Jankowski, you may begin your conference.
Simona Jankowski -- Investor Relations
Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the third quarter of fiscal 2022. With me today from NVIDIA are Jensen Huang, President and Chief Executive Officer; and Colette Kress, Executive Vice President and Chief Financial Officer.
I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the fourth quarter and fiscal year 2022.
The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent.
During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, November 17, 2021, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website.
With that, let me turn the call over to Colette.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, Simona. Q3 was an outstanding quarter with revenue of $7.1 billion and year-on-year growth of 50%. We set records for total revenue as well as for Gaming, Data Center and Professional Visualization.
Starting with Gaming. Revenue of $3.2 billion was up 5% sequentially and up 42% from a year earlier. Demand was strong across the board. While we continued to increase desktop GPU supply, we believe channel inventories remain low. Laptop GPUs also posted strong year-on-year growth, led by increased demand for high-end RTX laptops. NVIDIA RTX technology is driving our biggest ever refresh cycle with gamers, and continues to expand our base with creators.
RTX introduced groundbreaking real-time ray tracing and AI-enabled super resolution capabilities, which are getting adopted at an accelerating pace. More than 200 games and applications now supports NVIDIA RTX, including 125 with NVIDIA DLSS. This quarter alone, 45 new games shipped with DLSS. And NVIDIA Reflex Latency Reducing Technology is in top esports titles, including Valorant, Fortnite, Apex Legends and Overwatch. In addition, the Reflex ecosystem continues to grow with Reflex technology now integrated in almost 50 gaming peripherals.
NVIDIA studio for creators keeps expanding. Last month at the Adobe MAX Creativity Conference, Adobe announced two powerful AI features for Adobe Lightroom and the Lightroom Classic, accelerated by NVIDIA RTX GPUs. In addition, several of our partners launched new studio systems, including Microsoft, HP and ASUS. We estimate that a quarter of our installed base has adopted RTX GPUs. Looking ahead, we expect continued upgrades as well as growth from NVIDIA GeForce users, given rapidly expanding RTX support and the growing popularity of gaming, esports, content creation and streaming.
Our GPUs are capable of crypto mining, but we don't have visibility into how much this impacts our overall GPU demand. In Q3, nearly all of our Ampere architecture gaming desktop GPU shipments were lite hash rate to help steer GeForce supply to gamers.
Crypto mining processor revenue was $105 million, which is included in our OEM and other. Our cloud gaming service, GeForce Now, has two major achievements this quarter. First, Electronic Arts brought more of its hit games to the server. And second, we announced the new GeForce Now RTX 3080 membership tier, priced at less than $100 for six months. GeForce Now membership has more than doubled in this last year to over 14 million gamers for streaming content from 30 data centers in more than 80 countries.
Moving to Pro Visualization. Q3 revenue of $577 million was up 11% sequentially and up 144% from the year ago quarter. The sequential rise was led by mobile workstations with desktop workstations also growing, as enterprises deployed systems to support hybrid work environment. Building on the strong initial ramp in Q2, Ampere architecture sales continue to grow, leading verticals, including media and entertainment, healthcare, public sector and automotive.
Last week, we announced general availability of Omniverse Enterprise, a platform for simulating physically accurate 3D world and digital twins. Initial market reception to Omniverse has been incredible. Professionals at over 700 companies are evaluating the platform, including BMW, Ericsson, Lockheed Martin and Sony Pictures. More than 70,000 individual creators have downloaded Omniverse since the open beta launch in December. There are approximately 40 million 3D designers in the global market.
Moving to Automotive. Q3 revenue of $135 million declined 11% sequentially and increased 8% from the year ago quarter. The sequential decline was primarily driven by AI cockpit revenue, which has negatively been impacted by automotive manufacturers supply constraints. We announced that self-driving truck start-up, Kodiak Robotics; auto maker, Lotus; autonomous bus manufacturers, QCraft; and EV start-up, WM Motor, have adopted NVIDIA DRIVE Orin platform for their next-generation vehicles. They join a large and rapidly growing list of companies adopting and developing on NVIDIA DRIVE, including auto OEMs, Tier 1 suppliers, NAVs, trucking companies, mobile taxis and software start-ups.
Moving to Data Center. Record revenue of $2.9 billion grew 24% sequentially and 55% from the year ago quarter with record revenue across both hyperscale and vertical industries. Strong growth was led by hyperscale customers, fueled by continued rapid adoption of Ampere architecture Tensor Core GPUs for both internal and external workloads. Hyperscale compute revenue doubled year-on-year, driven by the scale out of natural language processing and recommendator models and cloud computing.
Vertical industry growth was also strong, led by consumer Internet and broader cloud providers. For example, Barco Cloud deployed NVIDIA GPUs for its launch of AI services, such as tech analysis, speech recognition, computer vision and anomaly detection.
We continue to achieve exceptional growth and influence, which again outpaced our overall Data Center growth. We have transitioned our lineup of infant-focused processes to the Ampere architecture, such as the A30 GPU. We also released the latest version of our Triton Inference Server software, enabling compute-intensive inference workloads such as large language models to scale across multiple GPUs and nodes with real-time performance.
Over 25,000 companies worldwide use NVIDIA AI inference. A great new example is Microsoft Teams, which has nearly 250 million monthly active users. It uses NVIDIA AI to convert speech to text real time during video calls in 28 languages in a cost-effective way.
We reached three milestones to help drive more mainstream enterprise adoption of NVIDIA AI. First, we announced the general availability of NVIDIA AI Enterprise, a comprehensive software suite with AI tools and frameworks that enables the hundreds of thousands of companies running NVIDIA, running vSphere to virtualize AI workloads on NVIDIA-certified systems.
Second, VMware announced a future update to vSphere with Tanzu that is fully optimized for NVIDIA AI. When it's combined with NVIDIA AI enterprise, enterprises can efficiently manage cloud-native AI development and deployment on main stream data center servers and clouds with existing IT tools.
And third, we expanded our launch cloud program globally with ethernet as our first digital infrastructure partner. NVIDIA LaunchPad is now available in nine locations worldwide, providing enterprises with immediate access to NVIDIA software and infrastructure to help them prototype and test data science and AI workloads. LaunchPad features NVIDIA-certified systems and NVIDIA DGX systems running the entire NVIDIA AI software stack.
In networking, revenue was impacted as demand outstripped supply. We saw momentum toward higher speed and new generation products, including ConnectX-5 and 6. We announced the NVIDIA Quantum-2 400 gigabit per second end-to-end networking platform, consisting of the Quantum-2 switch the ConnectX-7 network adapter and the BlueField-3 DPU.
The NVIDIA Quantum-two, which is available from a wide range of building infrastructure and system vendors around the world. Earlier this week, the latest top 500 list of supercomputers showed continued momentum for our full stack computing approach.
NVIDIA's technologies accelerate over 70% of the systems Muslims on the including over 90% of all new systems and 23 of the top 25 most energy-efficient systems.
Turning to GTC. Last week we hosted our GPU Technology Conference, which had over 270,000 registered attendees. Jensen's keynote has been viewed 25 million times over the past eight days. While our Spring GTC is focused on new chips and systems, this edition focused on software, demonstrating our full computing stack. Let me cover some of the highlights.
Our vision for Omniverse came to life at GTC. We significantly expanded this ecosystem and announced new capabilities. Omniverse replication is an engine for producing data to train robots, replicating augment real-world data with massive, diverse and physically accurate synthetic data sets to both accelerate development of high-quality, high-performance AI across computing demand. NVIDIA Omniverse Avatar is our platform for generating interactive AI avatars. It connects several core NVIDIA SDKs including switch AI, computer vision, natural language understanding, recommendation engines and simulation. Applications including automated customer service, virtual collaboration and content solution. Replicator ad avatar joined several other announced features and capabilities for Omniverse, including AI, AR, VR and simulation-based technologies.
We introduced 65 new and updated software development page, bringing our total to more than 150 serving industries from gaming and design to AI, cybersecurity, 5G and robotics. One of the STKs is our first four licensed AI model, NVIDIA Riva, for building conversational AI applications. Companies using Riva during the open beta include RingCentral for video conference live captioning and Pig An for customer service chatbots. NVIDIA Riva Enterprise will be commercially available early next year, for launch.
We introduced the NVIDIA's NeMo Megatron optimized for training large language models on NVIDIA DGX SuperPOD infrastructure. This combination brings together production-ready, enterprise-grade hardware and software in both vertical industries, develop language and industry-specific dropbox, personal systems, content generation and summarization. Early adopters include SiDi, JD.com and VinBrain. We unveiled BlueField DOCA 1.2, the latest version of our GPU programming lender with new cybersecurity capabilities. DOCA is to our GPUs as CUDA is to our GPUs. It enables developers to build applications and services on top of our BlueFiled DOCAs. Our new capabilities make BlueField the ideal platform for the industry to build their own zero trust security platforms. The leading cybersecurity companies are working with us to provision their next-generation firewall service on BlueField, including Checkpoint, Juniper, Borgne, F5, Palo Alto Networks and VMware. And we released Clara Holoscan, a edge AI computing platform for medical instruments to improve decision-making tools in areas such as robo-assisted surgery, interventional radiology and radiation therapy planning.
Other new or expanded SDKs or libraries unveiled at GTC include ReOpt for AI optimized logistics Quantum for quantum computing, Morpheus for cybersecurity, Modulus for physical-based machine learning and Crunet Numeric, a data center scale mass library to bring accelerated computing to the large and growing Python ecosystem. All in, NVIDIA's computing platform continues to expand as a broadening set of SDK enable more and more GPU-accelerated applications and industry use cases.
CUDA has been downloaded 30 million times, and our developer ecosystem is now nearing 3 million strong. The applications they develop on top of our SDK and the cloud to edge computing platform are helping to transform multitrillion dollar industries from healthcare to transportation to mental services, manufacturing, logistics and virtual.
In Automotive, we announced NVIDIA DRIVE Concierge and DRIVE Chauffeur, AI software platforms that enhance a vehicle's performance, features and safety. Live Concierge build on Omniverse Avatar functioned as an AI-based in-vehicle person-assistance, but enables automatic parking, summoning capabilities. It also enhanced safety by monitoring the driver throughout the duration of the drive.
DRIVE Chauffeur offers autonomous capabilities, relieving the driver of constantly having to control the car. It will also perform address to address driving when combined with DRIVE Hyperion 8 platform.
For robotics, we announced Jetson AGX Orin, the world's smallest, most powerful and energy-efficient AI supercomputer for robotics, autonomous mission and embedded computing at the Edge. Built on our Ampere architecture, Jetson AGX Orin provides 6 times the processing power of its predecessor and delivers 200 trillion operations per second, similar to a GPU-enabled server that fits into the palm of your hand. Jetson AGX Orin will be available in the first quarter of calendar 2022.
Finally, we revealed plans to build Earth-2, the world's most powerful AI supercomputer dedicated to confronting climate change. The system would be the climate change counterpart to Cambridge-1, the U.K.'s most powerful AI supercomputer that we built for corporate research. Earth-2 furnishes all the technologies we've invented up to this moment.
Let me discuss Arm. I'll provide you a brief update on our proposed acquisition of Arm. Arm with NVIDIA is a great opportunity for the industry and customers with NVIDIA's scale, capabilities and robust understanding of data center computing, acceleration and AI. We assessed Arm in expanding their reach into data center, IOT and PCs and advanced Arm's IP for decades to come. The combination of our companies can enhance competition in the industry as we work together on further building the world of AI.
Regulators at the U.S. FTC have expressed concerns regarding the transaction and we are engaged in discussions with them regarding remedies to address those concerns. The transactions has been under review by China Antitrust Authority, pending the formal case initiation. Regulators in the U.K. and the EU have declined to approve the transaction in Phase 1 of their reviews on competition concerns. In the U.K., they have also voiced national security concerns. We have begun the Phase 2 process in the EU and U.K. jurisdictions. Despite these concerns and those raised by some Arm licensees, we continue to believe in the merits and the benefits of the acquisition to Arm, to its licensees and to the industry. We believe these concerns and those raised by some Arm licensees -- we continue to believe in the merits and benefits of the ongoing acquisition.
Moving to the rest of the P&L. GAAP gross margin for the third quarter was up 260 basis points from a year earlier, primarily due to higher end mix within desktop, notebook, GeForce GPUs. The year-on-year increase also benefited from a reduced impact of acquisition-related costs. GAAP gross margin was up 40 basis points sequentially, driven by growth in our Data Center Ampere architecture products, which is particularly offset by mix in gaming. Non-gaming gross margin was up 150 basis points from a year earlier and up 30 basis points sequentially.
Q3 GAAP EPS was $0.97, 83% from a year earlier. Non-GAAP EPS was $1.17, up 60% from a year ago, adjusting for our stock split. Q3 cash flow from operations was $1.5 billion, up from $1.3 billion a year earlier and down from $2.7 billion in the prior quarter. The year-on-year increase primarily reflects higher operating income, particularly offset by prepayment for long-term supply agreement.
Let me turn to the outlook for the fourth quarter of fiscal 2022. We expect sequential growth to be driven by Data Center and Gaming, more than offsetting a decline in CMP. Revenue is expected to be $7.4 billion plus or minus 2%. GAAP and non-GAAP gross margins are expected to be 65.3% and 67%, respectively, plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $2.02 billion and $1.43 billion, respectively. GAAP and non-GAAP other income and expenses are both expected to be an expense of approximately $60 million, excluding gains and losses on non-affiliated investments. GAAP and non-GAAP tax rates are both expected to be 11%, plus or minus 1% excluding discrete items. Capital expenditures are expected to be approximately $250 million to $275 million.
Further financial details are included in the CFO commentary. Other information is also available on our IR website.
In closing, let me highlight upcoming events for the financial community. We will be attending the Credit Suisse 25th Annual Technology Conference in person on November 30th. We will also be at the Wells Fargo Fifth Annual TMT Summit virtually on December 1st, the UBS Global TMT Virtual Conference on December 6th, and the Deutsche Bank Virtual Auto Tech Conference on December 9th. Our earnings call to discuss our fourth quarter and fiscal year 2022 results is scheduled for Wednesday, February 16.
With that, we will now open the call for questions. Operator, will you please poll for the questions.
Operator
[Operator Instructions] For our first question, we have Aaron Rakers from Wells Fargo. Aaron, your line is open.
Aaron Rakers -- Wells Fargo -- Analyst
Yes. Thanks for taking the question and congratulations on the results. I guess, I wanted to ask about Omniverse. Obviously, a lot of excitement around that. I guess the simple question is, Jensen, how do you define success in Omniverse as we look out over the next, let's call it, 12 months and how do we think about the subscription license opportunity for Omniverse. I know you've talked about $40 million total 3D designers, I think that actually doubled what you talked about back in August. So I'm just curious of how we at finance line should probably think about that opportunity materializing?
Jensen Huang -- Founder, President and Chief Executive Officer
Yes. Thanks. Omniverse success will be defined by, number one, developer engagement, connecting with developers around the world; two, applications being developed by enterprises; three, the connection -- designers and creators among themselves. Those are the nearest term -- and I would say that in my type of definition, etc.
Near term also, it should be revenues and Omniverse has real immediate applications as I demonstrated at the keynote and I'll highlight a few of them right now. One of them, of course, is that it serves as a way to connect 3D and digital design world. Think of Adobe as a world, think of the Autodesk as a world, think of Revit as a world. These are design world in the sense that people are doing things in it, they are creating things in it and they have to run database.
We made it possible for these worlds to be connected for the very first time and for it to be shared like in cloud documents. That's not been possible ever before and we can now share work with each other, you can see each other's work, you can collaborate. And so in the world of remote working, Ominverse's collaboration capability is going to be really appreciated and that should happen right away. We would like to see that happen in very near term. And that drives of course, more PC sales, more GPU sales, more workstation sales, more server sales.
The second use case is digital twins. And we show in these following examples of how several companies using Omniverse to create a digital twin of a city so that they could optimize radio placements and radio energy used for beamforming. You saw BMW using it for their factories. You're going to see people using it for warehouse, logistics warehouse to plan and to optimize their warehouses and deploying the robots. And so digital twin applications are absolutely immediate.
And then remember, robots has several clients. There is the physical robot that you saw and a physical robot would be a self-driving car and physical robots would be the car itself, turning it into a robot, so that it could be an intelligent assistant. But I demonstrated probably the -- in my explanation, the largest application of robots in the future and its avatars.
We built Omniverse Avatars to make it easy for people to integrate some amazing technology for computer vision, for speech recognition, natural language understanding, gesture recognition, facial animation and speech synthesis, recommender systems, all of that integrated into one system and running in real time. That Avatar system is essentially a robotic system and the way that you use that is, for example, with $25 million or so retail stores, restaurant, places like airports and train stations, office buildings and such, where you're going to have intelligent Avatars doing a lot of assistance. They might be doing check out, they might be doing check in, they might be doing customer support and all of that can be done with Avatars, as I've demonstrated.
So the virtual robotics application, digital buys of Avatars, it is going to be likely the largest robotics opportunity. So if you look at our licensing model, the way it basically works is that inside Omniverse is one of the main users and the main users could be one of the 20 million creators or 20 million designers and the 40 million creators and designers around the world and they share Omniverse, each one of the main users would be a $1,000 per user per year.
But don't forget that intelligent use or intelligent users that have been connected through Omniverse will likely be much larger as digital buyers than humans. So I mentioned 40 million, but there are 100 million cars. And these 100 million cars will have the capability to have something like in Omniverse Avatar and so those 100 million cars could be $1,000 per car per year. And in the case of the 25 million or so places where you would have a digital avatar as customer support or check out smart retail or smart warehouses or smart whatever it is, those avatars also would each individually be a new account and so they would be $1,000 per Avatar per year. And so those are the immediate tangible opportunities for us and I demonstrate the applications in related keynotes. And then of course behind all of that, call it a couple of hundred million digital agents, intelligent agents, some of them humans, some of them robots, some of them Avatars adds $1,000 per agent per year. Behind it are, NVIDIA GPUs in PC, NVIDIA GPU in cloud, and NVIDIA GPUs in Omniverse servers. And my guess would be that the hardware part of it is probably going to be about half and then the licensing part of it is probably about half of the time. So this is really going to be one of the largest graphics opportunities that we've ever seen.
And the reason why it's taken so long for us to manifest is because it requires three fundamental technologies to come together, I guess four fundamentals technologies to come together. First of all, it's video graphic; second is physics simulation, because we're talking about things in world that has to be believable, so it has to obey the laws of physics; and then third is artificial intelligence, as I demonstrated and illustrated just now. And all of it runs on top of an Omniverse computer that has to do not just AI, not just physics, not just computer graphics, but all of it.
And so long term why people are so excited about it is, at the highest level what it basically means is that that long-term when we engage in that, which is largely 2D today, long-term every query would be 3D and instead of just querying information, we would query and interact with people and Avatars and things and places and all of these things are in 3D. So hopefully one of these days that we will probably realize it as fast as we can every transaction that goes on to internet touches a GPU and today that's a very small percentage, but hopefully one of these days it will be a bit of a high percentage. So I hope that's helpful.
Operator
For our next question, we have Mark Lipacis from Jefferies. Mark, your line is open.
Mark Lipacis -- Jefferies -- Analyst
Hi. Thanks for taking my question. Jensen, it seems like every year there seems to be a new set of demand drivers for your accelerated platform, accelerated processing ecosystem, there's gaming, then neural network and AI and then blockchain and then ray tracing. And five or six years ago, you guys showed a bunch of virtual reality demos, which were really exciting at your Analyst Day, excitement died down, now it seems to be resurfacing particularly with Omniverse Avatar capability and Facebook shedding light on the opportunities. So the two questions from that are, how close is your Omniverse Avatar to morphing into like a mass market technology that everybody uses daily? You talk about like -- you said that everybody is going to be a gamer, everybody is going to be a Omniverse Avatar user. And maybe the bigger picture is, is it reasonable to think about new killer app coming out every year? Is there a parallel that we should think about with previous computing markets that we could think about for the computing area that we're entering right now? Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Yes. I really appreciate that. Chips are enablers, but chips don't create markets, software creates market. At this point, I explain over the years that accelerated computing is very different than general purpose computing and the reason for that is because you can't just write into compiler and compile quantum physics into a chip. I mean, it doesn't. You can't just compile Schrodinger's equation and have it distributed across multiple GPUs, multiple nodes and have a new SaaS. You just -- you can't do that for computer graphics, you can't do that for artificial intelligence, you can't do that for robotics, you can't do that for the most of the interesting applications in the world and because we really run out of steam with GPUs and that people are saying that not because it's not true, it is abundantly clear that the amount of instruction in parallel that you can squeeze out of a system is although not zero is incredibly hard, it's just incredibly hard.
And there is another approach and we have been advocating accelerated computing for some time and now people really see the benefit of it, but it does requires a lot of work and yet the work basically says for every domain, for every application we have -- for every application in large domain that you'll use, you have to have a whole stack. And so whenever you want to open a new market by accelerating those applications or that domain of applications, you have to come up with a new stack and the new stack is hard, because you have to understand the application, you have to understand the algorithms, the mathematics, you have to understand computer science to distribute it across, to take something that was single threaded and make it multi-threaded and make something that we've done sequentially and make it process in parallel. You break everything, you break storage, you break networking, you break everything.
And so it takes a fair amount of expertise and that's why we're saying that over the years, over the course of 30 years we have become a full-stack company, because we've been trying to solve this problem practically through decades. And so that's one. But the benefit, once you have the ability, then you can open new markets and we played a really large role in democratizing artificial intelligence and making it possible for anybody to be able to do it.
Our greatest contribution is I hope when it's all said and done that we democratized scientific computing, so that researchers and scientists, computer scientists, data scientists, scientists of all kinds were able to get access to this incredibly powerful tool that we call computers to do advance research. And so every single year we're coming up with new stacks and we got a whole bunch of stacks we are working on and many of them are working on in plain sight, so that you see it coming, you just have to connect it together.
One of the areas that we spoke about this time, of course, was Omniverse and you saw the pieces of it being built over time, and it took half a decade to start building Omniverse, but it built on a quarter century of work. In the case of the Omniverse Avatar, you could literally point to MERLIN, the recommender; Megatron, the language -- large language model; Riva, the speech AI, all of our computer vision AIs that have been demonstrating over the years, natural speech synthesis that we see every single year with I AM AI the opening credits, how we're using, developing an AI to be able to speak in a human way so that people feel more comfortable and more engaged with the AI. Face, eye tracking, Maxine and all of these technologies are connected together. They were all built in pieces, but we integrated it, we have the intentions of integrating it and to create what it's called Omniverse Avatar.
And now you asked the question, how quickly will we deploy this? I believe Omniverse Avatar will be in drive-thrus and restaurants, fast food restaurants, check out with restaurants, in retail stores, all over the world within less than five years. And we're going to need it in all kinds of different applications, because there is such a great shortage of labor and there is such a wonderful way that you can now engage in Avatar and it could -- it doesn't make mistakes, it doesn't get tired and it's always on and we made so that it's cloud native and so when you saw the keynote, I hope you'd agree that the interaction is instantaneous and the conversational forum is so enjoyable.
And so anyway, I think what you highlight is, one, accelerated computing is a full-stack challenge. Two, it takes software to open new markets. Chips can't open new markets. If you build another chip, you can steal somebody's share, but you can't open new market and it takes software to open new market. NVIDIA switch with software, and that's one of the reasons why we could integrate such large market opportunities.
And then last with respect to Omniverse, I believe it's a near-term opportunity that we've be working on for some three, four, five years.
Operator
For our next question, we have C.J. Muse from Evercore ISI. C.J., your line is open.
C.J. Muse -- Evercore ISI -- Analyst
Yes. Good afternoon. Thank you for taking the question. And I guess not an Omniverse question, but I guess, Jensen, I'd like your commitment that you will not use Omniverse to target the sell-side research industry.
As my real question, can you speak to your Data Center visibility into 2022 and beyond? And within this outlook, can you talk to traditional cloud versus industry verticals and then perhaps emerging opportunities like Omniverse and others? Would love to get a sense of kind of what you're seeing today. And then as part of that, how you're planning to secure foundry and other supply to support that growth? Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Thank you, C.J. First of all, we have secured guaranteed supply, very large amounts of it, quite a spectacular amount of it from the world's leading foundry in substrate and packaging and testing certain companies, the integral part of our supply chain. And so we have done that and feel very good about our supply situation, particularly starting in the second half of this year and going forward. I think this whole last year was a wakeup call for everybody to be much more mindful about not taking the supply chain for granted and we were fortunate to have such good partners, but nonetheless we've secured our future.
With respect to Data Center, about half of our Data Center business comes from the cloud and cloud service providers and the other half comes from enterprise, what we call enterprise companies and they're in all kinds of industries. And about 1% of it comes from supercomputing centers, because so 50% or so cloud, 50% or so enterprise and 1% supercomputing centers.
And we expect next year, the cloud, the cloud service providers to scale out their deep learning and their AI workloads really aggressively and we're seeing that right now. We built a really fantastic platform and -- number one. Number two, the work we've been doing with TensorRT, which has the run time that goes into the server that's called Triton is one of our best pieces of work. We're just so proud of it. And we said nearly four years ago, three-and-half years ago that Inference is going to be one of the great computer science challenges, and it's really proving to be so. And the reason for that is, because sometimes it's throughput, sometimes it's latency, sometimes interactivity on the type of models we have with Inference. It's just all over the map, it's not just computer vision or image recognition, it's all over the map. And the reason for that is there's many different types of architectures, there's so many different ways to build different applications and so the application is complicated.
And finally there is just a wonderful people working. We're now on our 8th generation on that. It's adopted all over the world. Some 25,000 companies are now using NVIDIA AI and recently at GTC we announced two very, very big things. One, we remind everybody that we -- just this month before we have tried to support now just in every generation of NVIDIA GPUs, of which there are so many versions to be managing without trying how would you possibly deploy AI across the entire fleet of NVIDIA servers, NVIDIA GPU servers that are all over world and so it's almost an essential tool just to operate and take advantage of all of NVIDIA's GPU that are in datacenter.
Two, we support CPUs. And so it's no longer necessary for someone to have two Inference servers. You can just have one Inference servers, because the NVIDIA version is already essential. Now everybody could just use Triton and every single server in the Data Center could be part of the Inference capacity and then we did something else that was really big deal at GTC, which is the so-called Forced Inference Library, called FIL, that basically the most popular machine learning systems in Inference models are based on trees and decision trees and boosted gradient trees and people might know it as XGBoost. And trees all over the place, in fraud detection, in recommender systems and utilized in companies all over the world, because it's just self-explanatory. You can build upon it, you don't worry about regressions. It could build bigger and bigger trees. And we -- this GTC we announced that we support that as well. And so all of the sudden, all of that workflow that runs on CPU is not only do they run on Triton, it becomes accelerated.
And the last -- the next thing that NVIDIA will announce, with the tremendous interest in large language models, Triton now also supports multi-GPU and multi-node Inference, so that we could take something like an OpenAI GPT-3, NVIDIA Megatron 530B or anybody's giant model that's been developed all over the world in all these different languages, in all these different domains, in all these different fields of science and what -- in industry where we can now influence it in real time. And I demonstrated it in one of the demos, there was a question answering model that the team built and it was able to basically answer questions in real-time. And so that is just a giant venture and these are the type of workloads that's going to make it possible for us to continue to scale out and build on these, so.
So back to your original question, I think next year is going to be quite a good year for Data Center. Customers are very mindful of securing their supply for their scale out and so we have a fair amount of visibility and more visibility commonly than ever at Data Center, but in addition to that, Triton is just in adoption everywhere.
And then, finally, our brand-new workloads, which is built on top of AI and graphics and simulation, which is Omniverse, and we saw the examples that I gave, these are real companies doing real work and one of the areas that has severe shortages around the world is customer support, just genuine severe shortages all over the world, and we think the answer is Omniverse Avatar. And it runs in Data Center, you could easily adapt Omniverse Avatar to do drive-thrus or retail check out or customer service, and I demonstrated that with Tokyo, a parking kiosk. You can use it for a tele-operated customer service and we've demonstrated that with Maxine and we demonstrated how you could use it even for video conferencing. And then lastly, we demonstrated how we could use Omniverse Avatar for robotics, for example, to create a continues work what we call DRIVE Concierge where the car is turned into intelligent customer support, intelligent agent.
I think Omniverse Avatar is going to be a really exciting driver for enterprise this next year. And so next year is going to be a pretty terrific year for Data Center.
Operator
For our next question, we have Stacy Rasgon from Bernstein Research. Stacy, your line is open.
Stacy Rasgon -- Bernstein Research -- Analyst
Hi, guys. Thanks for taking my questions. I wanted to ask two of them on Data Center, both near term and then maybe a little longer term. On the near-term, Colette, you suggested guidance in the Q4 be driven by Data Center and gaming and you mentioned data center first. Does that mean that it's bigger? If you could just help us like parse the contribution of each into Q4?
And then in the next year, given the commentary for the last question, again it sounds like you've got like a very strong outlook for Data Center both from hyperscale and enterprise. If I look at sort of the implied guidance you gave, Data Center for you is probably likely to grow 50% year-over-year in this fiscal year. Would it be crazy to think given all the drivers that it could grow by a similar amount next year as well? Like, how should we be thinking about that given all of the drivers that you've been laying out?
Colette Kress -- Executive Vice President and Chief Financial Officer
Okay. Thanks, Stacy, for the question. Let's first focus in terms of our guidance for Q4. Our statements that we made were, yes, about driven by revenue growth from Data Center and Gaming sequentially. We can probably expect our Data Center to grow faster than our Gaming, probably both in terms of percentage wise and in absolute dollars. We also expect our CMP product to decline quarter-on-quarter to very negligible levels in Q4. So I hope that gives you a color on Q4.
Now in terms of next year, we'll certainly turn the corner into the new fiscal year. We certainly provide guidance one quarter out. We've given you some great discussions here about the opportunities in front of us, opportunities with the hyperscales, the opportunities with the verticals. Omniverse is a full stack opportunity in front of us.
We are securing supply for next year, not just for the current year and Q4, to allow us to really grow into so much of this opportunity going forward. But at this time, we're going to wait until next year to provide guidance.
Stacy Rasgon -- Bernstein Research -- Analyst
Got it. That's helpful. I appreciate it. Thank you
Operator
For the next question we have Vivek Arya from BofA Securities. Vivek, your line is open.
Vivek Arya -- BofA Securities -- Analyst
Thanks for taking my question. Actually I had two quick ones. And so, Colette, you suggested the inventory purchase and supply agreements are up, I think, almost 68% year-on-year. Does that provide some directional correlation with how you are preparing for growth over the next 12 to 24 months? So that's one question. And then the bigger question, Jensen, that I have for you is, where are we in the AI adoption cycle? What percentage of servers are accelerated in hyperscale and vertical industry today and where can those ratios get to?
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks for the question. So let's first start in terms of supply or supply purchase agreement. You have noted that we are discussing that we have made payments toward some of those commitments. Not only are we procuring for what we need in the quarter, what we need next year and again we are planning for growth next year, so we have been planning that supply purchases, we are also doing long-term supply purchases. These are areas of capacity agreements and/or many of our different suppliers.
We made a payment within this quarter of approximately $1.6 billion out of total long-term capacity agreement of about $3.4 billion. So we still have more payments to make and we were likely continue to be purchasing longer term to support our growth that we are planning for many years to come.
Jensen Huang -- Founder, President and Chief Executive Officer
Every single server will be GPU accelerated some day. Today of all the clouds and all the enterprise, less than 10%. That kind of give you a sense of where you are. In terms of the workloads, it is also consistent with that in the sense that that a lot of the workloads still only run on CPUs, which is the reason why in order for us to grow, we have to be a full stack company and we have to go find applications, we now have to find plenty of it, focus on the application that require acceleration or benefits tremendously from acceleration that if they were to get a million X speed up, which sounds insane but it's not. Mathematically I can prove it to you and historically I can even demonstrate it to you that in many areas we have seen million X speed up and has completely revolutionized those industries, computer graphics is of course one of them. Omniverse would not be possible without it.
And so the work that we're doing with digital biology, protein synthesis, which is likely going to be one of the large industries of the world that doesn't exist today at all. Protein engineering and the protein economy is likely going to be very, very large. You can't do that unless you are able to get million X speed up in the simulation of protein biology. And so those are -- and not to mention some of the most imperative comps that we have to build and engage. Climate science needs million X, billion X speed up and we are at a point where we can actually tackle that.
And so in each one of these cases we have performed, we have to focus our resources to go and accelerate those applications and that translates to growth. Until then, they run on GPUs. And we look at a lot of today speech synthesis and speech recognition system, it still uses fairly traditional or mixture of traditional and deep learning approaches for speech AI. NVIDIA Riva is the world's first, I believe, that is end to end deep neural network. And we've worked with many companies in helping them advance there, so that they could move their clouds to our neural-based approaches. But that's one of the reasons why we do it, so that we could provide the reference, but we can also license it to enterprises around the world, so that they could advance it for their own use cases. And so one application after another we have to get it accelerated, one domain after another we have to get it accelerated.
One of the ones that we're excited about and something that we've been working on for so long is EDA, even our own industry, Electronic Design Automation, for the very first time we announced the EDA using GPU accelerated computing, whether it's because of the artificial intelligence capability, because EDA is very large combinatorial optimization program and using artificial intelligence you could really improve the design quality and design time.
So we're seeing from all the major game vendors, from chip design to simulation to PCB design and optimization, design synthesis, moving toward artificial intelligence and GPU acceleration in a very significant. And then we see that with a mechanical CAD and traditional CAD application now also jumping on to GPU acceleration is getting very significant speed ups. And so I'm super excited about the work that we're doing in each one of these domains. Because every time you do it, you open up brand new market and customers that never used NVIDIA GPUs now can, because ultimately people don't buy chips, it cannot solve problems. Without a full stack, without software expertise, you can't really commence the enabling technology, what the chip provide and ultimately solve the customers' problems.
Operator
Your final question comes from the line of Timothy Arcuri from UBS. Timothy, your line is open.
Timothy Arcuri -- UBS -- Analyst
Thanks a lot. Colette, I had a question about gross margin. Are there any margin headwinds maybe on the wafer pricing side that we should sort of think about normalizing out, because gross margin is pretty flat between fiscal Q2 and fiscal Q4. But I imagine that's kind of masking a strong underlying margin growth, especially as Data Center has been actually driving that growth. So I'm wondering if maybe there are some underlying factors that are sort of gating gross margin? Thanks.
Colette Kress -- Executive Vice President and Chief Financial Officer
Yes. So we have always been working on our gross margin and being able to absorb a lot of the cost changes along the way, architecture-to-architecture really. So that's always based into our gross margin. Our gross margins right now are largely stable. Our incremental revenue, for example, what we're expecting next quarter will likely align to our current gross margin levels that we finished in terms of Q3. Our largest driver always continues to be mix. We have a lot of different mix that has driven related to the high-end AI and RTX solutions, for example, and the software that is embedded in solutions have allowed us to increase our gross margin.
As we look forward long-term, software if sold separately can be another driver of gross margin increases in the future. But cost changes, cost increases are -- generally been a part of our gross margin figures.
Operator
Thank you. I will now turn the call over back to Jensen Huang for closing remarks.
Jensen Huang -- Founder, President and Chief Executive Officer
Thank you. We had an outstanding quarter. Demand for NVIDIA AI is strong with hyperscalers and cloud services deploying at scale and enterprises broadening adoption. We now help more than 25,000 companies that are using NVIDIA AI. And with NVIDIA AI enterprise software suite, our collaboration with VMware and our collaboration with Equinix to place NVIDIA LaunchPad across the world, every enterprise has an easy arm length to NVIDIA AI.
Gaming and Pro Vis are surging. RTX opportunity continues to expand with the growing market of gamers, creators, designers and now professionals building home workstations. We are working hard to increase supply for the overwhelming demand this holiday season.
Last week, GTC showcased the expanding universe of NVIDIA accelerated computing. In combination with AI and Data Center scale computing, the model we pioneered is on the cusp of producing million X speed ups that will revolutionize many important fields; already AI and upcoming robotics, digital biology and what I hope climate science. GTC highlighted our full stack expertise in action, built on CUDA and our acceleration libraries in data processing, in simulation, graphics, artificial intelligence, market and domain specific software is needed to solve customer problems. We also showed how software opens new growth opportunities for us. But the chips are the enablers, but it's the software that opens new growth opportunities. NVIDIA has 150 SDKs now addressed in many of the world's largest end markets.
One of the major themes of this GTC was Omniverse, our simulation platform for virtual worlds and digital twin. Our body of work and expertise in graphics, physics simulation, AI, robotics and full stack computing made Omniverse possible. At GTC, we showed how Omniverse is used to reinvent collaborative design, customer service avatars and video conferencing and digital twin to factories, processing plants and even entire cities. This is just the tip of the iceberg of what's to come. We look forward to updating you on our progress next quarter. Thank you.
Operator
Thank you. I will now turn over to Jensen for closing remarks.
Simona Jankowski -- Investor Relations

--- Q4 2021 ---
Simona Jankowski -- Vice President of Investor Relations and Strategic Finance
Thank you. Good afternoon everyone and welcome to NVIDIA's conference call for the fourth quarter of fiscal 2021. With me on the call today from NVIDIA are Jensen Huang, President and Chief Executive Officer and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's investor relations website. The webcast will be available for replay until the conference call to discuss our financial results for the first quarter of fiscal 2022. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent.
During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10-K and 10-Q and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, February 24, 2021 based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, Simona. Q4 was another record quarter with revenue exceeding $5 billion and year-on-year growth accelerating to 61%. Full year revenue was also a record at $16.7 billion, up 53%. Our Gaming business reached record revenue of $2.5 billion in Q4, up 10% sequentially and up 67% from a year earlier. Full year Gaming revenue was a record of $7.8 billion, up 41%. Demand is incredible for our new GeForce RTX 30 Series products based on the NVIDIA Ampere GPU architecture. In early December, we launched the GeForce RTX 3060 Ti, which joined the previously launched RTX 3090, 3080, and 3070. The entire 30 Series lineup has been hard to keep in stock and we exited Q4 with channel inventories even lower than when we started. Although we are increasing supply, channel inventories will likely remain low throughout Q1.
GeForce RTX 30 Series graphics cards were a holiday sensation due not just to their amazing performance but also to the rich features including our second-generation RTX ray tracing technology and DLSS, AI powered performance accelerator, which massively boosts frame rates in graphically demanding titles. 3,000 games now support RTX including the top battle royale game, Fortnite; the top role playing game, Cyberpunk 2077; the top massively multiplayer online game, World of Warcraft; and the best selling game of all-time, Minecraft. RTX has clearly set the new standard in gaming.
Building on this momentum, at CES in January, we introduced a wave of Ampere architecture gaming products, including our biggest ever laptop launch powered by GeForce RTX 3060, 3070 and 3080 laptop GPUs and with our third generation Max-Q technology. These new thin and lightweight gaming laptops increase performance and energy efficiency by up to 2 times from the prior generation. RTX 3060 laptops start $999 and are faster than the previous generation laptops, which sold for $2,500. The incredible performance, design, and price points of these new laptops will delight the growing universe of gamers and creators as well as students and professionals.
The gaming laptop market has grown seven-fold in the past seven years and momentum is building. With top OEMs bringing to market a record 70 plus laptop models based on the GeForce RTX 30 Series. GeForce laptops as a whole are the fastest growing and one of the largest gaming platforms. Also at CES, we announced the GeForce RTX 3060 GPU priced at $329, extending the 30 Series desktop lineup further into the mainstream. We expect strong demand when it launches this Friday as 60-class GPUs have traditionally been our most popular products.
Starting with the 3060, we're taking an important step to maximize the supply of GeForce GPUs for gamers. Users are constantly discovering new applications for our powerful, programmable GPUs and cryptocurrency mining is one of them. With rising Ethereum prices, there are indications that miners are behind GPUs. We would like GeForce GPUs to end up with gamers. So we have created new special software drivers that will detect the Ethereum mining algorithm, cutting in half the mining efficiency of the GeForce RTX 3060.
We suspect the significant increase in the Ethereum network hash rate observed over the past few months was driven by a combination of previously installed mining capacity that was reactivated as well as new sales of GPUs and ASICs. Since our GPUs are sold to graphics card manufacturers and then on to distribution, we don't have the ability to accurately track or quantify their end-use. Analyst estimates suggest that crypto mining contributed $100 million to $300 million to our Q4 revenue, a relatively small portion of our Gaming revenue in Q4.
Cryptocurrencies have recently started to be accepted by companies and financial institutions and show increased signs of staying power. To address industrial Ethereum mining demand, last week, we announced a new line of NVIDIA CMPs or Crypto Mining Processors. Shipments will start in March. CMP's lack display outputs and have other optimizations that improve crypto mining power efficiency. CMP products will let us gain some visibility into the contribution of crypto mining to our overall revenue. For Q1, we estimate that CMP will contribute approximately $50 million. We plan to sell these products to industrial miners. We will quantify their contribution each quarter for transparency.
Over the past year, it has become clear that we've entered a new era in which gaming is an integral part of global culture. The number of concurrent users on Steam has more than doubled since 2018 and continues to hit new records. In 2020 alone, more than 100 billion hours of gaming content was seen on YouTube and 0.5 billion people watched eSports. Increasingly, we aren't just gaming, we're also watching sports, kept attending concerts, creating content, and connecting with our friends in virtual environments.
Additionally, we are excited about the new experiences like VR. Significantly more content is now available including arguably the first VR killer app, Beat Saber. And there is now almost 2 million VR users on Steam. And with these powerful structural shifts, we expect our Gaming business to remain on a robust growth trajectory. The GeForce RTX 30 Series GPUs have kicked off a powerful upgrade cycle and we estimate only around 15% of GeForce gamers own an RTX class GPU, which is merely to experience the beautiful ray traced graphics of modern games.
Moreover, the universe of gamers is rapidly expanding and the reach of GeForce has extended beyond gamers to some 45 million creators. In addition, Gaming revenue continues to benefit from a favorable mix shift as gamers and creators keep moving to higher-end GPUs. We expect another great year for GeForce.
Earlier this month, we celebrated the one year anniversary of GeForce NOW Cloud Gaming platform, which is now over 6 million numbers strong. GeForce NOW offers 800 PCs from over 300 publishers, more than any other cloud gaming service including 80 of the most played free to play games. Starting with support for Windows PCs, Macs and Android devices, we added support in recent months to Chromebooks, iPhones, and iPads. GFN has grown globally with more than 65 countries on our service and more added regularly by our GeForce NOW Alliance Partners.
Moving to Pro Vis, Q4 revenue was $307 million, up 30% sequentially and down 10% [Phonetic] year-on-year and ahead of our expectations. Full year revenue was $1.1 [Phonetic] billion was down 13%. Strong sequential growth was driven primarily by a recovery in desktop workstations as some customers returned to the office and enterprises resumed purchases that have been deferred by the pandemic. Notebook GPUs grew sequentially to a record as enterprises continue to support remote workforce initiatives.
Looking ahead, the reopening of businesses will benefit desktop workstations, but longer-term workforce trends will likely shift our mix to notebook GPUs and cloud offerings. Healthcare was a standout vertical in the quarter with significant orders from GE, Siemens. and Oxford Nanopore Technologies. Public sector and automotive also showed strength.
Omniverse, our real-time 3D collaboration and simulation platform is now in open beta. Over 500 creators and professionals have tested Omniverse through our early access program. Omniverse is one of our most important and exciting platforms. We are delighted by its initial acceptance and look forward to sharing more details on its long-term growth opportunity in the coming months.
Moving to Automotive. Q4 revenue was $145 million, up 16% sequentially and down 11% year-on-year. Full year revenue of $536 million, declined 23%. Sequential growth was driven by continued recovery in the global automotive production volumes and growth in AI cockpit revenue. The year-on-year decline reflects the expected ramp down of legacy infotainment. NVIDIA has emerged as the industry's leading end-to-end full stack technology provider for self-driving and AI-enabled vehicles. Orin, the SoC that DRIVE self-driving platform is built on delivers an unrivaled 254 trillions of operations per second of performance on industry-leading power efficiency helping to revolutionize the transportation industry.
Our technology leadership has driven a robust rapidly growing set of opportunities. We have great momentum with an expanding list of electric vehicle OEMs including Nio, SAIC, Li Auto, and Xpeng which are all using the NVIDIA DRIVE platform to power their next-generation of vehicles. We look forward to growing with them as they continue to scale. Our software defined platform is the only solution that spans from the data center for training deep neural nets and running physically accurate simulations to a full stack in car solutions, scaling from ADAS to level 5 fully autonomous functionality.
Autonomous vehicle companies are harnessing this technology. Zoox's recently unveiled its level 5 bidirectional robotaxi powered by NVIDIA. Einride launched its next generation cabless autonomous truck using NVIDIA DRIVE Orin, and earlier this year, Mercedes announced a 56-inch wide MBUX's hyper-screen powered by NVIDIA AI cockpit technology. This win builds on our momentum with Mercedes first generation MBUX system, which is now in 1.8 million cars.
We are in the early innings of a significant opportunity. We have built a multi-billion dollar design win pipeline for our self-driving AI cockpit solutions, which will drive a material inflection in revenue over the next few years. Our transformational partnership with Mercedes announced last June demonstrates the power of our evolving business model as we expand our addressable market and layer in software revenue. We are exceptionally well positioned to capitalize on the significant opportunity that lies ahead.
Moving to Data Center. Revenue was $1.9 billion which exceeded our expectations, was comparable to last quarter, and up 97% from the year ago period, which did not include Mellanox. Data Center compute revenue was up 45% year-on-year. Full-year Data Center revenue rose 125% to a record $6.7 billion, including almost 70% growth from data center computer. From a sequential perspective, the Data Center compute's stronger than expected double-digit growth more than offset the anticipated decline in Mellanox revenue, which included a large non-recurring network sale to a single OEM in Q3.
Compute growth was led by vertical industries where OEM partners continued ramping up their A100 based servers and our own DGX system sales were strong. Vertical industries were well over 50% of Data Center revenue across compute and networking with particular strength in supercomputing, financial services, higher education, and consumer Internet verticals. Additionally, hyperscale customers continued to deploy the A100 driving both sequential growth and exceptionally strong year-on-year growth in Data Center compute.
The A100 has been adopted by all major cloud customers globally and is being deployed by hyperscale customers for internal workloads. Still, we are in the early stages of adoption and expect continued growth this year. The ramp of the A100 has been smoother and accomplished by better visibility with higher generation. Its universal AI training and inference capabilities as well as support for a wider set of applications and outstanding performance are driving high customer utilization, a clear sign of the A100's value.
Turning to Mellanox, we are seeing continued strong traction and robust momentum across our customer sets. Its revenue was up over 30% from Mellanox's Q4 revenue in calendar 2019 when it was still a stand-alone company. Year-on-year growth in the quarter was led by hyperscale and large consumer Internet customers which grew over 60% from last year with several contributing record revenues. Consistent with our outlook, Mellanox had a sequential decline impacted by a non-recurring sales to a China OEM in Q3.
We expect to return to sequential growth in Q1 driven by strong demand for our high-speed networking products, including the ramp of ConnectX adapters with CSPs and all major server OEMs in their upcoming refresh. We also see strong momentum in high-performance computing with HDR InfiniBand products. For example, we won six of the seven supercomputers awarded over the past few months by EuroHPC. Starting next quarter, we will continue to provide color on networking as part of the data center market platform, but we will no longer breakout Mellanox revenues separately.
Looking forward, we are incredibly excited about the opportunities in data center. Accelerated computing is not only delivering super Moore's Law [Phonetic] gains in performance but is also an energy efficient and cost effective method of computing and virtually every industry is adopting technology with greater urgency as companies adapt to the new world of more distributed workers and customers. As industries embark on this journey, they are also increasingly focused on combating climate change.
To that end, the A100 performs AI computations with one-twentieth the power consumption of CPUs. It powers our Selene supercomputer which is number one on the Green500 List of the world's most efficient supercomputers. Indeed, NVIDIA's powered machines recently captured 25 of the Top 30 spots on the Green500 List. Accelerated computing is not only serving the exponential growth in demand for compute, it can also help bend the power consumption curve. With accelerated computing, NVIDIA is pioneering a path forward the computing industry.
Before I move to the P&L and outlook, let me give you an update on our proposed acquisition of Arm. In September, we announced plans to acquire Arm from SoftBank Group in a transaction that will create the premier computing company for the age of AI. At that time, we said it would take approximately 18 months to secure regulatory approvals in the U.S., the U.K., the EU, China and other jurisdictions. Thorough reviews are typical with a deal of this size. This process is moving forward as expected. We are in constructive dialog with the relevant authorities and are confident that regulators will see the benefits to the entire tech ecosystem.
As we have said, this combination will spur competition. Together Arm and NVIDIA will provide greater choice to the data center ecosystem, a compelling alternative CPU architecture for the market, and further enhance Arm's offering in mobile and embedded. Our intention is to increase investment in Arm's existing road map, adding resources to stimulate growth in new markets. We love and intend to maintain Arm's open licensing model, a commitment guaranteed both by long-term legally binding contracts as well as our own interest in ensuring this investment is a profitable one for us.
We are on the cusp of a new age in which AI fuels industries ranging from healthcare to scientific research to the environment. With this transaction, our vision is to boost Arm's potential so it can thrive in this new era and grow into promising new markets.
Moving to the rest of the P&L, Q4 GAAP gross margins were 63.1% and non-GAAP gross margins were 65.5%. GAAP gross margins declined year-on-year due to amortization of developed technology acquired from Mellanox, partially offset by product mix. The sequential increase was due to higher margins for Gaming GPU and lower IP-related costs partially offset by lower margin mix in our Data Center portfolio. Non-GAAP gross margins increased by 10 basis points year-on-year and was flat sequentially, in line with our expectations. Q4 GAAP EPS was $2.31, up 51% from a year earlier. Non-GAAP EPS was $3.10, up 64% from a year ago. Q4 cash from operations was a record $2.07 billion.
With that, let me turn to the outlook for the first quarter of fiscal 2022. Revenue is expected to be $5.3 billion plus or minus 2% with most of the sequential growth driven by Gaming. GAAP and non-GAAP gross margins are expected to be 63.8% and 66% respectively plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $1.67 billion and $1.2 billion respectively. For the full year, we expect to grow non-GAAP opex in the mid-20% range.
GAAP and non-GAAP other income and expenses are both expected to be an expense of approximately $50 million. GAAP and non-GAAP tax rates are both expected to be 10% plus or minus 1% excluding discrete items. Capital expenditures are expected to be approximately $300 million to $325 million. Further financial details are included in the CFO commentary and other information on our IR website.
In closing, let me highlight upcoming events for the financial community. We will be virtually attending the Raymond James Institutional Investors Conference on March 1st, the Morgan Stanley Technology Media and Telecom Conference on March 3rd, and the Arete Virtual Semis Conference on March 3rd. In addition, we will be hosting a virtual Investor Day on Monday, April 12th following the live stream of Jensen's opening keynote at our GPU Technology Conference. Our earnings call to discuss our first quarter is scheduled for Wednesday, May 26. We will now open the call for questions. Operator, would you please poll for questions. Thank you.
Operator
[Operator Instructions] Your first question comes from the line of C.J. Muse with Evercore ISI. Your line is open.
C.J. Muse -- Evercore ISI -- Analyst
Good afternoon, thank you for taking the question. I guess, Jensen, higher level question for you on the enterprise side. You're now a couple of quarters into the ramp of A100 and curious if you could speak to whether you've seen any surprises here, any areas of specific strength worth calling out and any changes to how you're thinking about the size of this opportunity?
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah, thanks a lot, C.J. As you know, A100 is a very different type of GPU. This is our first universal computing GPU. It's great at high performance computing, it's great at data analytics, it's great at training and also for our highest-end GPUs, it is also the first time that it is incredible for inference. It's some 20 times faster than previous generation. It introduces some really exciting new computational formats like TF32, TensorFloat 32 for training and with multi-instance GPU, turning our GPU -- one GPU into a whole bunch of smaller GPUs, autonomous GPUs to improve performance and reducing latency.
And so the capability is really quite exciting. We're seeing strength in hyperscalers as they continue to accelerate their adoption of AI. Some of the new applications we've spoken about a couple of times before is the transition to deep learning for conversational AI, speech recognition to natural language understanding all the way to speech synthesis is now based on AI -- based on deep learning. The other area that is growing incredibly fast is deep learning recommender models. Just about everything that we do on the Internet is based on recommenders. There are hundreds of different recommenders out there whether you are shopping or recommending music or recommending news or recommending search and so all of the recommending ads. And so all of these different types of applications are driving value.
For the first time, we saw our industrial application -- industrial data center growing to be larger than hyperscale and we're seeing industrial applications across scientific computing where simulation-based approaches are now being fused with AI approaches for weather simulation, genomics, molecular dynamic simulation, quantum chemistry, even simulating quantum computing which is one of the really exciting areas. We're seeing AI being deployed for big data analytics, RAPIDS which is NVIDIA's creative open-source platform for data analytics.
Spark 3.0 which NVIDIA really led as GPU accelerated. So now you could have big data in the cloud while doing big data analytics in the cloud on all of the CSP platforms. You could -- we're seeing a lot of excitement around financial services. Financial services and consumer Internet services are all really growing nicely. And so A100 adoption is just starting. I mean we're going to see several couple of years of continued growth yet ahead of us as AI gets adopted in clouds and industries.
Operator
Your next question comes from the line of Vivek Arya with BofA Securities. Your line is open.
Vivek Arya -- BofA Securities -- Analyst
Thanks for taking my question. Just a clarification and then a question for Jensen. On the clarification, Colette, I was hoping if you could give a little more color around Q1. Do you still expect the data center to grow sequentially in Q1. I know you said that most of the growth will come from Gaming, but any color on the data center would be useful.
And then Jensen, the question for you is in your press release you used the phrase AI driving the smartphone moment for every industry. Could you help us quantify what that means and where I'm going with that is, is there a number in terms of what percentage of servers are shipping today with your accelerators and where can that ratio go over time. Is that a fair way of looking at the adoption of your technology and AI?
Colette Kress -- Executive Vice President and Chief Financial Officer
So, thank you, Vivek. Your question regarding the guidance as we lead into Q1. We had indicated that yes, a good percentage of our growth between Q4 and Q1 will stem from Gaming but we also do expect Data Center to grow. Most of our sequential growth coming from Gaming, but keep in mind, we also expect all of our market platforms will likely be able to grow quarter-over-quarter.
Jensen Huang -- Founder, President and Chief Executive Officer
Vivek, we're entering the third phase of AI. The first phase of AI was when we invented the computing platforms, the new chips, the new systems, the system software, the new middleware, the new way of working, the new way of developing software, which the industry -- the world is now starting to call MLOps. The way that software is developed and the way that it is deployed is completely different than in the past. In fact, I heard a great term, Software 2.0 and it makes a lot of sense. It's a computer that is writing software. The way that you develop software is completely different, the way compute is different and that was our first phase and that started in the journey that was some eight, nine years ago now.
The second phase was the adoption of using this in an industrial way for clouds and we strongly revolutionized these services whether it's speech oriented services or search oriented services, just recommender services, the way you shop, the way you use the Internet is completely different to and so that's really the second phase and those two phases are still continuing to grow and you're still seeing the growth associated with that. The third phase is the industrialization of AI and some of the great examples when I say kind of the smartphone moment, I meant that it's a device with AI, its autonomous and its connected to a cloud service and its continuously learning. So some of the exciting example that I saw -- that I've seen and we're working with, with companies all over the world, we have some 7,000 AI start-ups that we're working with and almost all of them are developing something like this and large industrial companies whether it's John Deere or Walmart, they are all developing applications kind of like this and basically it's an autonomous system, autonomous machine.
In our case, it's called Jetson, it's a robotics machine. If that robotics machine is a car, then its called DRIVE and it's running an autonomous -- an AI application on top, an AI skill on top and it could be moving things around, it could be picking and placing, it could be just watching a warehouse and monitoring traffic and keeping traffic flow going. It could be connected to a car and whenever the car -- whenever the fleet of cars needs to be retrained because of the new circumstance that was discovered, the cloud service would do the relearning and then would deploy it into all of the autonomous devices.
And so in the future we're seeing that these industries whether you're in retail or in logistics or transportation or farming, ag tech to lawnmowers -- consumer lawnmowers. They're not going to just be products that you buy and use from that point forward, but they will likely be a connected device with an AI service that runs on top of it and so these industries are so excited about it because it gives them an opportunity to change the way that they interact with their customers.
Rather than selling something once, they sell something and provide a service that's on top of that and they could stay engaged with the customers. The customers could get a product that's improving all of the time just like your smartphone and that's kind of like -- that's kind of the reason, that's the reason why I've been calling it the smartphone moment for all these industries and we saw what happened to the smartphone revolution and then we saw what happened to the smart microphone, the smart speaker revolution.
You're going to see smart lawnmowers, smart tractors, smart air conditioners, smart elevators, smart buildings, smart warehouses, robotic retail stores. The entire retail store is like a robot and they will all have autonomous capability, they'll all be driven by AI. And so what's new for the industry therefore is that all of the enterprises in the world used to have computers for IT to facilitate -- to host their employees and their supply chain, but in the future all of these industries whether you are in medical imaging or lawnmowers, you're going to have data centers that are hosting your products just like the CSPs and so that's a brand new industry and we have a platform that we call EGX, which is the 5G Edge AI systems and we have the autonomous system we call AGX, which is [Indecipherable] and between those two systems and the software stack that we have on top of it, we're in a great position to help these industries one at a time transform their business model from the object-oriented business model, a theme based business model to a connected device business model.
Operator
Your next question comes from the line of Stacy Rasgon with Bernstein Research. Your line is open.
Stacy Rasgon -- Bernstein Research -- Analyst
Hi guys, thanks for taking my question. First, I don't want to be pedantic I suppose, but I guess on the Q1 guide, you're saying that Gaming is the majority of the growth. Was that an absolute statement or was that a percentage statement? Can you give some idea of how you would sort of rank the sequential percentage growth of say Gaming versus Data Center versus other especially since it sounds like you've got $50 million in crypto specific stuff that will go into the other.
And then I guess just on briefly, could you give us some indication of where your supply situation and lead times are on your Ampere parts within Data Center. I think you said last quarter, they were many months on -- six months plus. Are they still looking like that and is that sort of the limiting factor at this point in terms of what you can actually ship on the compute side in Data Center?
Jensen Huang -- Founder, President and Chief Executive Officer
Colette will take one and I'll take the other.
Colette Kress -- Executive Vice President and Chief Financial Officer
Sure, let me start off of Stacy in terms of our guidance for Q1. As you know, we're still in the early innings of our Ampere architecture as it relates to Gaming as well as what it relates to Data Center. As we articulated in our call, we have been really seeing continued uplift of folks adoption of A100 and it's going quite smoothly than what we had seen in prior overall versions. So when we think about our guidance for Q1, there's many different types of conclusions that will happen at the end of the quarter in terms of what we ship, but all of our platforms can grow, but the majority of the growth from Q4 to Q1 will likely be Gaming.
Jensen Huang -- Founder, President and Chief Executive Officer
You asked a question about the lead times. At the company level, we're supply constrained. Our demand is greater than our supply. However for Data Center, so long as the customers work closely with us and we do a good job planning between our companies, there shouldn't be a supply issue for Data Centers. We just have to do a good job planning and we have direct relationships with each one of the world CSPs and we have direct relationships with all the OEMs and we can do excellent planning between us. We shouldn't be supply constrained there, but at the company level, we're supply constrained, demand is greater than supply.
We usually have enough supply to achieve better than the outlook and we had that situation in Q4 and we expect that situation in Q1 and we have enough supply to grow through the year, but supply is constrained and demand is really, really great and so we just have to do a really good job on planning. Meanwhile, one of the things that really came through for us is we have the world's best operations team. Our company really has an amazing operations team. We build the most complex products in the world, the most complex chips, the most complex packages, the most complex systems and during Q4, they improved our cycle time and during Q1, I'm expecting them to improve our cycle time again and we really are blessed to have such an amazing operations and so during these times, it really comes in handy, but overall at the company level, we expect demand to be greater than supply. We have enough supply to do better than the outlook and we have enough supply to grow each quarter throughout the year.
Operator
Your next question comes from the line of Timothy Arcuri with UBS. Your line is open.
Timothy Arcuri -- UBS -- Analyst
Hi, thanks, I had a question on crypto. I guess Jensen, I know that the CMP stuff and the software drivers stuff that you're doing for the 36 [Phonetic], that's going to help a lot, but I think that there is like four or five of the big currency are going to move or at least they are moving or they are on a path to move from a proof-of-work to proof of stake, which is going to be a lot less compute intensive. So I guess the question that I get a lot is how do you assess the degree to which that drives GPUs back into the secondary market. Is there any way that you can get kind of a handle on that? Thanks.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah, if you look at the recent hash rates -- first of all, the transition is going to take some time. It can't happen overnight and people have to build trust in all of the new versions and so that will take a little bit of time, but I hope it does. I hope that people use proof of stake over time and a little bit of these questions don't have to be answered. However, I don't have that much optimism either that it will be all proof of stake. I think that proof of work is a very legitimate way of securing the currency and in the beginning while any currency is building its reputation, it's takes something like a proof of work to do so. So I think proof of work is going to be around for a bit.
We developed CMP for this very reason so that there are different versions. We have different versions of our products for Gaming, for Professional Visualization, for high performance computing, for deep learning, it stands to reason we have to build a different version for CMP and we can sell it directly the way that we go to market would be to go to directly to the industrial miners and it's a great benefit to them so that they don't have to chase around spot markets, it's a great benefit to the gamers because they want to game and the game demand is just incredible, it's off the chart and so I think this is going to be really beneficial to everybody.
The recent hash rate growth was really a result of several dynamics. The first dynamic is the installed base. Most people thought that once the mining GPUs come back into the aftermarket, a small part does that, some people do that, but the vast majority of them keep them and the reason for that is because obviously they believe in Ethereum and they are industrial miners, that's what they do and so they keep it around for when the profitability returns and they could kick start their mining gear.
That's what we saw in the latter part of last year. We saw the hash rate starting to grow. Most of that was resulting from the installed miners reactivating their equipment. It wasn't until earlier this year that we started to see demand in our own GPUs and when that starts to happen, there are several different dynamics. The primary source these days come from powerful ASICs and then there are some that comes from our GPU and other GPUs in the marketplace. And so I think that this is going to be a part of our business. It won't grow extremely large no matter what happens and the reason for that is because when it starts to grow large, more ASICs come to the market, which kinds of mutes it and when the market becomes smaller, it's harder for ASICs to sustain the R&D and so the spot miners, industrial miners come back and then we'll create CMPs.
And so we expect it to be a small part of our business as we go forward. One of the important things is to realize that in the near-term because we're in the beginning parts of our Ampere ramp, only two quarters into a multi-year cycle. This is also the first time that we've completely changed our computer graphics. RTX using ray tracing is completely different than rasterization and so this is a fundamental change in the way we do computer graphics and the results have been spectacular. There is some 200 million installed base in desktops and 50 million in laptop and the vast majority of them we've only upgraded like approximately I think its something like 15% of the installed base that's been upgraded to RTX and so there is a giant installed base and the installed base is growing that will need update to the next generation of computer graphics.
Operator
Your next question comes from the line of John Pitzer with Credit Suisse. Your line is open.
John Pitzer -- Credit Suisse -- Analyst
Yeah, guys, thanks for letting me ask the question, I want to go back to Data Center, you've been very kind over the last couple of quarters to call out Mellanox both when it was a positive driver and when it was a headwind. I'm kind of curious as you when you look into the fiscal first quarter, is there anything of distinction to mention around Mellanox versus core Data Center.
And I guess as a follow-on, the key metric that a lot of investors are looking at is when does the core data center business year-over-year growth start to reaccelerate and some of that is just simple math, you're just comping very hard compares from last year, but Jensen, how would you think about Data Center year-over-year growth in the context of a reopening trade or any sort of new applications out there. What helped it last time around was the move to natural language AI, is there another big sort of AI application we should be thinking about as we think about Data Center growth reaccelerating?
Jensen Huang -- Founder, President and Chief Executive Officer
We're expecting -- Mellanox was down this last quarter and our compute business grew double-digit and more than offset the decline in Mellanox. We expect Q1 to be a growth quarter for Mellanox and we expect this coming year to be quite an exciting year for Mellanox. The business is growing and Ethernet [Phonetic] is growing for CSPs is growing in InfiniBand for high performance computing on the switch the switches are growing. Switch business grew 50% year-over-year and so we're seeing really terrific growth there.
One of the new initiatives and we're going to see success toward the second half because the number of adoption and the number of engagements on new BlueField-2 DPUs. It's used for virtualization, for hyperscalers, it's also used for security. As you know quite well, the future of computing is cloud and its multi-tenant cloud and there is no VPN front door to the cloud. You got millions of people who are using every aspect of computing. So you need to have distributed firewalls and you can't have it just in one place. The intense focus of security across all of the data centers around the world is really creating a great condition for BlueField which is really perfect for them.
So I expect our Mellanox networking business to grow very nicely this year and we expect Q1 to be a great growth quarter for compute as well as Mellanox. The great driving application for AI are several. Last year, you're absolutely right [Indecipherable] in other versions like that really made it possible for us to enable all kinds of new applications. So you're going to see natural language understanding do text completion, it's going to be integrated, I think it was just announced today that it was going to be integrated into Microsoft Word.
We've been working with them on that for some time and so some really exciting applications but the new ones that came, that emerged recently are deep learning based conversational AI where the ASR, the speech recognition as well as the speech synthesis are now based on deep learning. It wasn't before. And they were based on models that ran on CPUs but now with these deep learning models, the accuracy is much, much higher and it has the ability to also mimic a voice and be a lot more natural and so the ability to -- these models are much more complex, they are much larger.
The other big huge driver is recommenders. This is something really worthwhile to take a look at it, it's called deep learning recommender models and recommenders have historically whether it's for shopping or personalizing websites or personalizing your store, recommending your basket, recommending your music. Historically it's been used in traditional machine learning algorithms, but because of the accuracy and just the extraordinary economic impact that comes from an incremental 1% in accuracy for most of the world's large Internet businesses, people are moving very rapidly to deep learning based model and these models are gigantic, they are utterly gigantic and so this is an area that is really driving high performance computing. I expect this to see a lot of momentum.
And the last one is the one that I just spoke about, which has to do with industrial 5G and Edge IoT type of applications for all of the different industries whether it's retail or logistics or transportation, agriculture or warehouses to factories. And so we're going to see AI and robotics in a very large number of applications and industries and we're just seeing so much excitement there.
Operator
Your next question comes from the line of Aaron Rakers with Wells Fargo. Your line is open.
Aaron Rakers -- Wells Fargo -- Analyst
Yeah, thanks for taking the questions. I wanted to go back again on the Data Center business that you just mentioned, Jensen, that the BlueField-2 product poised to kind of ramp materialize in the back half of the calendar year. How do you see that? Is it an attach rate? I think there's some discussions in the past about all servers could potentially over time incorporate this layer of acceleration. How quickly should we think about that ramp? And then the second question, can you just at a high level talk about how a CPU strategy you're thinking about that in the context of the broader data center market?
Jensen Huang -- Founder, President and Chief Executive Officer
Sure, if I could just work backwards, I believe that every single data center node will be outfitted with a DPU some day and that some day is probably call it five years from now and the fundamental driver of it is going to be security. Every single application in the data center and every single node in the data center has to be individually secured. Zero Trust computing, zero or confidential computing or Zero Trust computing, these initiatives are going to cause every data center to have every single application and every single node to be secured, which was every one of those computers have to have a control plane that is isolated from the application plane and all the applications cannot share the same resources because that application could be malware, that application could be an intruder.
No application could have access to the control plane and yet today, the software defined data centers, the software defined networking, software defined storage, all of the security agents are running in the same processors as the applications and that has to change. You see the cloud -- the CSPs in the world are moving in this direction. Every single data center will have to move in this direction. So every node will be DPU processed for the software for the infrastructure. You're essentially going to see the data center infrastructure be offloaded from the application plane and it will be something like a BlueField. So I think this is our next multi-billion dollar opportunity.
CPUs, we support every CPU in the world and we're the only accelerated computing platforms that accelerates every CPU. Ironically, the only CPU we don't accelerate for AI is Arm, but we want to change that. Arm has such an exciting future because the nature of their business model and the nature of their architecture is perfect for the future of hyperscalers and data centers. You want the most energy efficiency in every single data center because every data center is power constrained. We are going to be power constraining in every aspect of computing going forward.
And so we would love to build around the Arm processor and invest in building a great ecosystem around it so that all the world's peripherals and all the world's applications can work on any one of the CPUs that we know today and so we're going to start with high performance computing and start with AI and all the areas that we have a lot of expertise in and build out that platform. So you're starting to see one industry leader after another embrace Arm and I think that's terrific, but now we've got to energize it with all of the ecosystem support. It can't just be vertical applications, but we want to create a broad general Arm ecosystem.
Operator
Your next question comes from the line of Mark Lipacis with Jefferies. Your line is open.
Mark Lipacis -- Jefferies -- Analyst
Hi, thanks for taking my question. Question for Jensen I think. Jensen, if you look at the past computing eras, typically, it's one ecosystem that captures 80% of the value of that computing era. In mainframes, it was IBM; in mini computers,it was DEC; PCs, Wintel; Cell phones, Nokia and then Apple. So if you don't get the ecosystem right then you're splitting 20% of the market with a handful of players. So in this next era of computing, parallel processing or AI, I think you've articulated the most compelling architectural vision of the data center of the future with data center scale, computing devices, with CPUs, GPUs, DPUs integrated in the same box serving all workloads, I imagine a virtualized environment. Can you help us understand where is the market in embracing that vision and where is NVIDIA in building out the ecosystem for that data center scale computing vision and maybe as part of that, to what extent is CUDA the kernel for that ecosystem? Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah, I think we've done a great job building out the platforms for several ecosystems around the world and the domains that we do incredibly well at are the domains that have to do with accelerated computing. We pioneered this approach and we brought it to high performance computing at first and we accelerated scientific computing and we democratized supercomputing for all researchers. Anybody who wants to have a supercomputer now can and computing will simply not be the obstacle to somebody's discovery [Phonetic]. We did the same for artificial intelligence, we did the same for visualization, we brought -- we expanded the reach of gaming tremendously. GeForce today is the largest gaming platform. It's the single largest body of computers that are used for gaming and in each case, we expanded the market tremendously.
We would like to do the same for data center scale computing as it applies to virtualizing these applications. These applications are also in the process. They've historically required dedicated systems, but they are moving into a virtualized data center environment and we are best at doing that. They run on our platform today. We have the ability to virtualize it and put it into the data center and make it remotely available and so these applications or these domains are some of the most important domains in the world and so we're in the process of doing that. By doing so and making our architecture available to CSPs and OEMs, we could create this accelerated computing platform available to everybody and so that's -- you're seeing our journey doing that.
First, creating and architecting this platform and then putting it literally into every single data center in the world. We would also like to -- the next step of our journey is the Phase 3 of AI and has to do with turning every endpoint into a data center whether it's a 5G tower, a warehouse, a retail store, a self-driving car, a self-driving truck. These are going to be -- they're all going to be essentially autonomous data centers and they're going to run AI, but they're going to run a lot more, they are going to do security in real-time. It's networking is going to be incredible, it's going to run software 5G and GPU accelerated 5G we call Aerial and so these platforms are going to become data centers that will be secure.
The software is protected and you can't tamper with it. If you tamper with it, it of course won't run and so the capability of these clouds will move all the way out to the edge and we're in the best position to be able to do that. So I think in this new world of post Moore's Law, post the NOW [Phonetic] gaming, in this new world where AI and software that writes software, in this new world where data centers are going to be literally everywhere and they are unprotected. I mean there's no giant building with a whole bunch of people to secure it and in this new world where software is going to enable this autonomous future. I think we are perfectly positioned for it.
Operator
This is all the time we have for our Q&A today. I will now turn the call back to CEO, Jensen Huang.
Jensen Huang -- Founder, President and Chief Executive Officer
Thanks for joining us today. Q4 capped a truly breakout year for NVIDIA. The two biggest engines of our business, Gaming and Data Center posted powerful growth. Gaming has become the world's largest media and entertainment industry and will grow to be much larger. And again, gamers will create and will play, they will learn, they will connect. The medium of gaming can host any type of game and eventually evolve into countless meta verses, some for play, some for work. Gaming is simultaneously a great technology and a great business driver for our company. This year, we also closed our Mellanox acquisition and successfully united amazing talent of our companies. Combined, we possess deep expertise in all aspects of computing and networking to drive the architecture of modern data centers.
Cloud computing and hyperscalers have transformed the data center into the new unit of computing. Chips and servers are just elements of the data center scale computers now. With our expertise in AI computing, full stack accelerated computing, our deep network to computing expertise, and cloud to edge platforms, NVIDIA is helping to drive a great computer industry transformation. And our planned acquisition of Arm, the world's most popular and energy efficient CPU company, will help position NVIDIA to lead in the age of AI.
This year was extraordinary. The pandemic will pass, but the world has been changed forever. Technology adoption is accelerating across every industry. Companies and products need to be more remote and autonomous. This will drive data centers, AI, and robotics. This underlies the accelerated adoption of NVIDIA's technology. The urgency to digitize, automate, and accelerate innovation has never been higher. We are ready. We look forward to updating you on our progress next quarter. Thanks a lot.

--- Q1 2022 ---
Simona Jankowski, you may begin your conference.
Simona Jankowski -- Investor Relations
Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the first quarter of fiscal 2022. With me on the call today from NVIDIA are Jensen Huang, President and Chief Executive Officer; and Colette Kress, Executive Vice President and Chief Financial Officer.
I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the second quarter of fiscal 2022. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent.
During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission.
All our statements are made as of today, May 26, 2021, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website.
With that, let me turn the call over to Colette.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, Simona.
Q1 was exceptionally strong with revenue of $5.66 billion and year-on-year growth accelerating to 84%. We set a record in total revenue in Gaming, Data Center and Professional Visualization, driven by our best ever product lineups and structural tailwinds across our businesses.
Starting with Gaming, revenue of $2.8 billion was up 11% sequentially and up 106% from a year earlier. This is the third consecutive quarter of accelerating year-on-year growth beginning with the fall launch of our GeForce RTX 30 Series GPUs. Based on the Ampere GPU architecture, the 30 series has been our most successful launch ever, driving incredible demand and setting records for both desktop and laptop GPU sales. Channel inventories are still leading and we expect to remain supply constrained into the second half of the year.
With our Ampere GPU architecture now ramping across the stack in both desktops and laptops, we expect the RTX upgrade cycle to kick into high gear, as the vast majority of our GPU installed base needs to upgrade. Now Laptops continue to drive strong growth this quarter as we started ramping the Ampere GPU architecture across our lineup. Earlier this month, all major PC OEMs launched GeForce RTX 30 Series laptops based on the 3080, 3070 and 3060, as part of their spring refresh. In addition, mainstream versions based on the 3050 and 3050 Ti will be available this summer just in time for back-to-school starting at price points as low as $799.
This is the largest ever wave of GeForce gaming laptops, over 140 in total as OEMs address the rising demand for gamers, creators and students for NVIDIA's powered laptops. The RTX 30 Series delivers our biggest generational ray tracing [Phonetic] performance ever. It also features our second-generation ray tracing technology and frame rate boosting, AI-powered DLSS. The RTX is a reset for graphics with over 60 accelerated games. This quarter, we added many more, including Call of Duty, Modern Warfare, Crysis Remastered and Outriders. We also announced that DLSS is now available in Unreal Engine 4 and soon in the Unity game engine, enabling game developers to accelerate frame rates with minimal effort.
The RTX 30 Series also offers NVIDIA Reflex, a new technology that reduces system latency. Reflex is emerging as a must-have feature for eSports gamers who play competitive titles like Call of Duty: Warzone, Fortnite, Valorant and Apex Legends. We estimate that about 75% of GeForce gamers play eSport games and 99% of eSports pros compete on GeForce.
We believe gaming also benefited from crypto mining demand, although it's hard to determine to what extent. We've taken actions to optimize GeForce GPUs for gamers, while separately addressing mining demand with crypto currency minding processors, or CMPs. last week, we announced that newly manufactured GeForce RTX 3080, RTX 3070, and RTX 3060 Ti graphics cards will have their Ethereum mining capabilities reduced by half and carry a low hash rate, or LHR identifier. Along with the updated RTX 3060, this should allow our partners to get more GeForce cards into the hands of gamers at better prices. To help address mining demand, CMP products launched this quarter, optimized for mining performance and efficiency. Because they don't meet the specifications required of a GeForce GPU, they don't impact the supply of GeForce GPUs to gamers. CMP revenue was $155 million in Q1, reported as part of the OEM and other category. And our Q2 outlook assumes CMP sales of $400 million.
Our GeForce NOW cloud gaming platform passed 10 million registered numbers this quarter. GFN offers nearly 1,000 PC games from over 300 publishers, more than any other cloud gaming service including 80 of the most popular free to game -- play games. GFN expands the reach of GeForce to billions of under-powered Windows PCs, Macs, Chromebooks, Android devices, iPhones and iPads. GFN is offered in over 70 countries with our latest expansions including Australia, Singapore and South America.
Moving to Pro Vis. Q1 revenue was $372 million, up 21% both sequentially and year-on-year. Strong notebook growth was driven by a new, sleek and powerful RTX-powered mobile workstations with Max-Q technology and the enterprises continue to support remote workforce initiatives. Desktop workstations rebounded as enterprise resumed the spending that has been deferred during the lockdown with continued growth likely as offices open. Key verticals driving Q1 demand include manufacturing, healthcare, automotive, and media and entertainment.
At GTC we announced the upcoming general availability of NVIDIA Omniverse Enterprise, the world's first technology platform that enables global 3D design teams to collaborate in real time in a shared space, working across multiple software speeds. This incredible technology builds on NVIDIA's entire body of work and is supported by a large, rapidly growing ecosystem. Early adopters include sophisticated design teams at some of the world's leading companies such as BMW Group, Foster and Partners and WPP. Over 400 companies have been evaluating Omniverse and nearly 17,000 users have downloaded the open beta. Omniverse is offered as a software subscription on a per-user and a per-server basis. As the world becomes more digital, virtual and collaborative, we see a significant revenue opportunity for Omniverse. We also announced powerful new Ampere architecture GPUs for next-generation desktop and laptop workstation. The new RTX-powered workstations will be available from all major OEMs.
Moving to automotive, Q1 revenue was $154 million, up 6% sequentially and down 1% year-on-year. Growth in AI cockpit revenue was partially offset by the expected decline in legacy infotainment revenue. We extended our technology leadership with the announcement of the next generation NVIDIA DRIVE Atlan SOC. Atlan will deliver an unrivaled 1,000 trillion operations per second of performance and integrate data center class NVIDIA BlueField networking and security technologies to enhance vehicle performance and safety, making it a true data center on wheels.
Atlan, which targets automakers' 2025 models, will follow the NVIDIA DRIVE Orin SOC which delivers 254 TOPS that has been selected by leading vehicle makers for production timeline starting next year. The NVIDIA DRIVE platform has achieved global adoption across the transportation industry. Our automotive design win pipeline now exceeds 8 billion through fiscal 2027. Most recently for Volvo Cars announced that it will use NVIDIA DRIVE Orin, building on our next great momentum with some of the largest automakers including Mercedes-Benz, SAIC and Hyundai Motor Group.
In robotaxis, we added GM Cruise to the growing number of companies adopting the NVIDIA DRIVE platform, which include Amazon Zoox and DiDi. We've also had a great traction with new energy vehicle makers. Our latest wins include Faraday Future, R Auto, IM Motors, and VinFast, which joined previously announced wins with SAIC, Nio, Xpeng and Li Auto.
In trucking, Navistar is partnered with TuSimple in selecting NVIDIA DRIVE for autonomous driving, joining previously announced Volvo Autonomous Solutions and plus [Phonetic]. NVIDIA is helping to revolutionize the transportation industry. Our full stack software-defined AV and AI cockpit platform spans silicon, systems, software and AI data center infrastructure, enabling over-the-air upgrades to enhance safety and the joy of driving throughout the vehicle's lifetime. Starting with our lead partner, Mercedes-Benz, NVIDIA DRIVE can transform the automotive industry with amazing technologies delivered through new software and services business models.
Moving to Data Center. Revenue topped $2 billion for the first time, growing 8% sequentially and up 79% from the year-ago quarter, which did not include Mellanox. Hyperscale customers led our growth this quarter as they built infrastructure to commercialize AI in their services. In addition, cloud providers have adopted the A100 to support growing demand for AI from enterprises, start-ups and research organizations. Customers have deployed NVIDIA's A100 and DGX platforms to train deep neural networks with rising computational intensity led by two of the fastest growing areas of AI; natural language understanding and deep recommendators.
In March, Google Cloud platform announced general availability of the A100 with early customers including Square for its cash application and Alphabet's DeepMind. The A100 is deployed across all major hyperscale and cloud service providers globally and we see strengthening demand in the coming quarters. Every industry is becoming a technology industry and accelerating investments in AI infrastructure both through the cloud and on-premise. Our vertical industries global sequentially and year-on-year led by consumer internet companies. For example, NAVER, a leading internet technology company in Korea and Japan, is training giant AI language models at scale on DGX SuperPOD to pioneer new services across e-commerce, search, entertainment, and payment applications.
We continue to gain traction in inference with hyperscale and vertical industry customers across a broadening portfolio of GPUs. We had record shipments of GPUs used for inference. Inference growth is driving not just the T4, which was up strongly in the quarter, but also the universal A100 Tensor Core GPU as well as the new Ampere architecture-based A10 and A30 GPUs, all excellent at training as well as inferencing.
Customers are increasingly migrated from CPUs to GPUs for AI inference for two chief reasons. First, GPUs can better keep up with the exponential growth in the size and the complexity of deep neural networks and respond with the required low latency. In April's MLPerf AI inference benchmark, NVIDIA achieved the top results across every category, spanning computer vision, medical imaging, recommender systems, speech recognition, and natural language processing; and second, NVIDIA's full stack inference platform including Triton's inference server software simplifies the complexity of deploying AI applications by supporting models from all major frameworks, and optimizing for different query types including batch, real time and streaming. Triton is supported by several partners in the cloud services, including Amazon, Google, Microsoft and Tencent. Examples of how customers use NVIDIA's inference platform includes Microsoft for grammar checking in Office, the United States Postal Service for real-time package analytics, T-Mobile for customer service, Pinterest for image search, and GE Healthcare for heart disease detection.
We also had strong results with Mellanox networking products. Like our compute business, strong growth was driven by hyperscale customers across both Ethernet and InfiniBand. We achieved key design wins and proof-of-concept trials through the NVIDIA BlueField-2 DPU with cloud service providers and consumer internet companies. We also unveiled BlueField-3, the first GPU built for AI and accelerated computing with support from VMware, NetApp, Splunk, Cloudflare, and others.
Bluefield-3 is the industry's first 400 gig DPU and delivers the equivalent data center services of up to 300 CPU cores. It transforms traditional server infrastructure into zero trust environment in which every user is authenticated by offloading and isolating data center services for business applications. With Bluefield-3, our DPU roadmap will deliver an unrivaled 100x performance increase over a three-year period. As we look back at the first full year since closing the Mellanox acquisition, we are extremely pleased with how the business has performed. It has not only exceeded our financial projections, but it has been instrumental in key new platforms like the DGX SuperPOD and the BlueField DPU, enabling our Data Center scale computing strategy.
In April, we held our largest ever GPU Technology Conference with more than 200,000 registrants from 195 countries. Jensen's keynote had over 14 million views. At GTC, we announced our first data center CPU, NVIDIA Grace, targeted processing massive next-generation AI models with trillions of parameters. The Arm-based processor will enable 10 extra performance and energy efficiency of today's fastest servers. With Grace, NVIDIA has a three chip strategy with GPU, DPU and now CPU. The Swiss National Supercomputing Center and the US Department of Energy's Los Alamos National Laboratory are the first to announce plans to build Grace-powered supercomputers.
Grace will be available in early 2023.
GTC is first and foremost for developers. We announced NVIDIA developed and optimized pre-trained model availability on the NVIDIA GPU Cloud registry. Developers can choose a pre-trained model and adapt it to fit their specific needs using NVIDIA TAO, our transfer learning software. TAO fine tunes the model with customer's own small data set to get models accustomed to it without the cost, time and massive data sets required to train a neural network from scratch. Once a model is optimized and ready for deployment, users can integrate it with a NVIDIA application framework that fits their use.
For example, the NVIDIA Jarvis framework for interactive conversational AI is now generally available and used by customers such as T-Mobile and Snap and the NVIDIA MERLIN framework for deep recommendators is an open beta with customers such as Snap and Tencent. With the chosen application framework, users can launch NVIDIA Fleet Command software to deploy and manage the AI application across a variety of NVIDIA GPU-powered devices.
For enterprise customers, we unveiled a new enterprise-grade software offering available as a perpetual license or subscription, NVIDIA AI Enterprise, is a comprehensive suite of AI software that speeds development and deployment of AI workloads and simplifies management of enterprise AI infrastructure. Through our partnership with VMware, hundreds of thousands of vSphere customers will be able to purchase NVIDIA AI Enterprise with the same familiar pricing model that IT managers use to procure VMware Infrastructure software.
We also made several announcement at GTC about accelerating the delivery of both NVIDIA AI and accelerated computing to enterprises and edge users among the world's largest industries. Leading server OEMs launched NVIDIA-certified systems, which are industry standard servers based on the NVIDIA EGX platform. They run NVIDIA AI Enterprise software and are supported by the NVIDIA A30 and A10 GPUs. Initial customers including Lockheed Martin, and Mass General Brigham.
In addition, we announced the NVIDIA AI on 5G platform supported on NVIDIA EGX servers to enable high performance 5G ram and AI applications. The AI on 5G platform leverages the NVIDIA Aerial software and the NVIDIA Bluefield-2 A100 converged card which combines our GPUs and DPUs. We are teaming with Fujitsu, Google Cloud, Mavenir, Radisys and Wind River in developing solutions based on our AI on 5G platform to speed the creation of smart cities and factories, advanced hospitals and intelligent stores.
Another highlight at GTC was the announcement of a broad range of initiatives to strengthen the Arm ecosystem across cloud, data centers, HPC, enterprise and edge, and PCs. In the cloud, we are bringing together AWS Graviton2 processors and NVIDIA GPUs to provide a range of benefits including lower-costs support for richer game streaming experiences and greater performance for Arm-based workloads. In HPC, we are bringing together an Ampere Altra CPU with NVIDIA GPUs, DPUs and NVIDIA HPC Software Development Kit.
Initial supercomputing centers deploying it include Oak Ridge and Los Alamos National Labs. In the enterprise and edge, we're bringing together Marvell Arm-based OCTEON processors and the NVIDIA GPUs to accelerate video analytics and cybersecurity solutions. And in PCs, we are bringing together MediaTek's Arm-based processors with NVIDIA's RTX GPUs to enable realistic ray-trace graphics and cutting edge AI in a new class of Arm-based laptops.
On our Arm acquisition, we are making steady progress in working with the regulators across key regions. We remain on track to close the transaction within our original timeframe of early 2022. Arm's IP is widely used, but the Company needs a partner that can help it achieve new heights. NVIDIA is uniquely positioned to enhance Arm's capabilities, and we are committed to invest in developing the Arm's ecosystem, enhancing R&D, adding IP and turbocharging its development to grow into new markets in the data center, IoT and embedded devices; areas where it only has a light footprint, or in some cases, none at all.
Moving to the rest of the P&L, GAAP gross margin for the first quarter was down 100 basis points from a year earlier and up 100 basis points sequentially. Non-GAAP gross margin was up 40 basis points from a year earlier and up 70 basis points sequentially. The sequential non-GAAP increase was largely driven by a more favorable mix within data centers and the addition of CMP products. Q1 GAAP EPS was $3.03, up 106% from a year earlier. Non-GAAP EPS was $3.66, up 103% from a year ago. Q1 cash flow from operations was $1.9 billion.
Let me turn to the outlook for the second quarter of fiscal 2022. We expect broad-based sequential year-on-year revenue growth in all of our markets platforms.
Our outlook includes $400 million in CMP. Aside from CMP, the sequential revenue increase in our Q2 outlook is driven largely by data center and gaming. In data center, we expect sequential growth in both compute and networking. In gaming, with the move to low hash rate GeForce CPUs and increase in the amount of CMP products, we are making a significant effort to serve liners with CMPs and provide more GeForce cards to gamers. If there is additional CMP demand, we have supply flexibility to support it. We believe these actions, combined with strong gaming demand, will drive an increase in our core gaming business for Q2.
Now to look at our outlook for Q2, revenue is expected to be $6.3 billion, plus or minus 2%. GAAP and non-GAAP gross margins are expected to be 64.6% and 66.5%, respectively, plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $17.6 billion and $1.26 billion, respectively. GAAP and non-GAAP other income and expenses are both expected to be an expense of approximately $50 million. GAAP and non-GAAP tax rates are both expected to be 10%, plus or minus 1%, excluding discrete items. Capital expenditures are expected to be approximately $300 million to $325 million. Further financial details are included in the CFO commentary and other information available on our IR website.
In closing, let me highlight that Jeff Fisher and Manuvir Das will keynote Computex on the evening of May 31, U.S. time, as well as several upcoming events for the financial community. We'll be virtually attending the Evercore TMT Conference on June 7, the BofA 2021 Global Technology Conference on June 9 and the NASDAQ Virtual Investor Conference on June 16. Our earnings call to discuss our second quarter results is scheduled for Wednesday, August 18.
With -- now, we will open the call for question. Operator, would you please poll for questions?
Operator
[Operator Instructions] And your first question comes from Timothy Arcuri with UBS.
Timothy Arcuri -- UBS -- Analyst
Thanks a lot. Colette, I was wondering if you can double click a little more on the guidance. I know, of the 600 to 650 [Phonetic] in growth, you said 250 [Phonetic] is coming from CMP and both Gaming and Data Center will be up. I -- can we assume that they're up about equally, so you're getting about 200 roughly from each of those?
And I guess, second part of that is, within Data Center, I'm wondering, can you speak to the networking piece? It sounds like maybe it was up a bit more modestly than it's been up the past few quarters. I'm just wondering what the outlook is there. Thanks.
Colette Kress -- Executive Vice President and Chief Financial Officer
Yeah. Thanks so much for the question on our guidance. So I first want to start off with, we see demand really across all of our markets, all of our different market platforms, we do plan to grow sequentially. You are correct that we are expecting increase in our CMP and outside of our CMP growth, we expect the lion share of our growth to come from our Data Center and Gaming. In our Data Center business, right now, our product lineup couldn't be better. We have a strong overall portfolio both for training and inferencing and we're seeing strong demand across our hyperscales and vertical industries.
We've made a deliberate effort on the Gaming perspective to supply to our gamers the cards that they would like, given the strong demand that we see. So that will also support the sequential growth that we're receiving. So you're correct that we do see it -- growth sequentially coming from Data Center and Gaming, both contributing quite well to our growth.
Timothy Arcuri -- UBS -- Analyst
Thanks a lot, Colette.
Colette Kress -- Executive Vice President and Chief Financial Officer
I didn't answer your second question, my apologies, on Mellanox. Additionally, Mellanox is an important part of our data center. It is quite integrated with our overall products. We did continue to see growth. This last quarter and we are also expecting them to sequentially grow as we move into Q2. They are smaller part of our overall Data Center business. But again, we do expect them to grow.
Operator
And your next question comes from C.J. Muse with Evercore ISI.
C.J. Muse -- Evercore ISI -- Analyst
Yeah, good afternoon, thank you for taking the question. In your prepared remarks, I think I heard you talk about a vision for acceleration in data center as we go through the year. And as you think about the purchase obligations that you reported, up 45% year-on-year, how much of that is related to long lead time data center and how should we interpret that in terms of what kind of ramp we could see in the second half, particularly as you think about perhaps adding more growth from enterprise on top of what was hyperscale-driven growth in the April quarter? Thank you.
Colette Kress -- Executive Vice President and Chief Financial Officer
So let me take the first part of your question regarding our purchasing, our purchasing of inventory and what we're seeing in just both our purchase commitments and our inventory. The market has definitely changed to where long lead times are required to build out our Data Center products. So we're on a steady stream to both commit longer term so that we can make sure that we can serve our customers with the great lineup of products that we have. So yes, a good part of those purchase commitments is really about the long lead times of the components to create the full systems.
I will turn the second part of the question over to Jensen.
Jensen Huang -- Founder, President and Chief Executive Officer
What was the second part of the question, Colette?
Colette Kress -- Executive Vice President and Chief Financial Officer
The second part of the question was what do we see in the second half as it relates to the lineup of enterprise? And we articulated in our pre-remarks regarding -- that we see an acceleration. Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. Yeah, we're seeing strength across the board in Data Centers and we're seeing strengthening demand. C.J., our data centers, as you know, is accelerating range of applications from scientific computing, both physical and life sciences, data analytics and classical machine learning, cloud computing and cloud graphics, which is becoming more important because of remote work and very importantly, AI, both for training, as well as inferencing for classical machine learning models like XGBoost, all the way to deep learning based models like conversational AI, natural language understanding, recommender systems and so on. And so, we have a large suite of applications and our NVIDIA AI and NVIDIA HPC as the case, accelerate these applications and data centers. They run on systems that range from HGX for the hyperscalers to DGX for on-prem to EGX for enterprise and edge, all the way out to our AGX, autonomous systems.
And this quarter, at GTC, we announced one of our largest initiatives and it's taken us several years, you've seen working on it in open -- out in the open over the course of the last several years and it's called EGX, it's our enterprise AI platform. We're democratizing AI, we'll bring it out of the cloud, we'll bring it to enterprises and we'll bring it out to the edge. And the reason for that is because the vast majority of the world at the automation that has to be done has data that has data sovereignty issues or data rate issues that can't move to the cloud easily. And so we have to move the computing to the premise and oftentimes, all the way up to the edge. The platform has to be secure, has to be confidential, it has to be remotely manageable and of course, it has to be high-performance and it has to be cloud-native, and that's a -- be built like a cloud, the modern way of building cloud data centers.
And so these stacks has to be modern on the one hand, it has to be integrated into classical enterprise systems on the other hand, which is the reason why we've worked so closely with VMware and accelerated VMware's operating system, data center our operating system, software-defined data center stacks on BlueField. Meanwhile, we reported NVIDIA AI and NVIDIA HPC on to VMware, so that they could run distributed large-scale accelerated computing for the very first time. And that partnership that was announced at VMworld, it was announced at GTC and we're in the process of going to the market with all of our enterprise partners, their OEMs, their value-added resellers, their service -- their solution integrators, all over the world.
And so, this is a really large endeavor and the early indications of it are really exciting and the reason for that is because, as you know, our data center business is more than 50% vertical industry enterprise already. It's more than 50% vertical industry enterprises already and by creating this easy-to-adapt and easy-to-integrate stack is going to allow them to move a lot faster. And so this is the next major wave of AI. This is a very exciting part of our initiative and it's something that I've been working on for -- we've been working on for quite a long time and so I'm delighted with the launch this quarter at GTC.
The rest of the data center is doing great too. As Colette mentioned, hyperscale demand is strengthening. We're seeing that for computing and networking. You know that the world's cloud data centers are moving to deep learning because every small percentage that they get out of predictive inference drives billions and billions of dollars of economics for them. And so, the movement toward deep learning shifts the data center workload away from CPUs because accelerators are so important. And so, hyperscale, we're seeing great traction and great demand.
And then lastly, supercomputing; supercomputing centers all over the world are building out and we're really in a great position there to fuse for the very first time simulation-based approaches as well as data-driven-based approaches, what is called artificial intelligence. And so across the board, our data center is gaining momentum. And we see -- we just see great strength right now and it's growing strength and what really set up for years of growth in data center. This is the largest segment of computing as you know and this segment of computing is going to continue to grow for some time to come.
Operator
And your next question comes from Aaron Rakers with Wells Fargo.
Aaron Rakers -- Wells Fargo -- Analyst
Yeah, thanks for taking the questions. Congratulation on the results. I'm going to try to slip in two of them here. First of all, Colette, I think in the past, you talked about how much of your gaming installed base is kind of on the pre-ray tracing platforms are really kind of in context behind the upgrade cycle, that's still in front of us. That's going to question one.
And then, on the heels of the last question, I'm just curious, things like VMware's Project Monterey as we think about the BlueField-2 product and Bluefield-3, how should we think about those starting to become or when should they become really material incremental revenue growth contributors for the Company? Thank you.
Colette Kress -- Executive Vice President and Chief Financial Officer
So, yeah, we have definitely discussed in terms of the great opportunity that we have in front of us of folks moving to our ray-traced GPUs and we're in the early stages of that. We had a strong cycle already, but still we probably have approximately 15% moving up a little bit from that at this time. So it's a great opportunity for us to continue to upgrade a good part of that installed base, not only just with our desktop GPUs, but the RTX laptops are also a great driver of growth and upgrading folks to RTX.
Jensen Huang -- Founder, President and Chief Executive Officer
Colette, do you want me take the second one?
Colette Kress -- Executive Vice President and Chief Financial Officer
Yes, please.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. Aaron, good -- great question on BlueField. First of all, the modern data center has to be rearchitected for several reasons. There are several fundamental reasons that makes it very, very clear that the architecture has to change. The first insight is it's cloud-native, which means that a data center is shared for everybody. You talk to a tenant [Phonetic], you don't know who is coming and going and it's exposed to everybody on the Internet.
Number two, you have to assume that it's a zero-trust environment because you don't know who's using it. That used to be that we have perimeter security, but those days are gone, because it's called native, its remote access, it's multi-tenant, you're -- it's public cloud, the infrastructure is used for internal and external applications. So number two has to be -- it has to be zero trust.
The third reason is something that started a long time ago, which is software-defined in every way because you want -- you don't want a whole bunch of bespoke custom gear inside a data center. You want to operate the data center with software, you want it to be software-defined. The software-defined data center movement enabled this one pane of glass, a few IT managers orchestrating millions and millions of nodes of computers at one place. And the software runs what used to be storage, networking, security, virtualization, and all of that -- all of those things have become a lot larger and a lot more intensive and it's consuming a lot of the data center. And in fact, the estimate depending on how you want to think about how much security you want to put on it, if you assume that it's a zero-trust data center, probably half of the CPU cores inside the data center is running not applications and then that's kind of strange because you created the data center to run services and applications, which is the only thing that makes money.
The other half of the computing is completely soaked up running the software-defined data center, just to provide for those applications. And that you could imagine, even accepting if you like, as the cost of doing business. However, it commingles the infrastructure, the security plane and the application plane and exposes the data center to attackers. And so you fundamentally want to change the architecture as a result of that. To offload that software-defined virtualization and the infrastructure operating system, if you will, and the security services to accelerate it, because Moore's Law has ended and moving software that was running on one set of CPUs, which is really, really good already, to another set of CPUs is going to make it more effective. Separating it doesn't make it more effective.
And so, do you want to offload that and take the -- take that application and software and accelerate it using accelerators, a form of accelerated computing. And so that's -- these things are fundamentally what BlueField is all about. And we created the processor that allows us to do -- BlueField-2 replace as approximately 30 CPU cores, BlueField-3 replaces approximately 300 CPU cores, which is -- to put it, give you a sense of it and a BlueField-4, we're in the process of building already. And so we've had a really aggressive pipeline to do this.
Now, how big is this market? The way to think about that is every single networking chip in the world will be a smart networking chip. It will be a programmable, accelerated infrastructure processor. And that's what the DPU is. It's a data center on a chip. And I believe every single server node will have it, it will replace today's mix with something like BlueField, and it will offload about half of the software processing that's consuming data centers today, but most importantly, it will enable this future world where every single packet, every single application is being monitored in real time all the time for intrusion. And so how big is that application, how big is that market? Just 25 million servers a year, that's the size of the market and we know the servers are growing. And so those give you a feeling for that.
And in the future, servers are going to move out to the edge and all of those edge devices will have something like BlueField. And then how we're doing? We're doing PLCs now with just about every Internet company. We're doing really exciting work there. We've included it in high-performance computing, so that it's possible for supercomputers in the future to be cloud-native, to be zero-trust, to be secured, and still be a supercomputer, and then we expect next year to have meaningful, if not significant revenues contribution from BlueField, and this is going to be a really large growth market for us. You can tell, I'm excited about this and I put a lot of my energy into it. The Company is working really hard on it, and this is a form of accelerated computing, that's going to really make a difference.
Operator
And your next question comes from Vivek Arya with Bank of America Securities.
Vivek Arya -- Bank of America Securities -- Analyst
Thanks for taking my question. Jensen, is NVIDIA able to ring fence, this crypto impact in your CMP product? So even if, let's say crypto goes away, for whatever reason, the decline is a lot more predictable and manageable than what we saw in the 2018, '19 cycle. And then kind of part B of that is, how do you think about your core PC gamer demand? Because when we see these kind of 106% year-on-year growth rate, it brings questions of sustainability. So give us your perspectives on these two topics, just how does one ring fence kind of the crypto effect and what do you think about the sustainability of your core PC gamer demand? Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Sure. Thanks a lot. First of all, it's hard to estimate exactly how much and where crypto mining is being done. However, we can only assume that the vast majority of it is contributed by professional miners, especially when the amount of mining increases tremendously like it has. And so we created the CMP and GeForce for mining, but you can't use CMP for gaming. CMP is -- yields better, and producing those doesn't take away from the supply of GeForce. And so it protects our GeForce supply for the gamers.
And the question that you have is, what happens when on the tail end of this? There's several things that we hope and we learned a lot from the last time that when you never learn enough about this dynamic. What we hope is that, that the CMPs will satisfy the miners and will stay in mines, in the professional mines. And we're trying to produce a fair amount of them and we have -- we secured a lot of demand for the CMPs and we will fulfill it.
And what makes it different this time is several things. One, we're in the beginning of our RTX cycle, whereas Pascal was the last GTX. And now exactly was at the tail end of the GTX cycle. It was the last GTX and it was the tail-end of GTX cycle. We're at the very beginning of the RTX 30 cycle. And because we reinvented computer graphics, we reset the computer industry. And after three years, the entire graphics industry has followed. Every game developers need to do ray tracing, every content developer and every content tool has moved to ray tracing. And so if you move to ray tracing, these applications are so much better, and they simply run too slow on GTXs. And so we're seeing a reset of the install base, if you will.
And at a time, when the gaming market is the largest ever, we've got this incredible installed base of GeForce users. We've reinvented computer graphics and we've reset the install base, and created an opportunity that's really exciting. At a time when the market is -- the gaming market, the gaming industry is really large, and what's really -- sports -- eSports, it's infused into art. It's infused into social. And so, gaming has such a large cultural impact now, it's the largest form of entertainment. And I think that the experience we're going through is going to last a while. And so, one, I hope that crypto will -- the CMP will steer our GeForce supply to gamers. We see strong demand and I expect to see strong demand for quite some time because of the dynamics that I described. And hopefully, in the combination of those two, we'll see strong growth and through strong growth in our core gaming business through the year.
Operator
And your next question comes from John Pitzer with Credit Suisse.
John Pitzer -- Credit Suisse -- Analyst
Yeah, good afternoon, guys. Thanks for letting me ask a question. Jensen, I had two hopefully quick questions. First, I harken back to the mantra you guys put out a couple of analysts days ago, the more you spend, the more you save. And you've always been very successful as you brought down the cost of doing something to really drive penetration growth. And so I'm curious with the NVIDIA enterprise AI software stack. Is there a sense that you can give us as how much that brings down the cost of deployment in AI inside the enterprise? And do you think whether COVID lockdown related or cost related, there's pent-up demand that this unlocks?
And then my second question is just around government subsidies. A lot of talks out of Washington about subsidizing the chip industry, a lot of that goes toward building fabs domestically. But when I look at AI, I can't think of anything more important to maintain sort of leadership in -- relative to national security. How do we think about NVIDIA and kind of the impact that these government subsidies might have on either you or your customers or your business trends?
Jensen Huang -- Founder, President and Chief Executive Officer
The more you buy, the more you shall save, there's no question about that. And the reason for that is because we're in the business of accelerated computing. We don't accelerate every application. However, for the applications we do accelerate, the acceleration is so dramatic and because we sell a component, the entire system, the TCO, the TCO of the entire system, and all the service and all the people and the infrastructure and the energy cost, has been reduced by X factors, sometimes 10 times, sometimes 15 times, sometimes 5 times.
And so when we set our mind on accelerating a certain class of applications and recently we worked on cuQuantum, so that we could help the quantum industry, quantum computing industry accelerate their simulators so that they could discover new algorithms and invent future computers. Even though it won't happen until 2030, for the next 20 years, we're going to -- 15 years, we're going to have some really, really great work that we can do using NVIDIA GPUs to do quantum simulations.
We recently did a lot of work in natural language understanding and computational biology so that we could decode biology and understand how biology is -- to infer to understand it and to predictively improve upon it and design new proteins. Those words are so vital. And that's what accelerated computing is all about.
Our enterprise software, and I really appreciate the question. Our Enterprise software used to be just about the vGPU, which is virtualizing GPU inside the VMware environment, or inside the Red Hat environment and makes it possible for multiple users to use one GPU, which is the nature of enterprise virtualization, but now with NVIDIA AI, NVIDIA Omniverse, NVIDIA Fleet Command, whether you're doing collaboration or virtual simulations for robotics and digital twins, designing your factory or you're doing data analytics, learning what the predictive features are that could create an AI model, predictive model that you can deploy out at the edge using Fleet Command. We now have an intense suite of software that is consistent with today's enterprise service agreements. It's consistent with today's enterprise business models, and allows us to support customers directly, and provide them with the necessary service promises that they expect, because they're delivering -- they're trying to build a mission-critical application on top.
And more importantly, by creating this -- prioritizing our software, we provide the ability for our large network of partners, OEM partners, value-added resellers, system integrators, solution providers. For this large network of hundreds of thousands of IT sales professionals that we are connected to through our network, we give them a product that they can take to market. And so the distribution channel, the sales channel, VMware, the sales channel of Cloudera, the sales channel of all of our partners in EDA and design, Autodesk, Dassault, so on, so forth, all of these sales channels, and all of these partners are now partners and taking our stacks to market. And we have a fully integrated system that are open to the OEM, so that they could create systems that run the stack, and it's all certified, all tested, all benchmarked. And, of course, very importantly, all supported.
And so this new way of taking our products to market, whereas our cloud business is going to continue to grow, and that's that part of AI is going to continue to grow, that business is direct, we sell components directly to them, we support them directly. But there are 10 of those customers in the world. For enterprises, there are thousands; industries, far and wide. And so we now have a great stack and a great software stack that allows us to take it to the world's market so that everybody could buy more and save more.
Operator
And your final question comes from Stacy Rasgon with Bernstein.
Stacy Rasgon -- Bernstein -- Analyst
Hi, guys, thanks for taking my questions. This one's for Colette. So, Colette, last quarter, you had kind of suggested that Q1 would be the trough for, I guess, for gaming, as well as the rest of the Company, but gaming in particular, and it would grow sequentially through the year. I guess given the strength we're seeing in the first half, you still believe that that is the case? And I kind of heard you guys, I think kind of dance around that point a little bit in response to one of the other questions, but could you clarify that? Is that still your belief that that core gaming business can grow sequentially through the rest of the year? And I guess same core, same question as well for data center, especially since sounds like hyperscale is now coming back, like after a few quarters of digestion and then all of the other tailwinds you talked about. I mean, is there any reason to think that data center itself shouldn't also grow sequentially, like through the rest of the year?
Colette Kress -- Executive Vice President and Chief Financial Officer
Yeah, Stacy, thanks for the question. So I first want to start with, when we talked about our Q1 results and when we're looking at Q1, we were really discussing a lot about what we expected between Q4 and Q1. Given what we knew was still high demand for gaming, we believed we will continue to grow between Q4 and Q1, which often we don't, and we absolutely have the strength and overall demand to grow. What that then led was, again, continued growth from Q1 to Q2, as we are working hard to provide more supply for the strong demand that we see.
We have talked about that we have additional supply coming. We expect to continue to grow as we move into the second half of the year as well for gaming. Now, we only guide one quarter at a time. But our plan is to take the supply, serve the overall gamers, work on building up the channel as we know the channel is quite lean. And so, yes, we do and still expect growth in the second half of the year particularly when we see the lineup of games on the holiday overall coming, the back to school, all very important cycles for us. And there's a great opportunity to upgrade this RTX installed base.
Now, in terms of data center, we'll work in terms of our guidance here. We have growth from Q1 to Q2 planned in our overall guidance. And we do see as things continue to open up, a time to accelerate in the second half of the year for data center. We have, again, a great lineup of products here. Couldn't be a better lineup, now that we've also added the Infineon products, and the host of overall applications that are using our software that we have. So this could be an opportunity as well to see that continued growth. We'll work in terms of serving the supply that we need for both of these markets. But yes, we can see definitely growth in the second half of the year.
Operator
There are no further questions at this time. CEO, Jensen Huang, I'll turn the call back over to you.
Jensen Huang -- Founder, President and Chief Executive Officer
Well, thank you. Thank you for joining us today. NVIDIA computing platform is accelerating. Launched at GTC, we are now ramping new platforms and initiatives. There are several that I mentioned. First, enabled by this fusion of NVIDIA RTX, NVIDIA AI, NVIDIA [Indecipherable], we built Omniverse, a platform for virtual worlds to enable tens of millions of artists and designers to create together in their own metaverses.
It's Second, we laid the foundation to be a three-chip data center scale computing company with GPUs, DPUs and CPUs. Third, AI is the most powerful technology force of our time. We partner with cloud and consumer Internet companies to scale out and commercialize AI-powered services. And we're democratizing AI for every enterprise and every industry. With NVIDIA EGX certified systems, the NVIDIA Enterprise AI suite, pre-trained models for conversational AI, language understanding, recommender systems and our broad partnerships across the IT industry, we are removing the barriers for every enterprise to access state-of-the-art AI.
Fourth, the work of NVIDIA Clara in using AI to revolutionize genomics and biology is deeply impactful for the healthcare industry, and I look forward to telling you a lot more about this in the future. And fifth, the electric, self-driving and software-defined car is coming. With NVIDIA DRIVE, we are partnering with the global transportation industry to reinvent the car architecture, reinvent mobility, reinvent driving and reinvent the business model of the industry. Transportation is going to be one of the world's largest technology industries.
From gaming, metaverses, cloud computing, AI, robotics, self-driving cars, genomics, computational biology, NVIDIA is doing important work and innovating in the fastest-growing markets today. As you can see, on top of our computing platforms that span PC, HPC, cloud, enterprise to autonomous edge, we've also transformed our business model beyond chips. NVIDIA vGPU, NVIDIA AI Enterprise, NVIDIA Free Command and NVIDIA Omniverse adds enterprise software license and subscription to our business model, and NVIDIA GeForce Now and NVIDIA DRIVE with Mercedes-Benz as the lead partner, our end-to-end services on top of that.

--- Q2 2022 ---
Simona Jankowski, you may begin your conference.
Simona Jankowski -- Investor Relations
Thank you. Good afternoon, everyone. And welcome to NVIDIA's conference call for the second quarter of fiscal 2022. With me today from NVIDIA are Jensen Huang, President and Chief Executive Officer; and Colette Kress, Executive Vice President and Chief Financial Officer.
I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the third quarter of fiscal 2022. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent.
During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10-K and 10-Q and the reports that we may file on Form 8-K with the Securities and Exchange Commission.
All our statements are made as of today, August 18, 2021 based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website.
With that, let me turn the call over to Colette.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, Simona. Q2 was another strong quarter with revenue of $6.5 billion and year-on-year growth of 68%. We set records for total revenue as well as for Gaming, Data Center and Professional Visualization.
Starting with Gaming, revenue was $3.1 billion, was up 11% sequentially and up 85% from a year earlier. Demand remained exceptionally strong, outpacing supply. We are now four quarters into Ampere architecture product cycle for gaming and it continues to be our best ever.
At COMPUTEX in June, we announced two powerful new GPUs for gamers and creators, the GeForce RTX 3080 Ti and RTX 3070 Ti, delivering 50% faster performance than their prior generation with acclaimed features such as real-time ray tracing, NVIDIA DLSS, AI Rendering, Reflex and Broadcast. Laptop demand was also very strong. OEMs adopted Ampere architecture GPUs in a record number of designs. From the top of the line gaming laptops to those through mainstream price points as low as $799, that bring the power of GeForce CPUs to gamers, students and creators on the go.
Ampere architecture-powered laptops feature our third-generation Max-Q power optimization technology that enables ultra-thin designs such as the new Alienware x15, the world's most powerful sub-16 millimeter gaming laptop. NVIDIA RTX technology has reset computer graphics and spurred our biggest ever refresh cycle. Ampere has been our fastest ramping gaming GPU architecture on Steam and the combination of Turing and Ampere RTX GPUs have only upgraded about 20% of our installed base. 80% have yet to upgrade to RTX.
And the audience for global esports will soon approach 0.5 billion people, while the number of those who live stream games is expected to reach over 700 million. The number of PC gamers on Steam is up almost 20% over the past year. More than 60 RTX games now support NVIDIA's RTX ray tracing or DLSS, including today's biggest game franchises such as Minecraft, Fortnite and Cyberpunk. New RTX games this quarter include Red Dead Redemption 2, one of the top-rated games of all-time, popular titles like Rainbow Six Siege and Rushed [Phonetic] and Minecraft RTX in China with over 400 million players.
The competitive gamers, NVIDIA Reflex, which include latency is now supported by 20 games. Let me say a few words on cryptocurrency mining. In an effort to address the needs of miners and direct GeForce to gamers, we increased the supply of cryptocurrency mining processors, or CMP, and introduced low hash rate GeForce GPUs with limited Ethereum mining capability. Over 80% of our Ampere architecture-based GeForce shipments in the quarter were both hash rate GPUs. The combination of crypto to gaming revenue is difficult to quantify.
CMP revenue, which is recognized in OEM, was $266 million, lower than our original $400 million estimate on reduced mining profitability and we expect a minimal contribution from CMP going forward. GeForce NOW reached a new milestone this quarter surpassing 1,000 PC games, more than any other cloud gaming service. The premium tier is available for a subscription of $10 per month, giving gamers access to RTX class performance even on an underpowered PC, Mac, Chromebook, iOS or Android device.
Moving to Pro Visualization. Q2 revenue was a record $519 million, up 40% sequentially and up 156% year-on-year. Strong sequential revenue growth was led by desktop workstations, driven by demand to outfit design offices at home as remote work becomes the norm across industries. This is also the first big quarter of the Ampere architecture ramp for pro visualization. Key verticals driving Q2 demand include automotive, public sector and healthcare.
At SIGGRAPH, last week we announced an expansion of NVIDIA Omniverse, our simulation and collaboration platform that provides the foundation of the metaverse. Through our new integrations with Blender, the world's leading open source 3D animation tool; and Adobe, we're opening the Omniverse platform to millions of additional users.
We are also collaborating with Apple and Pixar to bring advanced physics capabilities to Pixar's Universal Scene Description framework, embracing open standards to provide 3D workflows to billions of devices. Omniverse Enterprise software is in the early access stage and will be generally available later this year on a subscription basis from NVIDIA's partners, including Dell, HP, Lenovo and many others. Over 500 companies are evaluating Omniverse Enterprise, including BMW, Volvo and Lockheed Martin. And more than 50,000 individual creators have downloaded Omniverse since it entered open beta in December.
Moving to automotive. Our Q2 revenue was $152 million, down 1% sequentially and up 3% year-on-year. Sequential revenue declines in infotainment were largely offset by growth in self-driving. Looking further out, we have substantial design wins set to ramp that we expect will drive a major inflection in revenue in the coming years. This quarter, we announced several additional wins. Self-driving start-up AutoX unveiled its latest autonomous driving platform for robotaxis powered by NVIDIA DRIVE. The performance and safe capabilities of the software-defined NVIDIA DRIVE platform has enabled AutoX to become one of the first companies in the world to provide full self-driving mobility services without the need for a safety driver.
In autonomous trucking, DRIVE ecosystem partner, Plus, signed a deal with Amazon to provide at least 1,000 self-driving systems to Amazon's fleet of delivery vehicles. The systems are powered by NVIDIA DRIVE for high performance, energy efficient and centralized AI compute. An autonomous trucking start-up, Embark, is building on NVIDIA DRIVE. The system is being developed for trucks for four major OEMs; Freightliner, Navistar International, PACCAR and Volvo, representing the vast majority of the Class 8 or largest size trucks in the US.
The NVIDIA DRIVE platform is being rapidly adopted across the transportation industry from passenger-owned vehicles to robotaxi, to trucking and delivery vehicles. We believe everything that moves will be autonomous some day.
Moving to Data Center. Revenue of $2.4 billion, grew 16% sequentially and 35% from the year ago quarter -- the year ago quarter, which was our first quarter to include Mellanox. Growth was driven by both hyperscale customers and vertical industries, each of which had record revenues. Our flagship A100 continue to ramp across hyperscale and cloud computing customers with Microsoft Azure announcing general availability in June, following AWS and Google Cloud Platforms general availability in prior quarters.
Vertical industry demand was strong with sequential growth led by financial services, supercomputing and telecom customers. We also had exceptional growth in inference, which reached a record more than doubling year-on-year. Revenue from inference focused processors includes the new A30 GPU, which provides 4 times the inference performance of the T4. Customers are also turning to NVIDIA GPUs to take AI to production and shifting from CPUs to GPUs, driven by the stringent performance latency and cost requirements of deploying and scaling deep learning AI workloads.
NVIDIA's networking products posted solid results. We see momentum across regions driven by our technology leadership with upgrades to high speed products such as ConnectX-6 as well as new customer wins across cloud, service providers, enterprise and high performance computing. We extended our leadership in supercomputing, the latest TOP500 list shows that NVIDIA technologies power 342 of the world's Top 500 supercomputers, including 70% of all new systems and eight of the Top 10 to help companies harness the new industrial high performance computing navigation. We delivered a turnkey AI data center solution with the NVIDIA DGX SuperPOD, the same technology that powers our new Cambridge-1 supercomputer in the UK and a number of others in the top 500.
We expanded our AI software and subscription offerings, making it easier for enterprises to adopt AI from the initial development stage through to deployment and operations. We announced NVIDIA Base Command, our Software-as-a-Service offering for operating and managing large scale multi-user and multi-team AI development workloads on DGX SuperPOD. Base Command is the operating and management system software for distributed training customers.
We also announced general availability of NVIDIA Fleet Command, our managed edge AI Software-as-a-Service offering. Fleet Command helps companies solve the problem of securely deploying and managing AI applications across thousands of remote locations, combining the efficiency and simplicity of central management with the cost performance and data sovereignty benefits of real-time processing at the edge.
Early adopters of Fleet Command include some of the world's leading retail, manufacturing and logistics companies and the specialty software companies that work with them. The new NVIDIA Base Command and Fleet Command software and subscription offerings followed last quarter's announcements of the NVIDIA AI Enterprise software suite, which is in early access with general availability expected soon.
Our enterprise software strategy is supported by the NVIDIA-Certified Systems program with server OEMs, which are bringing to market over 55 systems ready to run on NVIDIA's AI software out of the box to help enterprise simplify and accelerate their AI deployment.
The NVIDIA ecosystem keeps getting stronger. NVIDIA Inception, our acceleration platform for AI start-ups just surpassed 8,500 members. With cumulative funding of over $60 billion and numbers in 90 countries, Inception is one of the largest AI start-up ecosystems in the world. CUDA now has been downloaded 27 million times since it launched 15 years ago, with 7 million in the last year alone. TensorRT for Inference has been downloaded nearly 2.5 million times across more than 27,000 companies. And the total number of developers in the NVIDIA ecosystem now exceeds 2.6 million, up 4 times in the past four years.
Let me give you a quick update on Arm. In nearly one year since we initially agreed to combine with Arm, we have gotten to know the company, its business and its people much better. We believe more than ever in the power of our combination and the benefits it will deliver for Arm for the UK and for its customers across the world in the era of AI. Arm has great potential. We love their business model and committed to keep its open licensing approach. And with NVIDIA's scale and capabilities, Arm will make more embedded customers, while expanding into data center, IoT and other new markets.
NVIDIA accelerates computing, which starts with the CPU. Whatever new markets are open with the CPU and our accelerated computing opportunities, we've announced accelerated platforms for Amazon Graviton, Ampere Computing, MediaTek and Marvell, spanning cloud computing, AI, cloud gaming, supercomputing, edge AI to Chrome PCs. We plan to invest in the UK and we have with the Cambridge-1 supercomputer, and through Arm making UK a global center in science, technology and AI.
We are working through the regulatory process, although some Arm licensees have expressed concerns and objected to the transaction. And discussions with regulators are taking longer than initially thought. We are confident in the deal and that regulators should recognize the benefits of the acquisition to Arm, its licensees and the industry.
Moving to the rest of the P&L. GAAP gross margin of 64.8% for the second quarter was up 600 basis points from a year earlier, reflecting the absence of certain Mellanox acquisition-related costs. GAAP gross margins was up 70 basis points sequentially. Non-GAAP gross margins was 66.7%, up 70 basis points from a year earlier and up 50 basis points sequentially, reflecting higher ASPs within desktop, GeForce, GPUs and continued growth in high end Ampere architectured products, partially offset by a mix shift within data center. Q2 GAAP EPS was $0.94, up 276% from a year earlier. Non-GAAP EPS was $1.04, up 89% from a year earlier, adjusting for the 4-to-1 stock split effective this quarter, Q2 cash flow from operations was a record $2.7 billion.
Let me turn to the outlook for the third quarter of fiscal 2022. We expect another strong quarter with sequential growth driven largely by accelerating demand in data center. In addition, we expect sequential growth in each of our three other market platforms. Gaming demand is continuing to exceed supply as we expect channel inventories to remain below target levels as we exit Q3. The contribution of CMP to our revenue outlook is minimal. Revenue is expected to be $6.8 billion, plus or minus 2%.
GAAP and non-GAAP gross margins are expected to be 65.2% and 67% respectively, plus or minus 30 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $1.96 billion and $1.37 billion respectively. GAAP and non-GAAP other income and expenses are both expected to be an expense of approximately $60 million, excluding gains and losses on equity securities. GAAP and non-GAAP taxes are supposed to be expected 11%, plus or minus 1%, excluding discrete items. Capital expenditures are expected to be approximately $200 million to $225 million.
Further financial details are included in the CFO commentary and other information available on our IR website.
In closing, let me highlight upcoming events for the financial community. We will be attending the following virtual events: the BMO Technology Summit on August 24; the New Street Big Ideas in Semiconductors Conference on September 9th; the Citi Global Tech Conference on September 13th; the Piper Sandler Global Technology Conference on September 14th; and the Evercore ISI Autotech & AI Forum on September 21st. Our earnings call to discuss the third quarter results is scheduled for Wednesday, November 17.
We will now open the call for questions. Operator, would you please poll for questions.
Questions and Answers:
Operator
Thank you. [Operator Instructions] Your first question comes from the line of Vivek Arya of Bank of America. Your line is now open. You may ask your question.
Vivek Arya -- Bank of America -- Analyst
Thanks for taking my question. I actually had a near and longer-term question on the data center. I think near-term, you mentioned the possibility of accelerating data center growth from the 35% rate. I was hoping if you could give us some more color around that confidence and visibility? And then, longer term, Jensen, we have seen a lot of announcements from NVIDIA about your enterprise software opportunity. I honestly don't know how to model that. It sounds very promising, but how should be model it? What problem are you trying to solve? Is it cannibalizing demand you might have otherwise seen from your public cloud customers or is this incremental to grow? So just any guidance or any just insights into how to think about NVIDIA's enterprise software opportunity longer-term? Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah, Vivek, thanks for the question. We are seeing accelerated -- or as we've already reported that we have record revenues in both hyperscale cloud and industrial enterprise this last quarter. And we're seeing accelerated growth. The acceleration in hyperscale and cloud comes from the transition of the catalyst providers in taking their AI applications, which are now heavily deep learning driven into production. There were some of the things that we've spoken about in the past that really makes NVIDIA the ideal platform to scale out with.
And if my [Indecipherable] the several platforms -- the several elements of our platform, number one, Ampere GPU, which is known Universal GPU for AI, for training, but incredibly good for Inference. It's terrific in its throughput, it's terrific in its fast response time as well. And therefore, the cost of deployment, the cost of operating in AI applications is the lowest.
The second is the introduction of Tensor RT, which is our optimizing compiler that makes it possible for us to compile and optimize any AI application to our GPUs. And whether its Computer Vision or Natural Language Understanding or Conversational AI, recommender systems, the type of applications that are deploying AI is really quite vast.
And then lastly, software inference server that we also call Triton, which supports every one of our GPUs, it supports GPUs as well as GPUs. So, every Internet Service Provider could operate their entire data center using Triton. These several things are really accelerating our growth, which is for the first element is the deployment of transition of deep learning AI applications into large-scale deployment.
In the Enterprise, the application that is driving AI, as you know, every enterprise must be wants to move and raise toward being a tech company and take advantage of connected clouds and connected devices and artificial intelligence to achieve it. And we have an opportunity to deploy AI services out of the edge. And in order to do so, there are several things that has to happen; first, we have to create a computing platform that allows them to do training in the IT environment that they understand, which is a virtualized, which is largely managed by VMware. And our collaboration with VMware are creating a new type of systems that could be integrated in the enterprise has been quite a significant effort and it's in volume production today.
The second is a server that allows the enterprise customers to deploy their AI models out to the edge. And the AI engine, the software suite that we've been developing over the last 10 years now have been integrated into this environment and allows the enterprises to basically run AI out of the box. There are three elements of our software products there. First is NVIDIA AI Enterprise, and that puts -- that basically puts all of the state-of-the-art AI solvers and engines and libraries that we've industrialized and perfected over the years, made it available to Enterprise license.
Second is a operating system platform called Base Command that allows for distributed scale up software development in the -- for our training and development models. And then, the third is Fleet Command, which is a operating system software product that lets you operate and deploy and manage the AI models out to the edge. These three software products, in combination with the server called NVIDIA-Certified, taken out through our network of partners is our strategy to accelerate the adoption of AI by the enterprise customers. And so, we are really enthusiastic about entering into the software business model. This is an opportunity that could represent, of course, tens of millions of servers. We believe all of them will be GPU accelerated. We believe that enterprises will be deploying and taking advantage of AI to revolutionize the industry and using quite a traditional enterprise software licensing business model. This could represent billions of dollars of business opportunity for us.
Operator
Thank you. Next question comes from the line of Stacy Rasgon of Bernstein. Your line is now open. You may ask your questions.
Stacy Rasgon -- Bernstein -- Analyst
Hi, guys. Thanks for taking my questions. I wanted to go back, collect the sequential guidance, you gave a little bit of color by segments. If I look at your gaming revenues, it's currently three quarters in a row you've been up, call it, ballpark 10% or 11%. And my understanding is that was sort of a function of your ability to bring on supply. So, I guess, what is the supply issue look like as you're going from Q2 into Q3? And do you think you can still maintain that kind of sequential growth or does it dial down, because I also need to -- I also would play that against your other commentary suggesting that the sequential growth and I assume on the dollar basis was driven primarily by data centers. So, how do we think about the interplay within those comments of sequential growth of gaming, especially given the trajectory we’ve had over the last several quarters?
Colette Kress -- Executive Vice President and Chief Financial Officer
Yeah. So let me start and I'll let Jensen add a bit, Stacy, to your question. Just for providing the guidance for Q3 of $6.8 billion in revenue. Now, excluding CMP, we expect our revenue to grow over $500 million sequentially. Our lion's share about sequential revenue increase will be coming from data center. We do expect Gaming to be up slightly on a sequential basis, but remember, we are still supply constrained. Automotive and Pro Vis are also expected to be up slightly quarter-over-quarter. And from a CMP perspective, we'll probably just have minimal amounts in Q3. So, our Q3 results don't have seasonality with some for gaming and are really about the supply that we believe we can have for Q3.
We'll see if Jensen wants to add any more color.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. Thank you. Thanks for the question, Stacy. As you know, RTX is a fundamental reset of computer graphics. This is a technology coverage basically that has been the holy grail of computer graphics for quite a long time from 35 years and research -- in our NVIDIA research for 10 years, we finally made it possible to do real-time ray tracing with RTX. RTX demand is quite incredible. And as you know, we have a large installed base of PC gamers, the new end architecture called GTX based on programmable shatters that we invented some 20 years ago. And now, we reset the entire installed base and Ampere is of to just an incredible starting the best selling GPU architecture in the history of our company. And yet, we've only upgraded some 20% -- less than 20% of our total installed base. So there's another 80% of the world PC gaming market that we have yet to upgrade to RTX.
Meanwhile, the number of PC gamers in the world grew substantially, still grew 20% this last year. And so I think the -- a world wide beginning of our RTX transition. Meanwhile, computing graphics is expanded into so many different new markets. RTX we've known, we've always believed we’ll reinvent the way that people do design. And we're seeing that happening right now as we speak as workstations is growing faster than ever and has achieved record revenues. And at the same time because of all of our work with cloud gaming, we announced the public clouds, cloud graphics, whether it's workstations or PC or private gaming consoles up in the cloud. So we're seeing strong demand in PCs, in laptops, in workstations, in mobile workstations and cloud. And so, RTX is really doing great work. Our challenge there is that demand is just so much greater than supply and then as closely we'll do supply constraints.
Operator
Thank you. Next question comes from the line of Matt Ramsay of Cowen. Your line is now open.
Matt Ramsay -- Cowen -- Analyst
Yeah, thank you very much. Good afternoon, everybody. Before my question, Jensen, I just wanted to say congrats on the award, that's a big honor. For my question, I wanted to follow-on, on Stacy's question about supply. And Colette maybe you could give us a little bit of commentary around supply constraints in gaming in the different tiers or price tiers of your gaming cards. I'm just trying to get a better understanding as to how you guys are managing supply across the different price tiers? And I guess it translates into a question of, are the gaming ASPs that we're seeing in the October quarter guidance, are those what you would call sustainable going forward or do you feel like that mix may change as supply comes online? Thank you.
Colette Kress -- Executive Vice President and Chief Financial Officer
So, I'll start here. Thanks for the question on our overall mix as we go forward. First, our supply constraint in our gaming business is largely attributed to our desktop and notebook. That can mean a lot of different things from our components that are necessary to build so many of our products. But our mix is really important. Our mix, as we have also seen, many of our gamers very interested in our higher-end higher performance products. We will continue to see that as a driver of that overall lifts both our revenue and can lift our overall gross margins. So, there's quite a few different pieces into our supply that we have to think about, but we are going to try and make the best solutions for gamers at this time.
Operator
Thank you. Next question we have the line from C.J. Muse -- your line is -- from Evercore. Your line is now open.
C.J. Muse -- Evercore -- Analyst
Yeah. Thank you. Good afternoon. I guess, a follow-up question on the supply constraints. When do you think that they'll ease and how should we think about gaming into the January quarter B2B typical seasonality, given I would assume you would continue to be supply constraint? Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Colette, if I can take it or you can, either one of them.
Colette Kress -- Executive Vice President and Chief Financial Officer
Well, go ahead, Jensen. And I'll follow up if there are some other things.
Jensen Huang -- Founder, President and Chief Executive Officer
Okay. We're supply constrained in graphics, and we're supply constrained in graphics while we're delivering record revenues in graphics. Cloud gaming is growing. Cloud graphics is growing. RTX made it possible for us to address the design in accretive workstations. Historically, the rendering of ray tracing and photo realistic images has largely been done on CPUs and for the very first time, you could actually accelerate it with NVIDIA GPUs and RTX GPUs. And so the workstation market is really doing well. The backdrop of that of course is that people are building offices in their homes. And for many of the designers and creators around the world, some 20 million of them, they have to create, they have to build a workstation or an office at home, as well as the one that work, because we're now working with the new one.
And meanwhile, of course RTX, has reached all of our consumer graphics, the few hundred million installed base, PC gamers and it’s time to upgrade. And so there's a whole bunch of reasons. We're achieving record revenues what was supply constraints. We have enough supply to meet our second half company growth points. We want -- the next year we expect to be able to achieve our company's growth plans for next year. Meanwhile, we have and are securing pretty significant long-term supply commitments as we expand into all these different market initiatives that we've sort set ourselves up for. And so, I think – I would expect it enables to a supply constrained environment for the vast majority of next year is my guess at the moment. But a lot of that has to deal with [Indecipherable] demand, it's just so great. RTX is really a once in a generation reset of computer -- modern computer graphics, nothing like this has happened. It’s so convenient computer graphics. And so, the invention is new pipeline working [Technical Issues].
Operator
Thank you. Next question comes from the line of Harlan Sur of JPMorgan. Your line is now open.
Harlan Sur -- JPMorgan -- Analyst
Good afternoon. And congratulations on the strong results outlook and execution. The Mellanox networking franchise, this has been a really strong and synergistic addition to the NVIDIA Compute portfolio. I think, kind of near-to mid-term, the team is benefiting from the transition to 200 and 400 gig networking connectivity in cloud and hyperscale. And then, I think, in addition to that, you guys are getting some good traction with the BlueField SmartNIC products. Can you just give us a sense on how the business is trending year-over-year? And do you expect continued quarter-over-quarter networking momentum into the second half of this year, especially as the cloud and hyperscalers are going to a server and capex spending cycle?
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. I really appreciate that question. Mellanox had a solid growth quarter. And the Mellanox networking business is really growing incredibly . There are three dynamics happening all at the same time. The first is the transition that we're talking about. You know that the world's data centers -- hyperscale data centers are using this form of computing called disaggregated, which basically means that a single application is running on multiple servers at the same time. This is what makes it possible for them to scale up, the more users for AI application or a service, you just have to add more service.
And so, the ease of scale out that this aggregated computing provides also puts enormous pressure on the networking. And at the Mellanox, the world's lowest latency and a high bandwidth and performance networking on the planet. And so, the ability to scale out and the ability to provisioning disaggregated applications, it was really much, much better work on Mellanox networking. So that's number one.
Number two, almost every company in the world has to be a high-performance computing company. You see that the cloud service providers one after another are building effectively supercomputers. What historically was InfiniBand and Supercomputing centers, the cloud service providers have to build supercomputers themselves. And the reason for that is because of artificial intelligence in terms of these gigantic models. But the rate of growth of network sizes --AI model sizes is doubling every two months. It's doubling now every year or two years, it's doubling every two months. And so, you can imagine the size. We're now talking about training AI models that are 100 trillion parameters large. The human brain has 150-plus trillion synapses, and so -- or neurons. And so that gives you a sense of the scale of AI models that people are developing.
And so, you will see supercomputers that are built out of Mellanox, InfiniBand and the high-speed networking, along with NVIDIA GPU computing in more and more cloud service providers. You're also seeing it in enterprises, for used in the discovery of DRIVE. There's a digital biology revolution going on as the competition is stable. The large scale computing that we're able to do now in AI, better understand biology and better understand chemistry and bringing both of those deals into the field of information sciences. And so, you're seeing in March, [Technical Issues] in enterprises around the world as well. And so, the second dynamic has to do with our incredibly great networking, InfiniBand networking side as well, de facto standard in high performance computing.
And the third dynamic is around data center storing software. In order to orchestrate and run a data center with just a few people, essentially when the entire data centers, hundreds of thousands of servers as it is just one computer in front of you, that entire data center is software defined. And there's not a software that goes into that software-defined data center run on today's GPUs. It's the networking stack, the storage stack and now which has zero trust, the securities stack. All of that is putting enormous pressure on the available computing capacity for applications, which is ultimately what data centers are designed to do.
And so, the software defined data center needs to have a place to Triton infrastructure software and it's downloaded, offloaded, accelerated and very importantly to isolate it from the application plan, so that intruders cannot jump into the operating system, if you will, of your data center, the fabric of your data center. And so, the answer to that is BlueField. The ability to offload, accelerate and isolate the data center software infrastructure and to hurry up all of the CTOs to run what they're supposed to run, which is the application. Just about every data center in the world is moving towards a zero trust model and BlueField is just incredibly well positioned. So these three dynamics, disaggregated computing is really strong with fast networking, every company needing high performance computing, and lastly, software defined data centers following zero trust. And so, these are really important dynamics. And I appreciate the opportunity to tell you all that. And this is to tell how super exciting about the prospects of NVIDIA's networking business and the importance that they have in building modern data centers.
Operator
Thank you. Next question comes from the line of Aaron Rakers of Wells Fargo. Your line is open.
Aaron Rakers -- Wells Fargo Securities -- Analyst
Yeah. Thanks for taking the question. I think you hit a lot of my questions around the data center in that last one. So maybe I'll just ask kind of on a P&L basis. One of the things that I see in the results and more importantly the guidance, you're now, Colette, guiding over 67% gross margin potentially. I'm curious as we move forward, how do you think about the incremental operating gross margin upside still from here and how you're thinking about the operating margin leverage for the company from here through the P&L. Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. Colette, let me take that and if you could just follow-up with the details, that would be great. I think, at the highest level, I really appreciate the question. At the highest level, the important thing to realize is that artificial intelligence is the single greatest technology force that the computer industry has ever seen and potentially the world has ever seen. The automation opportunities which drives productivity, which translates directly to the cost savings of the companies is enormous. And it opens up opportunities for technology and computing companies like it's never happened before.
Let me just give you some examples. The fact that we can apply so much technology to warehouse logistics, retail automation, customer call center automation is really quite unprecedented. The fact that we could automate truck driving and last-mile delivery providing an automated chauffeur, those kind of services and benefits and products are never imaginable before. So the size of the IT industry, if you will, the industry that computer companies like ourselves are part of has expanded tremendously. And so, the thing that we want to do is to invest as smartly but as quickly as we can to go after the large operating -- large business opportunities, where we can make a real impact. And in doing so -- while doing so, to do so in a way that is architecturally sensible.
One of the things that is really an advantage of our company is the nature of the way that we build products, the nature of the way that we build software, our discipline around the architecture, which allows us to be so efficient while doing -- while addressing climate science on the one hand, digital biology on the other, artificial intelligence and robotics and self-driving cars. And of course, we always talked about computer graphics and video games. Using one architecture and having the ability to -- and having the discipline now for almost 30 years has given us incredible operating leverage. That's where the vast majority of our operating leverage comes from, which is architectural. The technology is architectural, our products are architectural in that way and the company has been built architecturally in that way. So hopefully as we go after these large, large market opportunities that AI has provided us, and we do so in a smart and disciplined way with great leverage through our architecture, we can continue to drive really great operating leverage for the company and our shareholders.
Operator
Thank you. The next question comes from the line of John Pitzer of Credit Suisse. Your line is open.
John Pitzer -- Credit Suisse -- Analyst
Yeah. Good afternoon, guys. Thanks for letting me ask a question. Apologize for the short-term nature of the question, but it's what I get asked most frequently. I kind of want to return to the impact of crypto with the potential impact of crypto. Colette, is there any way to kind of gauge the effectiveness of the low hash rate GeForce? Why only 80% and not 100%? And how confident are you that the CMP business being down is a reflection of crypto going off versus perhaps LHR being not that effective? And I bring it up because there's a lot of blogs out there that would suggest that as much as you guys are trying to limit the ability of miners to use GeForce, there are some work-arounds.
Jensen Huang -- Founder, President and Chief Executive Officer
Yeah. Go ahead.
Colette Kress -- Executive Vice President and Chief Financial Officer
Yeah. Let me start there and answer a couple of the questions about our strategy that we've put in place in this last couple of quarters. As you recall, what we put in place was the low hash rate cards as well as putting in the CMP cards. The low hash rate cards were to provide for more supply for our GeForce gamers that are out there. We articulated one of the metrics that we were looking is what percentage of those cards in Ampere we were able to sell with low hash cards. Almost all of our cards in Ampere are low hash rates, but also we are selling other types of cards as well. But at this time as we move forward, we're much higher than 80% but just at the end of this last quarter, we were approximately 80%. So, yes, that is moving up. So, the strategy is in place and will continue as we move into Q3.
I'll move it to Jensen here to see if he can discuss further.
Jensen Huang -- Founder, President and Chief Executive Officer
There's the question about the strategy of how we're steering GeForce supply to gamers. We moved incredibly fast with CMP and our LHR settings for GeForce. And our entire strategy is about steering GeForce supplies to gamers. And we have every reason to believe that because of the DRIVE team, which is really a measure of gamers, the rate of growth of our team adoption of Ampere GPUs, there's some evidence that we are successful. But there are several reasons why it's different this time. The first reason of course is the LHR which is new and the speed at which we responded with CMP GeForce applied to gamers.
The second is, at the very beginning of the Ampere and RTX cycles. As I mentioned earlier, RTX is a completely new venture in computer graphics. Every evidence is that gamers are incredibly -- and game developers are incredibly excited about ray tracing. The form of computer renderings, graphics rendering is just dramatically more beautiful. And we're at the beginning of that cycle and only 20% have been upgraded so far. So we have 80% developed in the market that is already quite large and installed base is quite large but also grown. Last year, gamers grew 20% [Indecipherable].
The third reason is that our demand is strong in our channel. And you can see that everyday with shortage of supply as quickly as we're shipping it. It's [Indecipherable] all over the world.
And then lastly, we have more growth drivers today because of RTX than ever. And we have the biggest wave of NVIDIA laptops. Just laptops is our fastest growing segment of computing and we have the largest wave of laptops coming. The demand for RTX in workstations, whereas previously the workstation market was a slow-growing market, it's now a fast growing market and has achieved records. And after more than a decade of working on cloud graphics, cloud graphics is in great demand. And so, all of these segments are seeing high demand while we continue to be supply limited. And so, I think the situations are very different and RTX is making a huge difference.
Operator
Thank you. We have the next question come from the line of Chris Caso of Raymond James. Your line is now open.
Chris Caso -- Raymond James -- Analyst
Yes. Thank you. Good evening. My question is about the split between the hyperscale and the vertical customers in the data center business and the trends you're seeing in each. I think, in your prepared remarks you said both would be up in the October quarter. But I'm interested to see if you're seeing any differing trends there, particularly in the vertical business as perhaps business conditions normalize and companies return to the office and they adjust their spending plans accordingly.
Colette Kress -- Executive Vice President and Chief Financial Officer
Yeah. So let me start out with the question and I'll let Jensen answer the tail. So far, with our data center business, with our Q2 results, our vertical industries are still quite a strong percentage. Essentially 50% of our data center business is going to our vertical industries. Our hyperscales make up the other portion of that slightly below the 50%. And then we also have our supercomputing business with a very small percentage but doing quite well. As we move into Q3 as we discussed, we will see an acceleration of both our vertical industries and our hyperscalers as we move into Q3.
With that backdrop, we'll see if Jensen has additional commentary.
Jensen Huang -- Founder, President and Chief Executive Officer
There's a fundamental difference in hyperscale use of HPC or AI versus the industrial use of HPC and AI. In the world of hyperscalers and Internet service providers, they're making recommendations on movies and songs and articles and search results and so on and so forth. And the difference in the improvement in hyper speed, the deep learning and artificial intelligence large recommender systems can provide us, they're really working for them.
In the world of industry, the reason why artificial intelligence is transformative, recognizing that most of the things I just mentioned earlier, it's not really dynamic in the world's largest industries, whether it's healthcare or logistics or transportation and retail, the vast majority of the reasons why in some of the physical sciences industries, whether it's energy or transportation and such or healthcare, the simulation of physics, the simulation of the world was not achievable using traditional first principle simulation approaches. But artificial intelligence or data-driven approaches has completely shaken that up and put it on its head.
And some examples, whether it's using artificial intelligence so that you could feed up the simulation of the prediction of the protein structure of an -- or the 3D structural protein, which was recently achieved by a couple of very important networks, it's groundbreaking. And by understanding the protein structure, 3D structure, we understand it -- we can better understand its function and how it would adapt to other proteins and other chemicals. And it's a fundamental step of the process in drug discovery and that has just taken a giant leap forward.
In the areas of clinical science, it is now possible to consider using data-driven approaches to create models that overcome this -- not overcome but accelerate and make it possible for us to simulate much, much larger simulations of multiphysics geometry-aware simulations, which is basically climate science. These are really important fields of work that wouldn't have been possible for another decade at least.
And just as we made it possible using artificial intelligence, the realization of real-time ray tracing in every field of science, whether it's climate simulation, energy discovery, drug discovery, we're starting to see the industry recognizing that the fusion of the first-principle simulation and data-driven artificial intelligence approaches is going to get a giant leap up. And that is a second dynamic.
The other dynamic for industry is for the very first time, they could deploy AI model out to the edge to do a better job with agriculture, to do a better job with asset protection and warehouses, to do a better job with automating retail. AI is going to make it possible for all of these types of automation to finally be realized. And so, the dynamics are all very different.
That last one has to do with Edge AI, which was just made possible by putting AI right at the point of data and right at the point of action because you need to be low cost, you need to be high performance and instantly responsive. And you can't afford to stream all of the data to the cloud all the time. And so each one of them has a slightly different [Technical Issues].
Operator
Thank you. Your final question comes from the line of William Stein of Truist Securities. Your line is open.
William Stein -- Truist Securities -- Analyst
Great. Thanks so much for taking my question. Jensen, I'm wondering if you can talk for a moment about Omniverse. This looks like a really cool technology, but I tend to get very few questions from investors about it. But it looks to me like this could be potentially very meaningful technology for you longer-term. Can you explain perhaps what capabilities and what markets this is going after? It looks like perhaps this is going to position you very well in augmented and virtual reality, but maybe it's a sort of different market or group of markets, it's a bit confusing to us. So, if you could maybe help us understand it, it would be really appreciated. Thank you.
Jensen Huang -- Founder, President and Chief Executive Officer
I really appreciate the question. And it's one of the most important things we're doing. The Omniverse, first of all, what is it? It's a simulator. It's a simulator that is physically accurate and physically based and was made possible because of two fundamental technologies we invented. One of them is of course RTX, the ability to physically simulate light behavior in the world, which is ray tracing. The second is the ability to compute or simulate the physics of -- simulate the artificial intelligence behavior of engines and objects inside the world. So we have the ability now to simulate physics in a realistic way and to create an architecture that allows us to do it in the cloud, distribute in a computed way and to be able to scale it out to very large systems.
The question is, what would you do with such a thing? The simulator -- simulation of virtual worlds with portals, we call them connectors, portals based on an industry standard open standard that was pioneered by Pixar. And as we mentioned earlier, we're partnering with Pixar and Apple to make it even broadly adopted -- even more broadly adopted. It's called UFD, universal field description. They’re basically portals or worm holes into virtual worlds. And this virtual world we're simulating, it could be a concert for consumers, it could be a theme park for consumers, [Technical Issues] in the world of industries, we could use it for simulating robots, different robots could learn how to be robots inside these virtual worlds before they're downloaded from the simulator to the real world. You can use it to simulate factories, which is one of the early works that we done with BMW that I showed at GTC.
Factory of the future that is designed completely in Omniverse, simulated in Omniverse, robots trained in Omniverse with goods and materials that are original, cad data put into the factory, the logistics plan like an ERP system -- this is an ERP system of physical grids and physical simulation simulated through this Omniverse world. And you could plan the entire factory in Omniverse. This entire factory now becomes what is called a digital tool. In fact, it could be a factory, it could be a stadium, it could be an airport, it could be an entire city, it could be a fleet of cars. The digital twin would allow us to simulate new algorithms, new AI, new -- and optimization algorithms before we deploy it into the physical world.
And so, what is Omniverse? Well, Omniverse is going to be an overload, if you will, of virtual worlds that increasingly people call the metaverse. And if you have heard several companies talk about the metaverse. They all come from different perspectives. Some of it from a social perspective, some of it from a gaming perspective, some of it in our case from an industrial and design and engineering perspective. But the Omniverse is essentially an overlay of the Internet, an overlay of the physical world. And it's going to fuse all these different worlds together long-term. And you'll be able to -- you mentioned VR and AR, you'll be able to go into the Omniverse worlds using virtual reality. And so you worm hole into the virtual world using VR. You could have an AI or an object portal into our world using augmented reality. So you could have a beautiful piece of art that you somehow purchased and belongs to you because of NT FTs and it's only enjoyed in the virtual world and you can load into the physical world with AI. So I'm fairly sure that at this point Omniverse and the metaverse is going to be a new economy that is larger than our current economy.
And we'll have to enjoy a lot of our time in the future in Omniverse and the metaverse. And we'll do a lot of our work there and we'll have a lot of robots there doing a lot of our work on our behalf. And we wake up in morning as they show us results. So, Omniverse to us is an extension of our AI strategy. It's an extension of our high-performance computing strategy. And it makes it possible for companies and industries to be able to create digital tools that simulates the physical version before they deploy it and while they operate it.
Operator
Thank you. I will now turn the call over back to Mr. Jensen Huang for closing remarks.
Jensen Huang -- Founder, President and Chief Executive Officer
Thank you. We had an excellent quarter driven by surging demand for NVIDIA computing. Our premium work in accelerated computing continues to [Indecipherable] computing AI. Enabled by NVIDIA accelerated computing, developers are creating the most impactful technologies of our time. Our Natural Language Understanding, our recommender systems and autonomous vehicles and logistic centers to digital biology and quantum science research, a metaverse world that obeys the laws of physics.
This quarter, we announced NVIDIA Base Command and Fleet Command to develop, deploy, scale and orchestrate the AI workload that run on the NVIDIA AI Enterprise software suite. With our new Enterprise software, a wide range of NVIDIA-powered systems and global network of systems and integration partners, we can accelerate the world's largest industries as they race to benefit from the transformative power of AI.
We are thrilled to have launched NVIDIA Omniverse, a simulation platform nearly five years in the making that runs physically realistic virtual worlds and connects to other digital platforms. If you imagine engineers, designers and even autonomous machines connecting to Omniverse to create digital twins simulated worlds that help train robots, operate autonomous factories, simulate fleets and autonomous vehicles and even predict human impact on earth's climate. The future will have artificial intelligence augmenting our own and the metaverse augmenting our physical world. It will be populated by real and AI visitors and open new opportunities for artists, designers, scientists and businesses, a whole new digital economy for the world emerge. Omniverse is a platform for building the metaverse vision.
We're doing some of our best work and most impactful work in our history. And I want to thank all of NVIDIA's employees for their amazing work and the exciting future we are inventing together. Thank you. See you next time.
Operator
[Operator Closing Remarks]
Duration: 69 minutes

--- Q3 2022 ---
Simona Jankowski -- Vice President, Investor Relations
Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the third quarter of fiscal 2023. With me today from NVIDIA are Jen-Hsun Huang, president and chief executive officer; and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on NVIDIA's investor relations website.
The webcast will be available for replay until the conference call to discuss our financial results for the fourth quarter and fiscal 2023. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations.
These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release our most recent Forms 10-K and 10-Q and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, November 16, 2022, and based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, Simona. Q3 revenue was $5.93 billion, down 12% sequentially and down 17% year on year. We delivered record data center and automotive revenue. while our gaming and pro visualization platforms declined as we work through channel inventory corrections and challenging external conditions.
Starting with data center. Revenue of $3.83 billion was up 1% sequentially and 31% year-on-year. This reflects very solid performance in the face of macroeconomic challenges new export controls and lingering supply chain disruptions. Year-on-year growth was driven primarily by leading U.S.
cloud providers and a broadening set of consumer Internet companies for workloads such as large language models, recommendation systems and generative AI. As the number and scale of public cloud computing and Internet service companies deploying NVIDIA AI grows our traditional hyperscale definition will need to be expanded to convey the different end market use cases. We will align our data center customer commentary going forward accordingly. Other vertical industries, such as automotive and energy, also contributed to growth with key workloads relating to autonomous driving, high-performance computing, simulations and analytics.
During the quarter, the U.S. government announced new restrictions impacting exports of our A100 and H-100 based products to China, and any product destined for certain systems or entities in China. These restrictions impacted third quarter revenue, largely offset by sales of alternative products into China. That said, demand in China more broadly remains soft, and we expect that to continue in the current quarter.
We started shipping our flagship 100 data center GPU based on the new hopper architecture in Q3. A100-based systems are available starting this month from leading server makers including Dell, Hewlett Packard Enterprise, Lenovo and SuperMicro. Early next year, the first H-100 based cloud instances will be available on Amazon Web Services, Google Cloud, Microsoft Azure and Oracle Cloud Infrastructure. A100 delivered the highest performance and workload versatility for both AI training and inference in the latest MLPerf industry benchmarks.
H-100 also delivers incredible value compared to the previous generation for equivalent AI performance it offers three x lower total cost of ownership while using five x fewer server nodes and 3.5 x less energy. Earlier today, we announced a multiyear collaboration with Microsoft to build an advanced cloud-based AI supercomputer to help enterprises train, deploy and scale AI including large state-of-the-art models. MacBook Azure will incorporate our complete AI stack, adding tens and thousands of A100 and A100 GPUs. Quantum 2 400 gigabit per second InfiniBand networking and the NVIDIA AI enterprise software suite to its platform.
Oracle and NVIDIA are also working together to offer AI training and inference at scale to thousands of enterprises. This includes bringing to Oracle Cloud infrastructure, the full NVIDIA accelerated computing stack and adding tens of thousands of NVIDIA GPUs, including the A100 and H-100. Cloud-based high-performance in the company, new scale is adopting NVIDIA AI enterprise and other software to address the industrial scientific communities, rising demand for AI in the cloud. NVIDIA AI will bring new capability to rescale high-performance computing as a service offerings, which include simulation and engineering software used across industries.
Networking posted strong growth driven by hyperscale customers and easing supply constraints. -- our new Quantum 240 gigabit per second InfiniBand and Spectrum Ethernet networking platforms are building momentum. We achieved an important milestone this quarter with VMware. And whose leading server virtualization platform, vSphere, has been rearchitected over the last two years to run on DPUs and now supports our BlueField DPUs.
Our joint enterprise AI platform is available first on Dell PowerEdge servers. The BlueField DPU design win pipeline is growing and the number of infrastructure softer partners is expanding, including Arista, Check Point, Juniper, [Inaudible] Networks and Red Hot. The latest top 500 list of supercomputers released this week at Supercomputing '22 and has the highest ever number of NVIDIA-powered systems, including 72% of the total and 90% of new systems on the list. Moreover, NVIDIA powers 23 of the top 30 of the Green 500 list, demonstrating the energy efficiency of accelerated computing.
The No. 1 most energy-efficient system is the Flat Iron Institute Henry, which is the first top 500 system featuring our H-100 GPUs. At GTC, we announced the NVIDIA Omniverse Computing System, or OVS, reference designs featuring the new L4 GPU based on the ADA Lovelace architecture. These systems are designed to build and operate 3D virtual world using NVIDIA Omniverse enterprise.
NVIDIA OBX systems will be available from Inspur, Lenovo and Super Micro by early 2023. We Lockheed Martin and Jaguar Land Rover will be among the first customers to receive OVS systems. We are further expanding our AI software and services offerings with NVIDIA and Bio Nemo large language model services, which are both entering early access this month. These enable developers to easily adopt large language models and deploy customized AI applications for content generation, tech summarization, chatbox, co-development, protein structure and biomolecular property predictions.
Moving to gaming. Revenue of $1.57 billion was down 23% sequentially and down 51% from a year ago, reflecting lower sell-in to partners to help align channel inventory levels with current demand expectations. We believe Channel inventories are on track to approach normal levels as we exit Q4. Sell-through for our gaming products was relatively solid in the Americas and EMEA and but softer in Asia Pac as macroeconomic conditions and covered lockdowns in China continued to weigh on consumer demand.
Our new Ada Lovelace GPU architecture had an exceptional launch. The first ADA GPU, the GeForce RTX 4090 became available in mid-October and a tremendous amount and positive feedback from the gaming community. We sold out quickly in many locations and are working hard to keep up with demand. The next member of the ATA family, RTX 4080 is available today.
The RTX 40 Series GPUs features DLSS 3, the neuro rendering technology that uses AI to generate entire frames for faster game play. Our third-generation RTX technology has raised the bar for computer graphics and help supercharge gaming. For example, the 15-year old classic game portal, now reimagined with full ray tracing and DLSS 3 has made it on Steam's top 100 most wish-listed gains. The total number of RTX games and applications now exceeds 350.
There is tremendous energy in the gaming community that we believe will continue to fuel strong fundamentals over the long term. The number of simultaneous users on steam just hit a record of $30 million, surpassing the prior peak of $28 million in January. Activision's Call of Duty Modern Warfare 2 set a record for the franchise with more than $800 million in opening weekend sales. topping the combined box office openings of movie blockbusters, TopGun Maverick and Dr.
Strains in the Multiverse of [Inaudible]. And this month's League of Legends World Championship in San Francisco sold out minutes with 18,000 esports fans packed the arena where the Golden State Warriors play. We continue to expand the GeForce NOW cloud gaming service. In Q3, we added over 85 games to the library, bringing the total to over 1,400.
We also launched GeForce now on the new gaming devices, including Logitech, Cloud handheld, cloud gaming Chromebooks and Razor 5G Edge. Moving to Probi Revenue of $200 million was down 60% sequentially and down 65% from a year ago, reflecting lower sell-in to partners to help align channel inventory levels with the current demand expectations. These dynamics are expected to continue in Q4. Despite near-term challenges, we believe our long-term opportunity remains intact, fueled by AI simulation, computationally intensive design and engineering workloads.
At GTC, we announced NVIDIA Omniverse Cloud Services, our first software and infrastructure as a service offering, enabling artists, developers and enterprise teams to design, publish and operate metaverse applications from anywhere on any device. Omniverse Cloud Services runs on Omniverse cloud computer, a computing system comprised of NVIDIA OBX for graphics and physics simulation. NVIDIA HDX for AI workloads and the NVIDIA graphics delivery network, a global scale, distributed data center network for delivering low-latency metaverse graphics on the edge. Leaders in some of the world's largest industries continue to adopt Omniverse.
Home improvement retailer, Lowe's is using it to help design, build and operate digital twins for their stores. Charter Communications and advanced analytics company, heavy AI are creating Omniverse power digital twins to optimize Charter's wireless network. In Deutsche Bahn, operator of German National Railway is using Omniverse to create digital twins of its rail network and train AI models to monitor the network, increasing safety and reliability. Moving to automotive.
Revenue of $251 million, increased 14% sequentially and 86% from a year ago. Growth was driven by an increase in AI automotive solutions as our customers drive or on-based production ramp, continue to scale. Automotive has great momentum and is on its way to be our next multibillion-dollar platform. Global cars unveiled the all-new flagship Volvo EX90 SUV powered by the NVIDIA Drive platform.
This is the first model to use Volvo's software-defined architecture with a centralized core computer containing both drive Orin and DRIVEXaviar, along with 30 sensors. Other recently announced design wins and new model introductions include ton, auto, Neo, Polystar and [Inaudible]. At GTC, we also announced that NVIDIA Drive Super Chip, the successor to Orin in our automotive SoC road map, drive [Inaudible] delivers up to 2,000 tariff lots of performance and leverages technologies introduced in our Grace Hopper and ADA architectures. It is capable of running both the automated drive and in-vehicle infotainment systems.
Simultaneously offering a LIFA performance while reducing cost and energy consumption. Driver will be available for automakers 25 models with Geely owned automaker, Zika as the first announced customer. Moving to the rest of the P&L. GAAP gross margin was 53.6% and and non-GAAP gross margin was 56.1%.
Gross margins reflect $702 million in inventory charges largely related to lower data center demand in China, partially offset by a warranty benefit of approximately $70 million. Year-on-year, GAAP operating expenses were up 31%, and non-GAAP operating expenses were up 30%, primarily due to higher compensation expenses related to headcount growth and salary increases and higher data center infrastructure expenses. Sequentially, both GAAP and non-GAAP operating expense growth was in the single-digit percent, and we plan to keep it relatively flat at these levels over the coming quarters. We returned $3.75 billion to shareholders in the form of share repurchases and cash dividends.
At the end of Q3, we had approximately $8.3 billion remaining under our share repurchase authorization through December 23. Let me turn to the outlook for the fourth quarter of fiscal 2023. We expect our data center revenue to reflect early production shipments of the A100, offset by continued softness in China. In gaming, we expect to resume sequential growth with our revenue still below end demand as we continue to work through the channel inventory correction.
And in automotive, we expect the continued ramp of our Oren design wins. All in, we expect modest sequential growth driven by automotive, gaming and data center. Revenue is expected to be $6 billion, plus or minus 2%. GAAP and non-GAAP gross margins are expected to be $63.2 million and 66%, respectively, plus or minus 50 basis points.
GAAP operating expenses are expected to be approximately $2.56 billion. Non-GAAP operating expenses are expected to be approximately $1.78 billion. GAAP and non-GAAP other income and expenses are expected to be an income of approximately $40 million, excluding gains and losses on nonaffiliated investments. GAAP and non-GAAP tax rates are expected to be 9%, plus or minus 1%, excluding any discrete items.
Capital expenditures are expected to be approximately $500 million to $550 million. Further financial details are included in the CFO commentary and other information available on our IR website. In closing, let me highlight upcoming events for the financial community. We'll be attending the Credit Suisse conference in Phoenix on November 30.
The rate Virtual Tech Conference on December 5 and and the JPMorgan Forum on January 5 in Las Vegas. Our earnings call to discuss the results of our fourth quarter and fiscal 2023 are scheduled for Wednesday, February 22. We will now open the call for questions. Operator, could you please poll for questions?
Operator
[Operator instructions] Your first question comes from the line of Vivek Arya with Bank of America Securities. Your line is now open.
Vivek Arya -- Bank of America Merrill Lynch -- Analyst
Thanks for taking my question. Colette, just wanted to clarify first, I think last quarter, you gave us a sell-through rate for your gaming business at about $2.5 billion a quarter. I think you said China is somewhat weaker. So I was hoping you could update us on what that sell-through rate is right now for gaming.
And then, Jen-Hsun, the question for you. A lot of concerns about large hyperscalers cutting their spending and pointing to a slowdown. So if, let's say, U.S. cloud capex is flat or slightly down next year, do you think your business can still grow in the data center and why?
Colette Kress -- Executive Vice President and Chief Financial Officer
Yes. Thanks for the question. Let me first start with the sell-through on our gaming business. we had indicated, if you put two quarters together, we would see approximately $5 billion in normalized sell-through for our business.
Now, during the quarter, sell-through in Q3 three was relatively solid. We've indicated that although China lockdowns continue to channel -- excuse me, challenge our overall China business. It was still relatively solid. Notebook sell-through was also quite solid.
And desktop, a bit softer, particularly in that China and Asia areas. We expect though stronger end demand, though, as we enter into Q4, driven by the upcoming holidays, as well as the continuation of the ADA adoption.
Jen-Hsun Huang -- President and Chief Executive Officer
Vivek, our data center business is indexed to two fundamental dynamics. The first has to do with general purpose computing no longer scaling. And so, acceleration is necessary to achieve the necessary level of cost efficiency scale and energy efficiency scale so that we can continue to increase workloads while saving money and saving power. Accelerated computing is recognized generally as the path forward as general purpose computing slows.
The second dynamic is AI. And we're seeing surging demand in some very important sectors of AIs in important breakthroughs in AI. One is called deep recommender systems, which is quite essential now to the best content or item or product to recommend to somebody who's using a device that is like a selfie or interacting with a computer just using voice. You need to really understand the nature, the context of the person making the request and make the appropriate recommendation to them.
The second has to do with large language models. This is -- this started several years ago with the invention of the transformer, which led to Bert, which led to GP3, which led to a whole bunch of other models now associated with that. We now have the ability to learn representations of languages of all kinds. It could be human language.
It could be the language of biology. It could be the language of chemistry. And recently, I just saw a breakthrough called Jeans LM, we just one of the first example of learning the language of human genomes. The third has to do with generative AI.
You know that the first 10 years, we've dedicated ourselves to perception AI. But the goal of perception, of course, is to understand context. But the ultimate goal of AI is to make a contribution to create something to generate product. And this is now the beginning of the era of generative AI.
You probably see it all over the place, whether they're generating images or generating videos or generating text of all kinds and the ability to augment our performance to enhance our performance to make productivity enhanced to reduce cost and improve whatever we do with whatever we have to work with, productivity is really more important than ever. And so, you could see that our company is indexed to two things, both of which are more important than ever, which is power efficiency, cost efficiency and then, of course, productivity. And these things are more important than ever. And my expectation is that we're seeing all the strong demand and surging demand for AI and for niche reasons.
Operator
Your next question comes from the line of C.J. Muse with Evercore. Your line is now open.
C.J. Muse -- Evercore ISI -- Analyst
Yeah, Good afternoon and thank you for taking the question. You started to bundle on NVIDIA enterprise now with the H-100. I'm curious if you can talk about how we should think about timing around software monetization? And how we should kind of see this flow through the model, particularly with the focus on the AI enterprise and Omnivere side of things?
Jen-Hsun Huang -- President and Chief Executive Officer
Yes. Thanks, CJ. We're making excellent progress in NVIDIA AI enterprise. In fact, you saw probably that we made several announcements this quarter associated with clouds.
You know that NVIDIA has a rich ecosystem. And over the years, our rich ecosystem and our software stack has been integrated into developers and start-ups of all kinds, but more so -- more than ever, we're at the tipping point of clouds, and that's fantastic. Because if we could get NVIDIA's architecture and our full stack into every single cloud, we could reach more customers more quickly. And this quarter, we announced several initiatives, one has several partnerships and collaborations, one that we announced today, which has to do with Microsoft and our partnership there.
It has everything to do with scaling up AI because we have so many start-ups clamoring for large installations of our GPU so that they could do large language model training and building their start-ups and scale out of AI to enterprise and all of the world's Internet service providers. Every company we're talking to would like to have the agility and the scale, flexibility of clouds. And so, over the last year or so, we've been working on moving all of our software stacks to the cloud are of our platform and software stacks to the cloud. And so, today, we announced that Microsoft and ourselves are going to standardize on the NVIDIA stack, for a very large part of the work that we're doing together so that we could take a full stack out to the world's enterprise.
That's all software included. We, a month ago, announced the same similar type of partnership with Oracle. You also saw that rescale a leader in high-performance computing cloud has integrated NVIDIA AI into their stack. [Inaudible] has been integrated into GCP.
And we announced recently Nemo, large language model and bionemo large language model to put NVIDIA software in the cloud. And we also announced Omniverse is now available in the cloud. The goal of all of this is to move the NVIDIA platform full stack off boarding the cloud so that we can engage customers much, much more quickly and customers could engage our software if they would like to use it in the cloud, it's per GPU instance hour if they would like to utilize our software on-prem, they could do it through software license. And so, license and subscription.
And so, in both cases, we now have software available practically everywhere you would like to engage it. The partners that we work with are super excited about it because MBDA's rich ecosystem is global, and this could bring both new consumption into their cloud for both them and ourselves, but also connect all of these new opportunities to the other APIs and other services that they offer. And so, our software stack is making really great progress.
Operator
Your next question comes from the line of Chris Caso with Credit Suisse. Your line is now open.
Chris Caso -- Credit Suisse -- Analyst
Yes. Thank you. Good evening. I wonder if you could give some more color about the inventory charges you took in the quarter and then internal inventory in general.
In the documentation, you talked about that being a portion of inventory on hand plus some purchase obligations. And you also spoke in your prepared remarks that some of this was due to China data centers. So if you can clarify what was in those charges. And then, in general, for your internal inventory.
Does that still need to be worked down? And what are the implications if that needs to be worked down over the next couple of quarters?
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks for the question, Chris. So as we highlighted in our prepared remarks, we booked an entry of $702 million for inventory reserves within the quarter. Most of that, primarily, all of it is related to our data center business, just due to the change in expected demand looking forward for China. So when we look at the data center products, a good portion of this was also the A100, which we wrote down.
Now, looking at our inventory that we have on hand and the inventory that has increased, a lot of that is just due to our upcoming architectures coming to market. our ADA architecture, our hopper architecture and even more in terms of our networking business. We have been building for those architectures to come to market and as such to say. We are always looking at our inventory levels at the end of each quarter for our expected demand going forward.
But I think we've done a solid job that we used in this quarter just based on that expectation going forward.
Operator
Your next question comes from the line of Timothy Arcuri with UBS. Your line is now open.
Timothy Arcuri -- UBS -- Analyst
Thanks a lot. Colette, can you -- I have a two-part question. First, is there any effect of stockpiling in the data center guidance? I ask because you now have the A800 that is sort of a modified version of the A100 with the lower data transfer rate. So one could imagine that customers might be stocking that while they can still get it.
And I guess the second part of that is related to the inventory charge, can you just go into that a little bit more? Because last quarter, it made sense that you took a charge because revenue was less than you thought, but revenue came in pretty much in line. And it sounded like China was a net neutral. So is the charge related to just working A100 inventory down faster? Is that what the charges related to?
Colette Kress -- Executive Vice President and Chief Financial Officer
Sure. So let me talk about the first statement that you indicated. Most of our data center business that we see is we're working with customers specifically on their needs to build out accelerated computing and AI. It's just not a business in terms of where units are being held for that.
They're usually four very, very specific products and projects that we see. So I'm going to answer no. Nothing that we can see. Your second question regarding the inventory provisions.
At the end of last quarter, we were beginning to see softness in China. We've always been looking at our needs long term. It's not a statement about the current quarter in inventory, as you can see. It usually takes two or three quarters for us to build product for the future demand.
So that's always a case of the inventory that we are ordering. So now looking at what we've seen in terms of continued lockdowns, continued economy challenges in China it was time for us to take a hard look of what do we think we'll need for data center going forward and not leg for write-downs.
Operator
Your next question comes from the line of Stacy Rasgon with Bernstein. Your line is now open.
Stacy Rasgon -- AllianceBernstein -- Analyst
Hi, guys. Thanks for taking my question. Colette, I had a question on the commentary you gave on the sequentials. It kind of sounded like data center maybe had some China softness issues.
You said gaming resumed sequential growth. But then you said sequential growth for the company driven by auto gaming and data center. How can all three of those grow sequentially if the overall guidance is kind of flattish? Are they all just like growing just a little bit? Or is one of them actually down? Like how do we think about the segments into Q4 given that commentary?
Colette Kress -- Executive Vice President and Chief Financial Officer
Yes. So your question is regarding the sequentials from Q3 to our guidance that we provided for Q4. As we are seeing the numbers in terms of our guidance, you're correct, is only growing about $100 million. And we've indicated that three of those platforms will likely grow just a little bit.
But our pro visualization business we think is going to be flattish and likely not growing as we're still working on correcting the channel inventory levels. to get to the right amount. It's very difficult to say which will have that increase. But again, we are planning for all three of those different market platforms to grow just a little bit.
Operator
Your next question comes from the line of Mark Lipacis with Jefferies. Your line is now open.
Mark Lipacis -- Jefferies -- Analyst
Hi. Thanks for taking my question. Jen-Hsun, I think for you, you've articulated a vision for the data center we're a solution with an integrated solution set of a CPU, GPU and DPU is deployed for all workloads or most workloads, I think. Could you just give us a sense of or talk about where is this vision in the penetration cycle? And maybe talk about Grace Grace's importance for realizing that vision, what will Grace deliver versus an off-the-shelf x86 where -- do you have a sense of where Grace will get embraced first or the fastest within that vision?
Jen-Hsun Huang -- President and Chief Executive Officer
Grace's data moving capability is off the charts. Grace also is memory coherent to our GPU, which allows our GPU to expand its effective GPU memory, fast GPU memory by a factor of 10. That's not possible without special capabilities that are designed between hopper and Grace and the architecture of Grace. And so, it was designed.
Grace is designed for very large data processing at very high speeds. Those applications are related to, for example, data processing is related for recommender systems, which operates on petabytes of live data at a time. It's all hot. It all needs to be fast, so that you can make a recommendation within milliseconds to hundreds of millions of people using our service.
It is also quite effective at AI training, machine learning. And so, those kind of applications are really terrific. We -- Grace, I think I've said before that we will have production samples in Q1, and we're still on track to do that.
Operator
Your next question comes from the line of Harlan Sur with J.P. Morgan. Your line is now open.
Harlan Sur -- JPMorgan Chase and Company -- Analyst
Good afternoon and thanks for taking my question. Your data center networking business, I believe, is driving about $800 million per quarter in sales, very, very strong growth over the past few years. Near term, as you guys pointed out, and the team is driving strong Nick and blue food attached to your own compute solutions like DGX and more partner announcements like VMware, but we also know that networking has pretty large exposure to general purpose cloud and hyperscale compute spending trends. So what's the visibility and growth outlook for the networking business over the next few quarters?
Jen-Hsun Huang -- President and Chief Executive Officer
Yes. If I could take that. First, thanks for your question. Our networking, as you know, is heavily indexed to high-performance computing.
We're not -- we don't serve the vast majority of commodity networking. All of our network solutions are very high end, and they're designed for data centers that move a lot of data. Now, if you have a hyperscale data center these days, and you are deploying a large number of AI applications. It is very likely that the network bandwidth that you provision has a substantial implication on the overall throughput of your data center.
So the small incremental investment they make in high-performance networking translates to billions of dollars of savings slightly in provisioning the service or billions of dollars more throughput, which increases their economics. And so, these days, with disaggregated and I application, AI provisioning and data centers, high-performance networking is really quite fantastic and it pays for itself right away. But that's where we are focused in high-performance networking and provisioning AI services in -- well, the AI applications that we focus on. You might have noticed that NVIDIA and Microsoft are building one of the largest AI infrastructures in the world.
And it is completely powered by NVIDIA's InfiniBand 400 gigabits per second network. And the reason for that is because that network pays for itself instantaneously. The investment that you're going to put into the infrastructure is so significant that if you were to be dragged by slow networks, obviously, the efficiency of the overall infrastructure is not as high. And so, in the places where we focus networking is really quite important.
It goes all the way back to when we first announced the acquisition of Mellanox. I think at the time, they were doing about a few hundred million dollars a quarter, about $400 million a quarter. And now we're doing what they used to do in the old days, in a year, practically coming up in a quarter. And so, that kind of tells you about the growth of high-performance networking.
It is an indexed to overall enterprise and data center spend but it is highly indexed to AI adoption.
Operator
Your next question comes from the line of Aaron Rakers with Wells Fargo. Your line is now open.
Aaron Rakers -- Wells Fargo Securities -- Analyst
Thanks for taking the question. I want to expand on the networking question a little bit further. When we look at the Microsoft announcement today, we think about what Meda is doing on the AI footprint that they're deploying. Jen-Hsun, can you help us understand like where your InfiniBand networking sits relative to like traditional data center switching? And maybe kind of build on that, how you're positioning spectrum for in the market, does that compete against a broader set of opportunities in the Ethernet world for AI fabric networking?
Jen-Hsun Huang -- President and Chief Executive Officer
Yes. Thanks, Erin. The math is like this. If you're going to spend $20 billion on an infrastructure and the efficiency of that overall data center is improved by 10%.
The numbers are huge. And when we do these large language models and recommender systems, the processing is done across the entire data center. And so, we distribute the workload across multiple GPUs, multiple nodes and it runs for a very long time. And so, the importance of the network can be overemphasized.
And so, the difference of 10% in overall improvement in efficiency, which is very to achieve. The difference between NVIDIA's InfiniBand, the entire software stack with what we call Magnum IO, which allows us to do computing in the network itself. A lot of software is running in the network itself, not just moving data around. We call it in-network computing because a ton of software is done at the edge at the -- within the network itself.
We achieved significant differences in overall efficiency. And so, if you're spending billions of dollars on the infrastructure, or even hundreds of millions of dollars of interest on the infrastructure. The difference is really quite profound.
Operator
Your next question comes from the line of Ambrish Srivastava with BMO. Your line is now open.
Ambrish Srivastava -- BMO Capital Markets -- Analyst
Hi. Thank you very much. I actually had a couple of clarifications. Colette, in the data center side, is it a fair assumption that compute was down Q-over-Q in the reported quarter because the quarter before, Mellanox or the networking business was up as it was called out.
And again, you said it grew quarter over quarter. So is that a fair assumption? And then, I had a clarification on the USG band. Initially, it was supposed to be a $400 million, really going to what the government was trying to firewall. Is the A800 -- I'm just trying to make sure I understand it.
Isn't that against the spirit of what the government is trying to do, i.e., firewall, high-performance compute? Or is A800 going to a different set of customers?
Colette Kress -- Executive Vice President and Chief Financial Officer
Thank you for the question. So looking at our compute for the quarter is about flattish. Yes, we're seeing also growth growth in terms of our networking, but you should look at our Q3 compute is about flatters with last quarter.
Jen-Hsun Huang -- President and Chief Executive Officer
Ambrish, A800 hardware, the hardware of ensures that it always meets U.S. government's clear test for export control. And it cannot be customer reprogrammed or application reprogrammed to exceed it. It is hardware limited.
It is in the hardware that determines 800s capabilities. And so, it meets the clear test in letter and in spirit. We raised the concern about the $400 million of A100s because we were uncertain about whether we could execute. The introduction of A800 to our customers and through our supply chain in time.
The company did remarkable feeds to swarm this situation and make sure that our business was not affected and our customers were not affected. But A800 hardware surely ensures that it always meets U.S. government's clear tests for export control.
Operator
Your next question comes from the line of William Stein with Truist Securities. Your line is now open.
William Stein -- Truist Securities -- Analyst
Thank you. I'm hoping you can discuss the pace of 100 growth as we progress over the next year. We've gotten a lot of questions as to whether the ramp in this product should look like a sort of traditional product cycle where there's quite a bit of pent-up demand for this significant improved performance product and that there's supply available as well. So does this rollout sort of look relatively typical from that perspective? Or should we expect a more perhaps delayed start of the growth trajectory where we see maybe substantially more growth in, let's say, second half of '23.
Jen-Hsun Huang -- President and Chief Executive Officer
H-100 ramp is different than the A100 ramp in several ways. The first is that the TCO, the cost benefits, the operational cost benefits because of the energy savings because every data center is now Power Limited. And because of this incredible transformer engine that's designed for the latest AI models. The performance over Ampere is so significant that I -- and because of the pent-up demand for hopper because of these new models that are that I spoke about earlier, deep recommender systems and large language models and generative AI models.
Customers are clamoring to ramp hopper as quickly as possible, and we are trying to do the same. We are all hands on deck to help the cloud service providers stand up the supercomputers. Remember, I is the only company in the world that produces and ships semi-custom supercomputers in high volume. It's a miracle to ship one supercomputer every three years.
it's unheard of to ship supercomputers to every cloud service provider in a quarter. And so, we're working hand with every one of them, and every one of them are racing to stand up hoppers. We expect them to have hopper cloud services stood up in Q1. And so, we are expecting to ship some volume, we're expecting to ship production in Q4, and then we're expecting to ship large volumes in Q1.
That's a faster transition than MPIR. And so, it's because of the dynamics that I described.
Operator
Your next question comes from the line of Matt Ramsay with Cowen. Your line is now open.
Matt Ramsay -- Cowen and Company -- Analyst
Yeah. Thank you very much. Good afternoon. I guess, Colette, I heard in your script that you had talked about maybe a new way of commenting on or reporting hyperscaler revenue in your data center business.
And I wonder if you could maybe give us a little bit more detail about what you're thinking there and what sort of drove the decision? And I guess the derivative of that, Jen-Hsun, how -- that decision to talk about the data center business to hyperscalers differently. I mean, what does that mean for the business that is just a reflection of where demand is and you're going to break things out differently? Or is something changing about the mix of I guess, internal properties versus vertical industry demand within the hyperscale customer base.
Colette Kress -- Executive Vice President and Chief Financial Officer
Yes, Matt, thanks for the question. Let me clarify a little bit in terms of what we believe we should be looking at when we go forward and discussing our data center business. Our data center business is becoming larger and larger and our customers are complex. And when we talk about hyperscale, we tend to talk about seven, eight different companies.
But the reality is there's a lot of very large companies that we could add to that discussion based on what they're purchasing. Additionally, looking at the cloud, looking at our cloud purchases and what our customers are building for the cloud is an important area to focus on because this is really where our enterprise is where our researchers, where our higher education is also purchasing. So we're trying to look for a better way to describe the color of what we're seeing in the cloud and also give you a better understanding of some of these large installments that we're seeing in the hyperscales.
Jen-Hsun Huang -- President and Chief Executive Officer
Yes. Let me double click on what Colette just said, which is absolutely right. There are two major dynamics that's happening. First, the adoption of NVIDIA in Internet service companies around the world, the number and the scale by which they're doing it has grown a lot.
Internet service companies. And these are Internet service companies that offer services, but they're not public cloud computing companies. The second factor has to do with cloud computing. We are now at the tipping point of cloud computing.
Almost every enterprise in the world has both a cloud-first and a multi-cloud strategy. It is exactly the reason why all of the announcements that we made this year -- this quarter, this last quarter since GTC about all the new platforms that are now available in the cloud. a CSP, a hyperscaler is both -- are two things to us, therefore, a hyperscaler can be a sell to customer. They are also a cell with partner on the public cloud side of their business.
Because of the richness of NVIDIA's ecosystem because we have so many Internet service customers and enterprise customers using NVIDIA's full stack. The public cloud side of their business really enjoys and values the partnership with us and the cell with relationship they have with us. And it's pretty clear now that for all of the hyperscalers, the public cloud side of their business will likely would very likely be the vast majority of their overall consumption. And so, because the world CSPs, the world's public clouds is only at the early innings of their enterprise to lifting enterprise to the cloud world it's very, very clear that the public cloud side of the business is going to be very large.
And so, increasingly, our relationship with CSPs, our relationship with hyperscalers will -- will include, of course, continuing to sell to them for internal consumption but very importantly, sell with for the public cloud side.
Operator
Your next question comes from the line of Joseph Moore with Morgan Stanley. Your line is now open.
Joseph Moore -- Morgan Stanley -- Analyst
Great. Thank you. I wonder if you could talk to looking backward at the crypto impact. Obviously, that's gone from your numbers now, but do you see any potential for liquidation of GPUs that are in the mining network, any impact going forward? And do you foresee blockchain being an important part of your business at some point down the road?
Jen-Hsun Huang -- President and Chief Executive Officer
We don't expect to see blockchain being an important part of our business down the road. There is always a resell market. If you look at any of the major resell sites, eBay, for example, there are secondhand graphics cards for sale all the time. And the reason for that is because a 3090 that somebody bought today, is upgraded to a 4090 or 3090 by a couple of years ago, it was up are until 4090 today.
That 3090 could be sold to somebody and enjoyed it sold at the right price. And so, the volume of -- the availability of secondhand and used graphics cards has always been there. And the inventory is never zero. and when the inventory is larger than usual, like all supply demand, it would likely drift lower price and affect the lower ends of our market.
But my sense is that where we're going right now with ADA is targeting very clearly in the upper range, the top half of our market. And and early signs are, and I'm sure you're also seeing that the ADA launch was a home run. That we shipped a large volume of 4090s because as you know, we were prepared for it. And yet within minutes, they were sold out around the world.
And so, the reception of 4090 and the reception of 4080 today has been off the charts. And that says something about the strength and the health and the vibrancy of the gaming market. So we're super enthusiastic about the ADA launch. We have many more ad products to come.
Operator
Your last question today comes from the line of Toshiya Hari with Goldman Sachs. Your line is now open.
Toshiya Hari -- Goldman Sachs -- Analyst
Great. Thank you so much for squeezing me in. I had two quick ones for Colette. On supply, I think there was some mixed messaging in your remarks.
I think you talked about supply being a headwind at one point. And then, when you were speaking to the networking business, I think you talked about supply easing. So I was hoping you can kind of speak to supply if you're caught up to demand at this point. And then, secondly, just on stock-based compensation, pretty mundane topic I realize, but it is -- I think in the quarter, it was about $700 million.
It's becoming a bigger piece of your opex. So curious how we should be modeling that going forward.
Colette Kress -- Executive Vice President and Chief Financial Officer
Sure. When we look at our supply constraints that we have had in the past, each and every quarter, this is getting better Networking was one of our issues probably a year ago, and it has taken us probably to this quarter. and next quarter to really see our supply improved so that we can support the pipeline that we have for our customers that are -- now that's our supply. We've also made a discussion regarding our customers, supply constraints, issues when setting up a data center, even getting data center capacity has been very difficult.
And therefore, that challenges them in their purchasing decisions as they're still looking for certain parts of that supply chain to come through. So that hopefully clarifies what we were talking about regarding two areas of supply. In our stock-based compensation, what we'll see, it's very difficult to predict what our stock-based compensation would be when it arrives. We have provided to our incoming employees but also once a year to our employees, and it's a single date in terms of when that is priced.
So it's difficult to determine, but stock-based compensation is an important part of our employees' compensation and will continue to be. So we look at it from an overall compensation perspective. So up until now and when we do the focal, we'll see about the same size with a few additions for the reduced level of employee hiring that we have right now.
Operator
Thank you. I will now turn the call back over to Jen-Hsun Huang for closing remarks.
Jen-Hsun Huang -- President and Chief Executive Officer
Thanks, everyone. We are quickly adapting to the macro environment. Correcting inventory levels, offering alternative products to data center customers in China and keeping our opex flat for the next few quarters. Our new platforms are off to a great start and formed the foundation for our resumed growth.
MRTX is reinventing 3D graphics with ray tracing and AI. The launch of [Inaudible] is phenomenal. Gamers waited in long lines around the world, 4090 stocks sold out quickly. Hopper, with its revolutionary transformer engine is just in time to meet the surging demand for recommender systems, large language models and generative AI.
NVIDIA networking is synonymous with the highest data center throughput and enjoying record results. Oren is the world's first computing platform designed for AI-powered autonomous vehicles and robotics and putting automotive on the road to be our next multibillion-dollar platform. These computing platforms run NVIDIA AI and NVIDIA Omniverse, software libraries and engines that help the companies build and deploy AI to products and services. we this pioneering work and accelerated computing is more vital than ever.
Limited by business, general purpose commuting has slowed to a crawl just as AI demands more computing. Scaling through general purchase computing alone is no longer viable, both from a cost or power standpoint. Accelerated computing is the path forward. We look forward to updating you on our progress next quarter.
Operator
[Operator signoff]
Duration: 0 minutes
Simona Jankowski -- Vice President, Investor Relations
Colette Kress -- Executive Vice President and Chief Financial Officer

--- Q4 2022 ---
All lines have been placed on mute to prevent any background noise. After the speakers' remarks, there'll be a question-and-answer session. [Operator instructions] Simona Jankowski, you may begin your conference.
Simona Jankowski -- Vice President of Investor Relations
Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the fourth quarter of fiscal 2022. With me today from NVIDIA are Jensen Huang, president and chief executive officer; and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website.
The webcast will be available for replay until the conference call to discuss our financial results for the first quarter of fiscal 2023. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations.
These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, February 16, 2022, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette. 
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, Simona. We had an excellent quarter with revenue up 53% year on year to $7.6 billion. We set records for total revenue, as well as for Gaming, Data Center, and Professional Visualization. Full-year revenue was a record $26.9 billion, up 61%, compounding the prior year's growth of 53%.
Starting with Gaming, revenue of $3.4 billion rose 6% sequentially and was up 37% from a year earlier. Fiscal year revenue of $12.5 billion was up 61%. Gaming has become the top entertainment medium that continues to show strong momentum. Just last month, Steam hit a record 28 million concurrent users, up 50% in two years.
Record desktop revenue in the quarter was led by our growth in our GeForce RTX 30 Series products with continued strength in the high end. At CES, we announced the RTX 3050 GPO, which hit retail in late January, bringing NVIDIA RTX and AI technologies to more mainstream audiences. Laptop gaming revenue also set a record, driven by the ramp of the new GeForce RTX 3070 Ti and 3080 GPUs, which were also announced at CES. These leverage our fourth-generation Max-Q technology to enable quiet and light gaming laptops.
All in, we announced over 160 new laptop designs for NVIDIA and tier architecture RTX 30 Series GPUs. These include a number of studio systems targeting the tens of millions of creators driving the future of design, innovation, and virtual world. In addition to supporting the new RTX 30 Series GPUs, Studio laptops future support for NVIDIA software with Omniverse, Tundus, and Broadcast. Availability of our gaming products in the channel remains low.
NVIDIA RTX ecosystem continues to expand with over 30 new RTX games and applications added this quarter, including blockbuster hit like Battlefield 2042, Grand Theft Auto, Call of Duty: Vanguard, and God of War. In addition, several new titles support NVIDIA Reflex for low-latency impact. Our GPUs are capable of cryptocurrency mining, so we have limited visibility into how much of this impacts our overall GPU demand. Nearly all desktop NVIDIA Ampere architecture GeForce GPU shipments are light cache rate to help direct GeForce supply to gamers.
Cryptomining processor revenue was $24 million, which is included in OEM and other. We continue to expand the NVIDIA GeForce NOW cloud gaming ecosystem with new hit titles, including EA's Battlefield 4 and Battlefield V. At CES, we announced a partnership with Samsung to integrate GeForce NOW in its smart TVs starting in Q2 of this year. This follows last month's beta release of the GeForce NOW for LG smart TVs.
In addition, we teamed up with AT&T to bring GeForce NOW to 5G mobile devices in the U.S. We also added our first GFN data center in Canada. Moving to pro visualization. Q4 revenue was $643 million was up 11% sequentially and up 109% from a year ago.
Fiscal year revenue of $2.1 billion was up 100%. Sequential growth in the quarter was driven by a shift to higher-value workstation and the continued ramp of our NVIDIA healthcare architecture. We believe strong demand is fueled by continued build-outs for hybrid work environment, as well as growth in key workloads, including design, AI, and rendering. For example, Sony Pictures ImageWorks is using NVIDIA RTX to accelerate ray-tracing for rendering-related applications.
Motion is using NVIDIA RTX for AI to assist in predictive maintenance of the vehicles. And Duke Energy is using NVIDIA RTX for AI and VR to map, view, and maintain energy facilities. NVIDIA Omniverse enterprise software entered general availability. And while it's still in early days, customer feedback so far has been very positive, with multiple significant enterprise licensees already signed.
In addition to software licenses, Omniverse also drives computing opportunity for NVIDIA RTX in laptops, workstations, and on-prem servers, and the cloud. Omniverse can be used by individuals for free and by enterprise teams via software subscriptions. At CES, we made the free version of Omniverse for individual's general availability. Omniverse allows creators with RTX GPUs to connect leading 3D design applications to a single scheme and superset their work with AI and physics.
We also announced early access to Omniverse Cloud, which adds one-click capability to collaborate with other artists, whether across the room or across the globe. For digital twin applications, we announced the Isaac Autonomous Mobile Robot platform using Omniverse and securely orchestrated and cloud delivered with the platform optimizes operational efficiency and accelerate deployment from logistics remods. It consists of several NVIDIA AI technologies and SDKs, including data for high-precision mapping, metropolis, or situational awareness and reop for real-time route optimization. Moving to automotive.
Q4 revenue was $125 million, declined 7% sequentially and 14% from the year-ago quarter. Fiscal year revenue of $566 million was up 6%. We have just started shipments of our Orion-based product platform and expect to return to sequential revenue growth in Q1 with more meaningful inflection in the second half of the fiscal year and momentum building into calendar 2023. I will now hand it over to Jensen to provide more color on this morning's automotive news.
Jensen Huang -- President and Chief Executive Officer
Thanks, Colette. Earlier today, we announced a partnership with Jaguar Land Rover to jointly develop and deliver fleets of software-defined cars. Starting in 2025, all new Jaguar and Land Rover vehicles will have next-generation automated driving systems, plus AI-enabled software and services built on the NVIDIA DRIVE platform. DRIVE Orin will be the AI computer brain running our DRIVE AV and DRIVE IX software.
And the DRIVE Hyperion sensor network will be the central nervous system. This new vehicle architecture will enable a wide spectrum of active safety, automated driving, and parking systems. Inside the vehicle, the system will deliver AI features, including driver and occupant monitoring and advanced visualization of the vehicles surroundings. We are very much looking forward to partnering with Thierry Bollore, JLR's CEO, and his team to reinvent the future of luxury cars.
Our full-stack end-to-end approach is a new business model that offers downloadable AV and AI services to the fleet of JLR vehicles with a shared software revenue stream for both companies over the life of the fleet. This partnership follows the template of our announcement with Mercedes-Benz. Our shared software revenue opportunity with both OEMs will scale with the size of their NVIDIA-powered fleet, which, combined, can exceed 10 million cars over a decade. Colette, back to you.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, Jensen. Moving to Data Center. Record revenue of $3.3 billion grew 11% sequentially and 71% from a year earlier. Fiscal year revenue of $10.6 billion was up 58%.
Data center growth in the quarter was once again led by our compute products on strong demand for NVIDIA AI. Hyperscale and cloud demand was outstanding, with revenue more than doubling year on year. Vertical Industries also posted strong double-digit year-on-year growth led by consumer Internet companies. The flagship NVIDIA A100 GPU continue to drive strong growth.
Inference-focused revenue more than tripled year on year. Accelerating inference growth has been enabled by widespread adoption of our Triton and France server software, which helps customers deliver fast and scalable AI in production. Data center compute demand was driven by continued deployment of our Ampere architecture-based product for fast-growing AI workloads such as natural language processing and deep learning recommendation systems, as well as cloud executing. For example, Block Inc., a global leader in payment, uses conversational AI in its Square Assistant to schedule appointments with customers.
These AI models are trained on video GPUs in AWS and perform inference 10x faster on the AWS GP service and on our CPUs. Social media company Snap used NVIDIA GPUs and Merlin deep recommendator software to improve inference cost efficiency by 50% and decrease latency to 2x. For the third year in a row, industry benchmarks show that NVIDIA AI continues to lead the industry in performance. Along with partners like Microsoft Azure, NVIDIA such records in the latest benchmarks for AI training across eight popular AI workloads, including computer vision, natural language processing, recommendation systems, reinforcement learning, and detection.
NVIDIA AI was the only platform to make submissions across all benchmarks and use cases, demonstrating versatility, as well as our performance. The numbers show performance gains on our A100 GPUs of over 5x in just two months, thanks to continuous innovations across the full stack in AI algorithms, optimization tools, and system software. Over the past three years, they saw performance gains of over 20x powered by advances we have made across our full-stack offering GPUs, networks, systems, and software. The leading performance of NVIDIA AI is sought after by some of the world's most technically advanced companies.
Meta Platforms unveils its new AI supercomputer research, SuperCluster, with over 6,000 A100 GPUs moved to an NVIDIA -- Meta's early benchmarks showed its system can train large natural language processing models 3x faster and run computer vision jobs 20x faster than the prior system. In a second phase later this year, the system will expand to 16,000 GPUs that Meta believes will deliver 5x of mixed precision AI performance. In addition to performance at scale, Meta cited extreme reliability, security, privacy, and flexibility to handle a wide range of AI models as its key criteria for the system. We continue to broaden the reach and ease the adoption of NVIDIA AI into vertical industries.
Our ecosystem of NVIDIA-certified systems expanded with Cisco and Hitachi -- which joined Dell, HewlettPackard Enterprise, Insper, Lenovo, and Supermicro, among other sever manufacturers. We released version 1.1 of our NVIDIA AI Enterprise software, allowing enterprises to accelerated annual workloads on VMware, on mainstream IT infrastructure as well. And we expanded the number of system integrators qualified for NVIDIA AI Enterprise. Forrester Research in its evaluation of Enterprise AI infrastructure providers recognized NVIDIA in the top category of leaders.
An example of a partner that's helping to expand our reach into enterprise IT is Deloitte, a leading global consulting firm, which has built its center for AI computing on NVIDIA DGX Superpod. At CES, we extended our collaboration to AV development, leveraging our own robust AI infrastructure and Deloitte's team of 5,500 system integration developers and 2,000 data scientists to architect solutions for truly intelligent transportation. Our networking products posted strong sequential and year-over-year growth, driven by exceptional demand across use cases ranging from computing, supercomputing, and enterprise to storage adopters-led growth driven by adoption of our next-generation products and higher-speed deployments. While revenue was gated by supply, we anticipate improving capacity in coming quarters, which should allow us to serve with significant customer demands we're seeing.
Across the board, we are excited about the traction we are seeing with our new software business models, including NVIDIA AI, NVIDIA Omniverse, and NVIDIA DRIVE. We are still early in the software revenue ramp. Our pipelines are building as customers across the industry seek to accelerate their pace of adoption and innovation with NVIDIA. Now, let me turn it back over to Jensen for some comments on Arm.
Jensen Huang -- President and Chief Executive Officer
Thanks, Colette. Last week, we terminated our efforts to purchase Arm. When we entered into the transaction in September 2020, we believed that would accelerate Arm's focus on high-performance CPUs and help Arm expand into new markets, benefiting all our customers in the entire ecosystem. Like any combination of pioneers of important technologies, our proposed acquisition spurred questions from regulators worldwide.
We appreciated the regulatory concerns. For over a year, we worked closely with SoftBank and Arm to explain our vision for Arm and reassure regulators that NVIDIA would be a worthy steward of the Arm ecosystem. We gave it our best shot, but the headwinds were too strong, and we could not give regulators the comfort they needed to approve our deal. NVIDIA's work in accelerated computing and our overall strategy will continue as before.
Our focus is accelerated computing. We are on track to launch our Arm-based CPU, targeting giant AI and HPC workloads in the first half of next year. Our 20-year architectural license to Arm's IP allows us the full breadth and flexibility of options across technologies and markets. We will deliver on our three-chip strategy across CPUs, GPUs, and DPUs.
Whether x86 or Arm, we will use the best CPU for the job. And together with partners in the computer industry, offer the world's best computing platform to tackle the impactful challenges of our time. Back to you, Colette.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, Jensen. We're going to turn to our P&L and our outlook. For the discussion of the rest of the P&L, please refer to the CFO commentary published earlier today on our Investor Relations lean. Let me turn to the outlook for the first quarter of fiscal 2023.
We expect sequential growth to be driven primarily by Data Center. Gaming will also contribute to growth. Revenue is expected to be $8.1 billion, plus or minus 2%. GAAP and non-GAAP gross margins are expected to be 65.2% and 67%, respectively, plus or minus 50 basis points.
GAAP operating expenses are expected to be $3.55 billion, including the Arm write-off of $1.36 billion. Non-GAAP operating expenses are expected to be $1.6 billion. For the fiscal year, we expect to grow non-GAAP operating expenses at a similar percent as in fiscal 2022. GAAP and non-GAAP other operating, other income, and expenses are both expected to be an expense of approximately $55 million, excluding gains and losses on nonaffiliated investments.
Non-GAAP tax rate are expected to be 11% and 13%, plus or minus 1%, excluding discrete items. Capital expenditures are expected to be approximately $350 million to $400 million. Further financial details are included in the CFO commentary and other information available on our IR website. In closing, let me highlight upcoming events for the financial community.
We will be attending the Morgan Stanley Technology, Media, and Telecom Conference in person on March 7. We will also be hosting a virtual Investor Day on March 22, alongside the GPU Technology Conference. This will follow Jensen's opening keynote, which we invite you to tune into. Our earnings call to discuss the results for our first quarter of fiscal 2023 is scheduled for Wednesday, May 27.
We will now open the call for questions. Operator, will you please poll for questions?
Operator
Thank you. [Operator instructions] As a reminder, please limit yourself to one question. We'll take our first question from Toshiya Hari with Goldman Sachs and Company. Your line is open.
Toshiya Hari -- Goldman Sachs -- Analyst
Great. Thank you so much for taking the question, Jensen and Colette. I wanted to ask about Data Center. Colette, based on your guidance, you're probably guiding Data Center growth on a year-over-year basis to accelerate into the April quarter.
You talked about hyperscale cloud growing more than 2x and enterprise verticals growing strong double digits in the January quarter. Can you kind of speak to the drivers for April and perhaps speak to visibility into the second half of the fiscal year as well in Data Center? Thank you.
Colette Kress -- Executive Vice President and Chief Financial Officer
I'll start, and I'll turn it over to Jensen. For Q1, our guidance can include an acceleration of Data Center from where we left in terms of Q4. We will have growth across several of our market platforms within Q1, both Data Center, Gaming, and probably a couple of others. But yes, there is expected to be accelerated growth as we move into Q1.
I'll turn it over to Jensen to talk about the drivers that we see for the quarter and also for the full year.
Jensen Huang -- President and Chief Executive Officer
Yes. We have several -- first of all, Toshiya, great to hear from you. We have several growth drivers in data centers. There's hyperscale, public cloud, enterprise core, and enterprise edge.
We're seeing growth across the entire spectrum. There are several different use cases that are particularly exciting, large language models -- language, understanding models triggered by the invention of transformers, which is probably one of the most important AI models that's been invented in some time. And conversational AI used for customer service, chatbots, a whole bunch of customer service applications. It can be web-based.
It could be point-of-sale base. It could be cloud-based. Recommender systems, deep learning-based recommender systems are making groundbreaking improvements. And cloud graphics, all of the work that we're doing and putting rendering or putting simulations up in the cloud, cloud gaming, Android cloud gaming, are really driving adoption in the cloud.
And so, many different use cases across all of the different platforms in data centers.
Operator
Next, we'll go to C.J. Muse with Evercore ISI.
C.J. Muse -- Evercore ISI -- Analyst
Yes, good afternoon. Thank you for taking the question. I guess another question on the data center side. Curious if you can speak to supply constraints on the wafer side and whether that played a role in terms of capping revenues in the January quarter and how you see that becoming less of a headwind for you as you proceed through the year.
Colette Kress -- Executive Vice President and Chief Financial Officer
Thanks, C.J., for the question. I'll start on the data center supply. As we discussed last quarter and discussed today, we still have some supply constraints across some of our businesses. Networking in the Data Center business has been supply constrained.
We're improving every single day. And we do expect to improve supply each quarter as we enter into fiscal year '23 here. So, that is probably the key area within our Data Center. But from time to time, there can be other focused on do -- so I'll turn the rest of the question to Jensen in terms of how about the rest of the year as well.
Jensen Huang -- President and Chief Executive Officer
Yeah. Colette captured it well. We are supply constrained. Our demand is greater than our supply.
As you know, our data center product line consists of GPUs and mix, Bluefield DPUs, Quantum, and spectrum switches, HGX, if you will, system component, meaning that the entire motherboard or the entire GP board is delivered in combination because it's so complicated. And so, we have products that span a broad reach of use cases for data centers from training of AI models to inferencing at very large scale, to universal GPUs for public cloud, industry-standard servers, community servers for enterprise use, and supercomputing systems that use InfiniBand and quantum switches. And so, the application space is quite broad. We saw demand constrained pretty much across the entire range.
Our operations team did a fantastic job this year, both in executing in all of these complicated products, but also in expanding our supply base. We expect supply to improve each and every quarter going forward. And this quarter, this coming quarter, the Q1 -- the April quarter is, based on guidance that Colette just made, is consistent with an increasing supply base. We expect to still be demand constrained, but our supply base is going to increase this quarter, this next quarter, and pretty substantially in the second half.
Operator
Next, we'll go to Joe Moore with Morgan Stanley.
Joe Moore -- Morgan Stanley -- Analyst
Great. Thank you. I wonder if you could talk a little bit more about Grace now that the strategy kind of separated from the acquisition of Arm. The -- what are your aspirations there? Is it going to be primarily oriented to the DGX and HX Systems business versus merchant chips? Just how are you thinking about that opportunity long term?
Jensen Huang -- President and Chief Executive Officer
Yes. Thanks, Joe. We have a multiple-arm projects ongoing in the company from connected -- for devices to robotics processors such as the new Orin that's going into autonomous vehicles and robotic systems and industrial automation, robotics, and such. Orin is doing incredibly well.
It started production. And as we mentioned earlier, it's going to drive an inflection point starting in Q2 but accelerating through Q3 and the several years after as we ramp into all of the electric cars and all of the robotic applications and robotaxis and such. We also have Arm projects with the CPU that you mentioned, Grace. We have Grace, and we surely have the follow-ons to Grace, and you could expect us to do a lot of developments around the Arm architecture.
One of the things that's really evolved nicely over the last couple of years is the success that Arm has seen in hyperscalers and data centers. And it's really accelerated and motivated them to accelerate the development of higher-end CPUs. And so, you're going to see a lot of exciting CPUs coming from us. And Grace is just the first example.
You're going to see a whole bunch of them beyond that. But our strategy is accelerated computing. That's ultimately what we do for a living. We, as you know, love it where there's any CPUs.
If it's an x86 from any vendor. So, long as we have a CPU, we could connect NVIDIA's platform to it and accelerate it for artificial intelligence or computer graphics, robotics, and such. And so, we love to see the expansion of CPU footprints, and we're just thrilled that Arm is now growing into robotics and autonomous vehicles and cloud computing and supercomputing and in all these different applications, and we intend to bring the full spectrum of NVIDIA's accelerated computing platform to NVIDIA Arm CPUs.
Operator
Next, we'll go to John Pitzer with Credit Suisse.
John Pitzer -- Credit Suisse -- Analyst
Yeah, good to see you, guys. Thanks for letting me ask the question. Just on the inventory purchase obligations, I think this was the fourth quarter in a row where you've seen greater than 30% sequential growth and is the first quarter where that number is now eclipsing kind of your quarterly revenue guidance. And so, I guess I'm trying to figure out, to what extent is this just a reflection of how tight things are across the semi industry? To what extent is this the poker tale of kind of how bullish you are on future demand? And relative to your commentary, that supply starts to get better throughout the year, should we expect that number to start to level off? Or as the mix moves more to data center and more to longer cycle times, more complicated devices should that number continue to grow?
Jensen Huang -- President and Chief Executive Officer
The factors, the drivers that you mentioned in the supply chain, we expanded our supply chain footprint significantly this year to prepare us for both increased supply base and supply availability in each one of the quarters going forward, but also in preparation for some really exciting product launches. As mentioned, Orin ramping into autonomous vehicles is brand new. This is the inflection point of us growing into autonomous vehicles. This is going to be a very large business for us going forward.
It was already mentioned, Grace is a brand-new product that has never been on NVIDIA's road map. And we already see great success with customers who love the architecture of it and desperately in need of the type of capability that Grace brings. And this should be a pretty exciting year for new product launches. And so, we're preparing for all of that laying the foundation for us to bring all those exciting products to the marketplace.
Operator
Next, we'll go to Tim Arcuri with UBS.
Tim Arcuri -- UBS -- Analyst
Thank you very much. Obviously, there's a lot more talk from you about software. And I think it's still kind of a little bit of a black box for live investors. And I know, Jensen, that you've talked about software as a medium to basically open up new markets.
But I'm wondering maybe if you can sort of quantify how big the software licensing revenue is today and maybe when you might start to break it out like you did data center, which really got the stock moving in a huge, huge way. Thanks.
Jensen Huang -- President and Chief Executive Officer
Yeah. NVIDIA is a software-driven business. Accelerated computing is a software-driven business. It starts from recognizing what domain of applications we want to accelerate and can accelerate and then building an entire stack from the processor to the system to the system software, the acceleration engines, and potentially even the applications itself, like the software that we were mentioning earlier, NVIDIA DRIVE, NVIDIA AI, and NVIDIA Omniverse.
These are applications that sit on top of system software and are really valuable to the marketplace. The way to think about our software licensing -- so we've always been a software-driven business. But for the very first time, we have packaged licensable software on -- available to customers. The way that we license software for NVIDIA AI Enterprise is per node of server.
There's some 20 million, 25 million servers that are installed in the world today in enterprises, not including clouds. We believe that every single server in the future will be running AI software. And we would like to offer an engine that enables enterprises to be able to use the most advanced the most trusted, the most utilized AI engine in the world. And so, that is essentially the target market, if you will, for NVIDIA AI.
The NVIDIA Omniverse is targeting -- is designed for creators contributing content to a virtual world and connect it to robots that are contributing to content in a virtual world. And so, it's based on connections. There are 40 million designers and creators around the world. There are going to be hundreds of millions of robots.
Every single car will essentially be a robot someday. And those are connections that will be connected into a digital twin system like Omniverse. And those are -- so the Omniverse business model is per connection per year. And in the case of NVIDIA DRIVE, we share the economics of the software that we deliver, if it's AB software or parking software or cabin-based AI software, whatever the licensing is or whatever the service, if it's an upfront license, we share the economics of that.
If it's a monthly service subscription, we share the economics of that. But basically, for the cars that we are part of, that we're developing, the end-to-end service, we will get the benefits of the economics of that for the entire life of the fleet of the car. And so, you could imagine, with 10 million cars, with modern car lifetimes of 10 to 20 years, the economics and the market, the installed opportunity is quite high. And so, our business opportunity is based on those factors.
But our software business really, really started several years ago with virtual GPUs, but this year was when we really stepped it up and offered for the very first time NVIDIA AI Enterprise, Omniverse, and DRIVE. And so, I watch the spot, I think this is going to be a very significant business opportunity for us, and we look forward to reporting on it.
Operator
Next, we'll go to Vivek Arya with Bank of America.
Vivek Arya -- Bank of America Merrill Lynch -- Analyst
Thanks for taking my questions. Jensen, in the past, you mentioned about 10% or so adoption rate for AI among your customer base. I was hoping you would quantify where we are in that adoption curve that you tend to differentiate between the adoption differences between your hyperscale and enterprise customers? And then kind of related to that, is there an inorganic element to your growth now that you have over $20 billion of cash on the balance sheet? How are you planning to deploy that to kind of accelerate your growth also?
Jensen Huang -- President and Chief Executive Officer
Yeah. The applications for AI is unquestionably growing, and it's growing incredibly fast. But whether in enterprises and financial services, it could be fraud detection, in cases of consumer pointing businesses, customer service, conversational AI, where people are calling chatbots. But in the future, every website will have a chatbot, every phone number will have a chatbot, whether it's a human in the loop or not human in the loop, we'll have a chatbot.
And so, customer service will be heavily, heavily supported by artificial intelligence in the future. Almost every point of sales, I think, whether it's a fast food or a quick service, businesses are going to have chatbots and AI-based customer service. Retail checkouts will be supported by AI agents. And so, all of this is made possible by a couple of breakthroughs, computer vision, of course, because the agents, the AIs have to make eye contact and recognize your posture and such, recognize speech, understand the context and what is being spoken about and have a reasonable conversation with people so that you could provide good customer service.
The ability to have human in the loop is one of the great things about an AI much, much more so than a recording, which obviously is not intelligent and therefore it's difficult to, if you will, call your manager or call somebody to provide services that they can't. And so, the number of different applications that have been enabled by natural language understanding in customer service in just the last couple of years has grown tremendously. I think we're -- we remain early days in our adoption. It's incredible how fast it has grown and how many different applications are now possible with AI.
It pretty much says that almost all future software will be written with AI or by AI. And when it's done, it will be an AI. And we see it in all these different industries. And so, I'm pretty certain we're in the early innings yet of AI, and this is going to be one of the largest industries of software that we have ever known.
With respect to capital, as you know, we had just terminated our Arm agreement. We have a regular capital strategy process, and we'll go through that, and we'll make the best judgment about how to use our capital in helping our growth and sustaining our growth, and accelerating our growth, and we'll have all of those sensible conversations during those capital allocation meetings. We're just delighted to have so much capital. And so, just to put it out there.
Operator
And next, we'll go to Aaron Rakers with Wells Fargo.
Unknown speaker
Thanks, guys. This is Michael on behalf of Aaron. Can you guys talk about how the launch of the RTX 3050 is going so far? And maybe more broadly, your view of where we are in the product cycle on gaming? Thanks.
Jensen Huang -- President and Chief Executive Officer
Thanks, Michael. Let's see. RTX is an unqualified home run. RTX completely reinvented modern computer graphics.
It brought forward ray tracing about a decade earlier than anybody thought possible. The combination of RTX with artificial intelligence, which enabled this technology we call DLSS, is able to not only do a ton more computation using our processors but also engage the powerful Tensor for processors that we have in our GPUs to generate images, beautiful images. RTX is being adopted by just every game developer on the planet now. It's being adopted by just about every design tool on the planet now.
And if not for RTX, Omniverse wouldn't be possible. We wouldn't be able to do physically based path tracing and simulate sensors like radars and LiDARs and ultrasonics and of course, cameras and simulate these cameras physically and still be able to deliver the type of performance that we deliver. And so, RTX was a game-changer for the industry. It reset modern computer graphics.
And it was an enabler for us to build an entire new platform from Omniverse. We're about -- I think about a third of the way through upgrading an installed base that is growing. You know that video games is now the world's largest gaming genre. And Steam, over the last two years, has grown by 50%.
The number of concurrent players on Steam has grown tremendously. And in just the last couple of years, a brand-new game store from Epic came on, and it's already a multi-hundred-million-dollar business. I think it's close to $1 billion that they're doing incredibly well. I'm so happy to see it.
And so, the overall gaming market is growing and it's growing quite nicely. But the thing that, in addition to resetting computer graphics for our entire installed base, the growing of our installed base because gaming is growing. There are a couple of other growth dynamics that are associated with GeForce and RTX that's really quite brand new. One of them is hybrid work.
This is a permanent condition. And we now are seeing across the board people who are designers and creators now have to set up essentially a new workstation or new home workstation design studio so that they could do their work at home. In addition, the creative economy, the digital economy, the creative economy is really, really doing fantastically because everything has to be done in 3D now. Print ads are done in 3D.
So, 2D print is done in 3D. Video is done in 3D. In live video broadcast video, the millions of influencers now augment their broadcast with rich augmented reality and 3D graphics. And so, 3D graphics is now not just for video games and 3D content, it's actually used now for all forms of digital content creation.
And so, RTX has all of these different drivers working behind it, and we're definitely in the early innings of RTX.
Operator
Next, we'll go to Stacy Rasgon with Bernstein Research.
Stacy Rasgon -- Bernstein Research -- Analyst
Hi, guys, thanks for taking my question. So, you said that the growth in the next quarter is about $450 million, give or take, driven by Data Center. Can you give us some feeling for how that growth is being driven by units versus pricing versus mix and how those drivers might differ between Gaming and Data Center, if at all, for Colette?
Colette Kress -- Executive Vice President and Chief Financial Officer
It's really early in the quarter to determine, Stacy, our exact mix that we will have based on the unit and an ASP -- our overall growth quarter over quarter going into Q1 will be driven by data center primarily. We will see a little bit of growth there in gaming. I think that's important to understand that even after Q4 holiday moving into Q1, we'll still probably see growth in gaming, which is different in terms of what we've seen seasonally. We will probably have growth in automotive as well sequentially between Q4 and Q1.
There are still some areas that are so constrained. We are working again to try and improve that for every quarter going forward, but that's how you should look at our earnings for Q1 primarily from Data Center.
Operator
Next, we'll go to Harlan Sur with J.P. Morgan.
Harlan Sur -- J.P. Morgan -- Analyst
Good afternoon, and congratulations on the solid results and execution. The networking connectivity portfolio addition has been pretty solid for the NVIDIA team, especially in enabling scaling of your GPU systems, improving connectivity bottlenecks in yours and your customers' accelerated compute platforms. So, in a year where spending is growing 30%. You've got a strong networking upgrade cycle, which is good for your NIC products and just continued overall good attach rates, if the team can unlock more supply, will the networking connectivity business grow in line or faster than the overall Data Center business this year? And then for Jensen, have you driven synergies between Mellanox's leadership in networking connectivity? And for example, leveraging their capabilities for your internally developed NVLink connectivity and switching architectures?
Jensen Huang -- President and Chief Executive Officer
Yes, absolutely. If not for the work that we did so closely with Mellanox, the scalability of DGX and DGX Super Pine and the research supercomputer that was just installed in Meta would just not be possible. The concepts of overlapping networking and compute, moving some -- moving computing into the fabric, into the network, the work that we're doing with Synchronoss and Precision Timing so that we could create Omniverse computers that obey the laws of physics and space-time, these things are just simply not possible. The work that we're doing to bring cloud-native secure multi-tenancy to supercomputing wouldn't have been possible.
The number of innovations, that are countless. And so, I am so thrilled with the combination and so through what the work the Mellanox team are doing. We've accelerated road maps as a result of the combination that we could leverage a much larger base of chip design. BlueField's road map has been accelerated probably by about a year.
The switch in -- the quantum switch and the spectrum switch, the SerDes are absolutely world-class, shared between Ethernet and InfiniBand and NVLink, absolutely the best servers in the world. And so, the list of opportunities or the list of combination benefits is really quite countless. And so, I'm super thrilled with that. With respect to networking growth, we should be growing.
If we weren't supply constrained, we should be growing faster than overall CSP growth. And the reason for that -- the reason for that is twofold. The first is because the networking leadership position of Mellanox, Mellanox is highly heavyweight in the upper end of networking, where the adoption of higher-speed networks tends to move. And so, it's sensible that as new data centers are built, the first preference is to install it with higher-speed networking than the last-generation networking.
And Mellanox's networking technology is unambiguously world-class. The second reason is because the areas where the overall NVIDIA is strong has to do with the areas that are growing quite fast, which related to artificial intelligence or cloud AI and such. And so, those different applications are growing faster than the core. And so, it would be sensible that we have the opportunity as we expand our supply base to continue to grow faster than CSPs overall.
Operator
Our next question will come from Matt Ramsay with Cowen.
Matt Ramsay -- Cowen and Company -- Analyst
Yes, thank you very much. Good afternoon. Jensen, I maybe wanted to expand on some of the things that you were just speaking about in your last answer with respect to the Data Center business. It's not often maybe ever that you have both x86 server vendors having new big platform upgrades in the same year, which will probably happen later this year.
There's a lot going on there, PCIe, some CXL stuff. I wonder if you could talk a bit about your Data Center business broadly and what you feel might be memory and I/O constrained currently that these systems might unlock for you both in the cloud and enterprise side, but also in the DGX business. Thanks.
Jensen Huang -- President and Chief Executive Officer
Yes. Thanks, Matt. There are several bottlenecks, and let me just highlight some of them. One of the largest bottlenecks is memory speed.
And memory speed, that's the reason why we use the fastest memories in the world, HBM and GDDR, etc., etc. We are the largest consumers of the fastest memories in the world and not even by -- there's not -- with no close second that I know. And so, our consumption of fast memories is important to the work that we do. The second is networking performance.
It is the reason why we have the fastest networks. It is also the reason why we have the most fastest networks in any system. We will have, for example, eight InfiniBand at the highest speeds connected right into HGX or DGX server. And so, the work that we do in GPU direct memory, RDMA, the work that we do with GPU direct storage, the work that we do with in-network computing and all reductions and moving data around inside the network is absolutely world-class.
This is an area that we are just -- I am just incredibly proud. All of that is so that we could be less bottlenecked by the CPU. Remember, inside our DGX system is on CPU and eight GPUs. And the fundamental goal is to offload as much as we can and utilize the resources that we have as much as we can.
This year, we expect a transition in PCIe Gen 4 to Gen 5. We are constrained on Gen 4. We'll be constrained on Gen 5, but we're used to that. And that's something that we're very good at.
And we'll continue to support Gen 4 well through next year, maybe well through the next couple of years. And all of the installed base of Gen 4 systems that are going to be all over the world, and we'll take advantage of Gen 5 as much as we can. But we have all kinds of new technologies and strategies to improve the throughput of systems and avert the bottlenecks that are there.
Operator
Our final question comes from the line of Raji Gill with Needham and Company.
Raji Gill -- Needham & Company -- Analyst
Yes. Thanks, and congrats on the good quarter and guide. Colette, question on the gross margin and to Jensen's point about really creating a software business driven by Omniverse, DRIVE, and Enterprise. When you're kind of contemplating your margin profile over the next couple of years, how do we think about that? Is it really going to be driven by an increasing mix of software as a percentage of your revenue over time? Is there more margin upside on the hardware side in terms of some of your segments? The software opportunity is very exciting, but I'm just curious how that would translate to your kind of more of a longer-term margin profile.
Thank you.
Colette Kress -- Executive Vice President and Chief Financial Officer
Yes. Thanks for the question on gross margin and the long term. When we think about the long-term gross margin, we have incorporated software in many of our platforms even today, meaning our high-value platforms in data center or for the purpose of our business, have really helped us with our gross margins to this point, and we've done a really solid job of managing that and the growth over the years. I believe these businesses will continue to be a growing opportunity for us, but now also with the ability to package up -- so as that scales with our Enterprise customers, in the Data center, and with our already procured deals, look, we've got a great opportunity to fill in the future and the margin needs to come.
So, we're going to work on that. We've set the stage for having been able to package it up to be able to sell it separately to create the business model, to create the partners that are helping us sell it. But yes, we do believe this will be a driver in the long term.
Operator
Thank you. I'll now turn it back over to Jensen Huang for closing remarks.
Jensen Huang -- President and Chief Executive Officer
Thanks, everyone. The tremendous demand for our computing platforms, NVIDIA RTX, NVIDIA HPC, and NVIDIA AI, drove a great quarter, capping a record year. Our work propels advances in AI, digital biology, climate sciences, gaming, creative design to autonomous vehicles and robotics, and some of today's most impactful fields. Our open computing platform optimized across the full stack, architecture for data center scale is adopted by customers globally from cloud to core to edge and robotics.
I am proud of the NVIDIA operations team as we make substantial strides in broadening our supply base to scale our company and better serve customer demand. And this year, we introduced new software business models with NVIDIA AI Enterprise, NVIDIA Omniverse, and NVIDIA DRIVE. NVIDIA DRIVE is a full-stack end-to-end platform that serves the industry with AV chips, data center infrastructure for AI and simulation, mapping, and the autonomous driving application service. Our data center infrastructure is used by just about anybody building AVs, robotics robotaxis, shuttles, and trucks.
EV companies have selected our Orin chip across the world. And our partnership with Mercedes-Benz and Jaguar Land Rover has opened up a new software and services business model for millions of cars for the life of the fleet. NVIDIA Omniverse is a world simulation engine that connects simulated digital worlds to the physical world. Omniverse is a digital twin, a simulation of the physical world.
The system can be a building a factory, a warehouse, a car, a fleet of cars, a robotic factory orchestrating a fleet of robots building cars that are themselves robotic. Today's Internet is 2D and AI is in the cloud. The next phase of Internet will be 3D and AI will be connected to the physical world. We created Omniverse to enable the next wave of AI where AI and robotics touches our world.
Omniverse can sound like science fiction, but there are real-world use cases today. Hundreds of companies are evaluating Omniverse. We can't wait to share more of our progress at next month's GTC, learn about new chips, new computing platforms, new AI and robotic breakthroughs, and the new frontiers of Omniverse. Hear from the technologists of Deloitte, Epic Games, Mercedes-Benz, Microsoft, Pfizer, Sony, Visa, Walt Disney, Zoom, and more.
This GTC promises to be our most exciting developers conference ever. We had quite a year, yet nothing makes me more proud than the incredible people who have made NVIDIA one of the best companies to work for and the company where they do their lives' work. We look forward to updating you on our progress next quarter. Thank you.
Operator
[Operator signoff]
Duration: 62 minutes